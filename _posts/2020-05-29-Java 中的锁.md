---
layout: post
title: Java 中的锁
categories: [Others]
description: 
keywords: 
---

* content
{:toc}




## Lock 简介, 地位, 作用

锁是一种工具, 用于控制对共享资源的访问

Lock 和 Synchronized, 这两个是最常见的锁, 它们都可以达到线程安全的目的, 但是在使用上和功能上又有较大的不同

Lock 并不是用来代替 Synchronized 的, 而是当使用 Synchronized 不合适或不足以满足要求的时候, 来提供高级功能的

Lock 接口最常见的实现类是 ReentrantLock

### 为什么需要 Lock

#### 为什么 synchronized 不够用

效率低: 锁的释放情况少, 试图获得锁时不能设定超时, 不能中断一个正在试图获得锁的线程

不够灵活(读写锁更灵活): 加锁和释放的时机单一, 每个锁仅有单一的条件(某个对象), 可能是不够的

#### Lock 主要方法介绍

lock(): 最普通的获取锁, 如果锁已经被其他线程获取了, 则进行等待

tryLock(), tryLock(long time, TimeUnit unit) 和 lockInterruptibly()

Lock 不会像 Synchronized 一样在异常时自动释放锁, 因此最佳实践是, 在 finally 中释放锁, 以保证发生异常时锁一定释放



### 可见性保证

happens-before 原则



## 锁的分类

![http://www.milky.show/images/java/lock/lock_1.png](http://www.milky.show/images/java/lock/lock_1.png)

### 乐观锁和悲观锁

互斥同步锁(悲观锁)的劣势

*   阻塞和唤醒带来的性能劣势
*   永久阻塞: 如果持有锁的线程被永久阻塞, 比如遇到了无限循环, 死锁等活跃性问题, 那么等待该线程释放锁的那几个悲催的线程, 将永远也得不到执行
*   优先级反转

非互斥同步锁(乐观锁)

#### 悲观锁

如果我不锁住这个资源, 别人就会来争抢, 就会造成数据结果错误, 所以每次悲观锁为了确保结果的正确性, 会在每次获取并修改数据时, 把数据锁住, 让别人无法访问该数据, 这样就可以确保数据内容万无一失

Java 中的悲观锁的实现就是 synchronized 和 Lock 相关类

#### 乐观锁

认为自己在处理操作的时候不会有其他线程来干扰, 所以并不会锁住被操作对象

在更新的时候, 去对比在我修改的期间数据有没有被其他人改变过: 如果没被改变过, 就说明真的是只有我自己在操作, 那我就正常去修改数据

如果数据和我一开始拿到的不一样了, 说明其他人在这段时间内改过数据, 那我就不能继续刚才的更新数据过程了, 我会选择放弃, 报错, 重试等策略

乐观锁的实现一般都是利用 CAS 算法来实现的

#### 开销对比

悲观锁的原始开销要高于乐观锁, 但是特点是一劳永逸, 临界区持锁时间就算越来越差, 也不会对互斥锁的开销造成影响

乐观锁一开始的开销比悲观锁小, 但是如果自旋时间很长或者不停重试, 那么消耗的资源也会越来越多

#### 两种锁各自的使用场景

悲观锁适合并发写入多的情况, 适用于临界区斥锁时间比较长的情况, 悲观锁可以避免大量的无用自旋等消耗, 典型情况:

*   临界区有 IO 操作
*   临界区代码复杂或者循环量大
*   临界区竞争非常激烈

乐观锁适合并发写入少, 大部分是读取的场景, 不加锁的能让读取性能大福提高



### 可重入锁(ReentrantLock)和非可重入锁

#### 可重入锁

可以反复获得同一把锁, 内部维护了计数器, 避免死锁, 提升封装性

#### 非可重入锁

不可以重复获取同一把锁



### 公平锁和非公平锁

公平指的是按照线程请求的顺序来分配锁; 非公平指的是**不完全按照请求的顺序**, 在一定情况下可以插队

非公平也同样不提倡"插队"行为, 这里的非公平, 指的是"在合适的时机"插队, 而不是盲目插队

**非公平锁避免唤醒带来的空档期**

#### 公平锁

如果在创建 ReentrantLock 对象时, 参数填写为 true, 那么这就是个公平锁

#### 非公平锁

默认情况下都是非公平锁

### 共享锁(读锁)和排它锁(写锁)

共享锁, 又称为读锁, 获得共享锁之后, 可以查看但无法修改和删除数据, 其他线程此时也可以获取到共享锁, 也可以查看但无法修改和删除数据

排它锁又称为独占锁, 独享锁, synchronized 就是典型的排它锁, **其他线程无法读写**

**共享锁和排它锁的典型是读写锁 ReentrantReadWriteLock, 其中读锁是共享锁, 写锁是排它锁**

在没有读写锁之前, 我们假设使用 ReentrantLock, 那么虽然我们保证了线程安全, 但是也浪费了一定的资源: 多个读操作同时进行, 并没有线程安全问题

在读的地方使用读锁, 在写的地方使用写锁, 灵活控制, 如果没有写锁的情况下, 读是物阻塞的, 提高了程序的执行效率

#### 读写锁的规则

1.  多个线程只申请读锁, 都可以申请到
2.  如果有一个线程已经占用了读锁, 则此时其他线程如果要申请写锁, 则申请写锁的线程会一直等待释放读锁
3.  如果有一个线程已经占用了写锁, 则此时其他线程如果要申请写锁或者读锁, 则申请的线程会一直等待释放写锁

#### 读写锁的插队策略

公平锁: 不允许插队, 会完全按照顺序执行

非公平锁:

*   写锁可以随时插队, 保证在大量读的情况下可以写入
*   读锁仅在等待队列头结点不是想获取写锁的线程的时候可以插队

#### 读写锁的升降级

**ReentrantReadWriteLock 支持锁的降级(写锁变读锁), 不支持升级(容易造成死锁)**



### 自旋锁和阻塞锁

阻塞或唤醒一个 Java 线程需要操作系统切换 CPU 状态来完成, 这种状态转换需要耗费处理器时间, 如果同步代码块中的内容过于简单, 状态转换消耗的时间有可能比用户代码执行的时间还要常, 在许多场景中, 同步资源的锁定时间很短, 为了这一小段时间去切换线程, 线程挂起和恢复现场的花费可能会让系统得不偿失如果物理机有多个处理器, 能够让两个或以上的线程同时并行执行, 我们就可以让后面那个请求锁的线程不放弃 CPU 的执行时间, 看看持有锁的线程是否很快就会释放锁, 而为了让当前线程"稍等一下", 我们需要让当前线程进行自旋, 如果在自旋完成后前面锁定同步资源的线程已经释放了锁, 那么当前线程就可以不必阻塞而是直接获取同步资源, 从而避免切换线程的开销, 这就是自旋锁. 阻塞锁和自旋锁相反, 阻塞锁如果遇到没拿到锁的情况, 会直接把线程阻塞, 知道被唤醒.

如果被锁占用的时间很长, 那么自选的线程只会白白浪费处理器资源, 在自旋的过程中, 一直消耗 CPU, 所以虽然自旋锁的其实开销低于悲观锁, 但是随着自旋时间的增长, 开销也是线性增长的.

在 java1.5 版本及以上的并发框架 java.util.concurrent 的 atomic 包下的类基本都是自旋锁的实现.

AtomicInteger 的实现, 自旋锁的实现原理是 CAS, Atomicinteger 中调用 unsafe 进行自增操作的源码中的 do-while 循环就是一个自旋操作, 如果修改过程中遇到其他线程竞争导致没修改成功, 就在 while 里死循环, 直至修改成功.



### 可中断锁

在 Java 中, synchronized 就是不可中断锁, 而 Lock 是可中断锁, 因为 tryLock(time) 和 lockInterruptibly 都能响应中断

如果某一线程 A 正在执行锁中的代码, 另一线程 B 正在等待获取该锁, 可能由于等待时间过长, 线程 B 不想等待了, 想先处理其他事情, 我们可以中断它, 这就是可中断锁了.



### 锁优化

#### Java 虚拟机对锁的优化

自旋锁和自适应

锁消除

锁粗化

#### 我们写代码时如何优化

缩小同步代码块

尽量不要锁住方法

减少请求锁的次数

避免人为制造"热点"

锁中尽量不要再包含锁

选择合适的锁类型或合适的工具类





## 原子类

不可分割

一个操作是**不可中断**的, 几遍是多线程的情况下也可以保证

java.util.concurrent.atomic

元子类的作用和锁类似, 是为了保证并发情况下**线程安全**, 不过元子类相比于锁, 有一定的**优势**.

粒度更细: 原子变量可以把竞争范围缩小到边浪级别, 这是我们可以获得的最细粒度的情况了, 通常锁的粒度都要大于原子变量的粒度.

效率更高: 通常, 使用原子类的效率会比使用锁的效率更高, 除了**高度竞争**的情况.

### 6 类原子类总览

| 分类                               | 类                                                           |
| ---------------------------------- | ------------------------------------------------------------ |
| Atomic*基本类型原子类              | AtomicInteger<br />AtomicLong<br />AtomicBoolean             |
| Atomic*Array 数组类型原子类        | AtomicIntegerArray<br />AtomicLongArray<br />AtomicReferenceArray |
| Atomic*Reference 引用类型原子类    | AtomicReference<br />AtomicStampedReference<br />AtomicMarkableReference |
| Atomic*FieldUpdater 升级类型原子类 | AtomicIntegerFieldUpdater<br />AtomicLongFieldUpdater<br />AtomicReferenceFieldUpdater |
| Adder 累加器                       | LongAdder<br />DoubleAdder                                   |
| Accumulator 累加器                 | LongAccumulator<br />DoubleAccumulator                       |

### Atomic* 基本类型原子类常用方法

public final int get() // 获取当前的值

public final int getAndSet(int newValue) // 获取当前的值, 并且设置新的值

public final int getAndIncrement() // 获取当前的值, 并自增, 避免 a++ 问题

public final int getAndDecrement() // 获取当前的值, 并自减

public final int getAndAdd(int delta) // 获取当前的值, 并加上预期的值

boolean compareAndSet(int expect, int update) // 如果输入的数值等于预期值, 则以原子方式将该值设置为输入值(update)



### Adder 累加器

是 Java8 引入的, 相对是比较新的一个类

高并发下 LongAdder 比 AtomicLong 效率高, 不过本质是空间换时间

竞争激烈的时候, LongAdder 把不同线程对应到不同的 Cell 上进行修改, 降低了冲突的概率, 是多段锁的理念, 提高了并发性





## Java 中是如何利用 CAS 实现原子操作的

AtomicInteger 加载 Unsafe 工具, 从来**直接操作内存**数据.

用 Unsafe 来实现底层操作.

用 volatile 修饰 value 字段, 保证可见性.



## final 关键字和不变性

### 不变性(Immutable)

如果对象在创建后, 状态就不能被修改, 那么它就是不可变的.

例如: person 对象, age 和 name 都不能再变.

具有不变性的对象**一定是线程安全**的, 我们不需要对其采取任何额外的安全措施, 也能保证线程安全.

### final 的作用

**类防止被继承, 方法防止被重写, 变量防止被修改.**

天生是**线程安全**的, 而不需要额外的同步开销.

#### final 修饰变量

final instance variable(类中的 final 属性)

*   第一种是在声明变量的等号右边直接赋值
*   第二种就是构造函数中赋值
*   第三种就是在类的初始代码块中赋值(不常用)
*   如果不采用第一种赋值方法, 那么就必须在第 2,3 种挑一个来赋值, 而不能不赋值, 这是 final 语法所规定的

final static variable(类中的 static final 属性)

*   声明变量的等号右边直接赋值
*   static 初始代码块赋值, 但是不能用普通的初始代码块赋值

final local variable(方法中的 final 变量)

*   不规定赋值时机, 只要求在使用前必须赋值, 这和方法中的非 final 变量的要求也是一样的

#### final 修饰方法

构造方法不允许 final 修饰

普通方法不可被重写, 也就是不能被 override

static 方法不能被重写

#### final 修饰类

类不可被继承

典型的 String 类就是 final 的, 我们从没见过哪个类是继承 String 类的

### 注意点

被 final 修饰的变量, 意味着**值不能被修改**. 如果变量是对象, 那么对象的**引用不能变**, 但是对象自身的**内容依然可以变化.**

final 使用原则: 良好的编程习惯

### 不变性和 final 的关系

不变性并不意味着, 简单地用 final 修饰就是不可变

*   对于基本数据类型, 确实被 final 修饰后就具有不变性
*   但是对于对象类型, 需要改对象保证自身被创建后, 状态永远不会变才可以

如何利用 final 实现对象不可变

*   把所有属性都声明为 final?
*   一个属性是对象类型的不可变对象的正确例子

### 栈封闭技术

在方法里新建的局部变量, 实际上是存储在每个线程四有的栈空间, 而每个栈的栈空间是不能被其他线程所访问到的, 所以不会有线程安全问题. 这就是著名的"栈封闭"技术, 是"线程封闭"技术的一种情况







## 实现多线程的官方正确方法

### 方法一: 实现 Runnable 接口

实现 Runnable 接口更好, 解耦更好, 还可以继承类, 最终调用 target.run()

### 方法二: 继承 Thread 类

整个 run() 方法被重写



### 同时使用两种方法会怎么样?

从面向对象的思想去考虑, run 方法就被覆盖了, 经典的三行代码就会被覆盖, 所以不会调用 Runnable 的 run() 方法了









## 并发容器精讲

ConcurrentHashMap: 线程安全的 HashMap

CopyOnWriteArrayList: 线程安全的 List

BlockingQueue: 这是一个接口, 表示阻塞队列, 非常适合用于作为数据共享的通道

ConcurrentLinkedQueue: 高效的非阻塞并发队列, 使用链表实现. 可以看做一个线程安全的 LinkedList

ConcurrentSkipListMap: 是一个 Map, 使用跳表的数据结构进行快速查找



### 集合类的历史

Vector 和 Hashtable: 早期 JDK 线程安全的 AarrayList 和 HashMap, 性能不好, 因为方法都是用 synchronized 修饰的

HashMap 和 ArrayList: 这两个类不是线程安全的, 但是可以用 Collections.synchronizedList(new ArrayList\<E>()) 和 Collections.synchronizedMap(new HashMap\<E\>())使之变成线程安全的, 本质还是使用 synchronized

ConcurrentHashMap 和 CopyOnWriteArrayList: 取代同步的 HashMap 和同步的 ArrayList(时代巨轮滚滚向前)

### ConcurrentHashMap

#### Map 简介

HashMap: 根据 hashcode 定位, 允许 key 为 null, 线程不安全

Hashtable: 和 HashMap 功能一样, 但是性能低下, 已淘汰

LinkedHashMap: 是 HashMap 的子类

TreeMap: 实现了 SortedMap 接口, 可以排序

#### 为什么 HashMap 是线程不安全的

同时 put 碰撞导致数据丢失

同时 put 扩容导致数据丢失

死循环造成的 CPU100%

#### 为什么需要 ConcurrentHashMap

#### HashMap 分析

#### JDK1.7 的 ConcurrentHashMap 实现和分析

#### JDK1.8 的 ConcurrentHashMap 实现和分析

#### 为什么要将 1.7 改为 1.8 的结构

#### ConcurrentHashMap 也不是线程安全的?



### CopyOnWriteArrayList



### 阻塞队列











## 请描述 synchronized 和 Reentrantlock 的底层实现及重入的底层原理

synchronized 的底层汇编还是 lock cmpxchg 命令

## 请描述锁的四种状态和升级过程

在 JDK1.2 时 synchronized 的性能非常差, 在 JDK1.6 后优化了锁的升级状态

**JDK 早期, synchronized 叫做重量级锁, 因为申请锁资源必须通过 kernel(内核), 早期 APP 可以直接系统调用底层硬件**

现代操作系统会分为两层, 内核态和用户态, 自己的 APP 就是用户态, 系统资源就是内核态, 如果用户态想访问内核态的资源需要通过 kernel 的允许, 将用户态转向内核态, 拿到结果后再从内核态返回用户态. 早期 synchronized 加锁就需要申请系统资源, 进行用户态和内核态的转换, 所以是重量级锁, 经过优化后在某些情况下不需要通过内核态就可以解决, 比如 CAS(轻量级锁), 只需要用户态就可以完成

![http://www.milky.show/images/mashibing/synchronized/syn_3.png](http://www.milky.show/images/mashibing/synchronized/syn_3.png)

### 无锁态

最后是 001

### 偏向锁

最后是 101, 用户态完成

将自己的线程号写进了 markword 上, 此时只是贴了一个自己的 id 上去, 并没有发生锁的竞争

多数 synchronized 方法, 在很多情况下, 只有一个线程在运行, 没有必要向内核态申请资源, 例如 StringBuffer 中的 sync 方法

**只要有另外的线程来竞争, 就会升级为轻量级锁**

### 轻量级锁, 自旋锁, 无锁(CAS)

最后是 00, 用户态完成

当发生了多线程争锁的情况, 哪个线程能将自己的 id 写进 markword 谁就能获得锁, 此时是在用户空间完成的 CAS 操作, 此时偏向锁的线程也会发起争锁, 但是会有一定优势

CAS 适合操作特别快或者线程数较小的情况, 因为自旋会消耗 CPU 资源

### 重量级锁

最后是 10, 需要向内核态申请

向操作系统申请锁

为什么有了自旋锁, 还需要重量级锁, 因为重量级锁不需要消耗 CPU 资源, 会将其他线程放到一个队列中(waitset),  因此不需要自旋的过程了

## 请谈一下 AQS, 为什么 AQS 的底层是 CAS + volatile

## 解释一下锁的四种状态

## 对象在内存中的布局

JOL = Java Object Layout(Java 对象内存布局)

在堆内存中 new 出来一个对象, 这个对象在堆中分为四个部分

1.  markword, 8 个字节, synchronized(o) 锁定对象的本质是修改了 markword, **使 markword 包含了锁的信息**, 我们平时所说的加锁, 就是修改对象的 markword 的内容

    *   锁信息, 无锁态, 偏向锁...
    *   GC 标记信息
    *   HashCode

    ![http://www.milky.show/images/mashibing/synchronized/syn_2.png](http://www.milky.show/images/mashibing/synchronized/syn_2.png)

2.  klass poniter, 是一个指针, 指向 T.class, 表名这个对象属于哪一个 class, 压缩是 4 字节, 不压缩是 8 字节

3.  instance state, 成员变量所占的位置, byte, short, int, long...

4.  padding, 对齐, 64 位虚拟机 padding 是需要 4 块内容可以被 8 字节整除, 如果前 3 块不能被 8 整除, 就用 padding 补齐

![http://www.milky.show/images/mashibing/synchronized/syn_1.png](http://www.milky.show/images/mashibing/synchronized/syn_1.png)

## Object o = new Object() 在内存中占了多少字节

16 字节

JOL 是 openjdk 的一个工具类

Object o = new Object();
sysout ClassLayout.parseInstance(o).toPrintable();

## 请描述一下锁的分类以及 JDK 的应用

## 自旋锁一定比重量级锁效率高吗

自旋是消耗CPU资源的，如果锁的时间长，或者自旋线程多，CPU会被大量消耗

重量级锁有等待队列，所有拿不到锁的进入等待队列，不需要消耗CPU资源

## 偏向锁一定比自旋锁效率高吗

**偏向锁是在 JVM 启动 4s 后开启的, 因为 JVM 启动时有很多内存区域需要进行加锁, 这时已经明确知道有多线程去竞争锁, 就不需要开启偏向锁了**

很多情况下我明知道会存在锁的竞争情况, 就不需要加偏向锁了, 如果加了偏向锁还存在一个偏向锁升级的过程, 反而效率会降低



不一定，在明确知道会有多线程竞争的情况下，偏向锁肯定会涉及锁撤销，这时候直接使用自旋锁

JVM启动过程，会有很多线程竞争（明确），所以默认情况启动时不打开偏向锁，过一段儿时间再打开



## synchronized vs Lock (CAS)

 在高争用 高耗时的环境下synchronized效率更高
 在低争用 低耗时的环境下CAS效率更高
 synchronized到重量级之后是等待队列（不消耗CPU）
 CAS（等待期间消耗CPU）

 一切以实测为准



## 锁消除 lock eliminate

```java
public void add(String str1,String str2){
    StringBuffer sb = new StringBuffer();
    sb.append(str1).append(str2);
}
```

我们都知道 StringBuffer 是线程安全的，因为它的关键方法都是被 synchronized 修饰过的，但我们看上面这段代码，我们会发现，sb 这个引用只会在 add 方法中使用，不可能被其它线程引用（因为是局部变量，栈私有），因此 sb 是不可能共享的资源，JVM 会自动消除 StringBuffer 对象内部的锁。



## 锁粗化 lock coarsening

```java
public String test(String str){
    int i = 0;
    StringBuffer sb = new StringBuffer():
    while(i < 100){
        sb.append(str);
        i++;
    }
    return sb.toString():
}
```

JVM 会检测到这样一连串的操作都对同一个对象加锁（while 循环内 100 次执行 append，没有锁粗化的就要进行 100  次加锁/解锁），此时 JVM 就会将加锁的范围粗化到这一连串的操作的外部（比如 while 虚幻体外），使得这一连串操作只需要加一次锁即可。



## 锁过程

偏向锁 - markword 上记录当前线程指针，下次同一个线程加锁的时候，不需要争用，只需要判断线程指针是否同一个，所以，偏向锁，偏向加锁的第一个线程 。hashCode备份在线程栈上 线程销毁，锁降级为无锁

有争用 - 锁升级为轻量级锁 - 每个线程有自己的LockRecord在自己的线程栈上，用CAS去争用markword的LR的指针，指针指向哪个线程的LR，哪个线程就拥有锁

自旋超过10次，升级为重量级锁 - 如果太多线程自旋 CPU消耗过大，不如升级为重量级锁，进入等待队列（不消耗CPU）-XX:PreBlockSpin



自旋锁在 JDK1.4.2 中引入，使用 -XX:+UseSpinning 来开启。JDK 6 中变为默认开启，并且引入了自适应的自旋锁（适应性自旋锁）。

自适应自旋锁意味着自旋的时间（次数）不再固定，而是由前一次在同一个锁上的自旋时间及锁的拥有者的状态来决定。如果在同一个锁对象上，自旋等待刚刚成功获得过锁，并且持有锁的线程正在运行中，那么虚拟机就会认为这次自旋也是很有可能再次成功，进而它将允许自旋等待持续相对更长的时间。如果对于某个锁，自旋很少成功获得过，那在以后尝试获取这个锁时将可能省略掉自旋过程，直接阻塞线程，避免浪费处理器资源。



偏向锁由于有锁撤销的过程revoke，会消耗系统资源，所以，在锁争用特别激烈的时候，用偏向锁未必效率高。还不如直接使用轻量级锁。











