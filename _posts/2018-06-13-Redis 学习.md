---
layout: post
title: "Redis 学习"
categories: [NoSql]
description:
keywords:
---

* content
{:toc}




## Redis 初识

### Redis 的特性

#### 速度快

官方称 Redis 可以达到 10W OPS, 虽然实际上不会 100% 达到 10W OPS 但是几万 OPS 还是有的, 原因有如下 3 点

* 数据存储在内存中, 内存相较于寄存器来说便宜, 相较于硬盘来说速度又快许多, 足够满足日常需求

    <img src="http://www.milky.show/images/redis/redis_58.png" alt="http://www.milky.show/images/redis/redis_58.png" style="zoom: 33%;" />

    | 类型   | 每秒读写次数 | 随机读写延迟 | 访问带宽   |
    | ------ | ------------ | ------------ | ---------- |
    | 内存   | 千万级       | 80ns         | 5GB        |
    | SSD 盘 | 35000        | 0.1-0.2ms    | 100~300MB  |
    | 机械盘 | 100 左右     | 10ms         | 100MB 左右 |

* 使用 C 语言编写

* 单线程模型

#### 持久化

Redis 所有的数据保持在内存中, 对数据的更新将异步地保存到磁盘上

#### 多种数据结构

Redis 支持 5 种经典数据结构

<img src="http://www.milky.show/images/redis/redis_59.png" alt="http://www.milky.show/images/redis/redis_59.png" style="zoom: 33%;" />

还支持其他的数据结构

* BitMaps: 位图
* HyperLogLog: 超小内存唯一值计数
* GEO: 地理信息定位

#### 支持多种编辑语言

Java, PHP, Python, Ruby, Lua, Nodejs

#### 功能丰富

发布订阅, Lua 脚本实现自定义功能, 事务, pipeline

#### 简单

最初的版本只有 23000 行代码, 源码易读, 不依赖外部, 单线程模型

#### 主从复制, 高可用, 分布式

从 Redis2.8 开始支持 Redis-Sentinel 高可用

从 Redis3.0 开始支持 Redis-Cluster 分布式



### 单线程Redis为什么这么快?

纯内存操作

单线程操作, 避免了频繁的上下文切换

基本对象使用多种底层数据结构, 且灵活变化是redis高性能的另一个原因

**采用了非阻塞I/O多路复用机制**

我们现在要仔细的说一说I/O多路复用机制, 因为这个说法实在是太通俗了, 通俗到一般人都不懂是什么意思.博主打一个比方: 小曲在S城开了一家快递店, 负责同城快送服务.小曲因为资金限制, 雇佣了一批快递员, 然后小曲发现资金不够了, 只够买一辆车送快递.

* 经营方式一

    客户每送来一份快递, 小曲就让一个快递员盯着, 然后快递员开车去送快递.慢慢的小曲就发现了这种经营方式存在下述问题

    几十个快递员基本上时间都花在了抢车上了, 大部分快递员都处在闲置状态, 谁抢到了车, 谁就能去送快递

    随着快递的增多, 快递员也越来越多, 小曲发现快递店里越来越挤, 没办法雇佣新的快递员了

    快递员之间的协调很花时间

    综合上述缺点, 小曲痛定思痛, 提出了下面的经营方式

* 经营方式二

    小曲只雇佣一个快递员.然后呢, 客户送来的快递, 小曲按送达地点标注好, 然后依次放在一个地方.最后, 那个快递员依次的去取快递, 一次拿一个, 然后开着车去送快递, 送好了就回来拿下一个快递.

    对比上述两种经营方式对比, 是不是明显觉得第二种, 效率更高, 更好呢.在上述比喻中:

每个快递员------------------>每个线程

每个快递-------------------->每个socket(I/O流)

快递的送达地点-------------->socket的不同状态

客户送快递请求-------------->来自客户端的请求

小曲的经营方式-------------->服务端运行的代码

一辆车---------------------->CPU的核数

1. 于是我们有如下结论:

    * 经营方式一就是传统的并发模型, 每个I/O流(快递)都有一个新的线程(快递员)管理.

    * 经营方式二就是I/O多路复用.只有单个线程(一个快递员), 通过跟踪每个I/O流的状态(每个快递的送达地点), 来管理多个I/O流.

    下面类比到真实的redis线程模型, 如图所示

    <img src="http://www.milky.show/images/redis/redis_1.png" alt="http://www.milky.show/images/redis/redis_1.png" style="zoom:50%;" />

### Redis 典型使用场景

缓存系统, 计数器功能, 消息队列系统, 排行榜, 社交网络, 实时系统

### Redis 单机安装

到官网下载, tar 解压缩, make&make install 安装

#### 可执行文件说明

redis-server: Redis 服务器

redis-cli: Redis 命令行客户端

redis-benchmark: Redis 性能测试工具

redis-check-aof: AOF 文件修复工具

redis-check-dump: RDB 文件检查工具

redis-sentinel: Sentinel 服务器(2.8 之后)

#### 三种启动方式

最简启动: redis-server 使用默认参数

动态参数启动: redis-server \-\-port 6380

配置文件启动: redis-server configPath

#### Redis 常用配置

daemonize: 是否是守护进程启动 no|yes

port: Redis 对外端口号, 默认 6379, 对应意大利女歌手的名字 Merz

logfile: Redis 系统日志

dir: Redis 工作目录

去除空格和注释输出 redis 配置并重定向到新的文件 `cat redis-6381.conf|grep -v "#"|grep -v "^$" > redis-6382.com`

## API 的理解和使用

### 通用命令

| **命令**        | **描述**                                                     | **用法**                                                     |      |
| --------------- | ------------------------------------------------------------ | ------------------------------------------------------------ | ---- |
| DEL             | 1. 删除给定的一个或多个key<br/>2. 不存在的Key将被忽略        | DEL key1 [key2 ...]                                          | O(1) |
| EXISTS          | 1. 检查给定 key 是否存在<br />2. 存在返回 1, 不存在返回 0, 线上可用 | EXISTS key                                                   | O(1) |
| EXPIRE          | 1. 为给定key设置生存时间, key 过期时它会被自动删除<br/>2. 对一个已经指定生存时间的 key 设置执行expire, 新的值会代替旧的值 | EXPIRE key seconds                                           | O(1) |
| EXPIREAT        | 1. 同EXPIRE, 但此命令指定的是UNIX时间戳, 单位为秒            | EXPIRE key timestamp                                         | O(1) |
| KEYS            | 1. 查找所有符合给定模式 pattern 的 key, 下面举一下例子<br/>2. KEYS \*匹配所有key<br/>3. KEYS h?llo匹配hello, hallo, hxllo等<br/>4. KEYS h*llo匹配hllo, heeeeello等<br/>5. KEYS h[ae]llo匹配hello和hallo<br/>6. 特殊符号想当做查找内容经的使用\ <br />**7. 线上禁用该命令** | KEYS pattern                                                 | O(n) |
| DBSIZE          | 计算 key 的总数, 生产可用, 内部维护了计数器                  | DBSIZE                                                       | O(1) |
| MIGRATE         | 1. 原子性地将key从当前实例传送到目标实例指定的数据库上<br/>2. 原数据库Key删除, 新数据库Key增加<br/>3. 阻塞进行迁移的两个实例, 直到迁移成功, 迁移失败, 等待超时三个之一发生 | MIGRATE host port key destination-db timeout [COPY] [REPLACE] |      |
| MOVE            | 1. 将当前数据库的key移动到给定数据库的db中<br/>2. 执行成功的条件为当前数据库有key, 给定数据库没有key | MOVE key db                                                  |      |
| PERSIST         | 1. 移除给定key的生存时间, 将key变为持久的                    | PERSIST key                                                  |      |
| RANDOMKEY       | 1. 从当前数据库随机返回且不删除一个key,                      | RANDOMKEY                                                    |      |
| RENAME          | 1. 将key改名为newkey<br/>2. 当key和newkey相同或key不存在, 报错<br/>3. newkey已存在, RENAME将覆盖旧值 | RENAME key newkey                                            |      |
| TTL             | 1. 以秒为单位, 返回给定的key剩余生存时间                     | TTL key                                                      |      |
| PTTL            | 1. 以毫秒为单位, 返回给定的key剩余生存时间                   | PTTL key                                                     |      |
| TYPE            | 1. 返回key锁存储的值的类型, string, hash, list, set, zset, none | TYPE key                                                     | O(1) |
| OBJECT ENCODING | 1. 显示数据类型的底层数据结构                                | OBJECT ENCODING key                                          |      |
| INFO MEMORY     | 1. 查看内存使用情况                                          | INFO MEMORY                                                  |      |

### 数据结构和内部编码

Redis 是基于内存的数据库, 内存相对来说还是比较贵的, 如果我们在使用数据结构时, 以时间换取空间, 可以使用一些压缩的结构比如 ziplist, 如果元素个数比较小的时候, 就可以用空间来换时间, 这就是内部编码的作用, 可以使我们的 redis 有一个更好的使用率, 我们在使用时不用关心具体内部编码的实现, 直接使用数据结构的 api 即可, 是一种面向接口编程的思想

<img src="http://www.milky.show/images/redis/redis_62.png" alt="http://www.milky.show/images/redis/redis_62.png" style="zoom: 33%;" />

### redisObject 结构体

<img src="http://www.milky.show/images/redis/redis_63.png" alt="http://www.milky.show/images/redis/redis_63.png" style="zoom: 25%;" />

### 单线程

**单线程为什么这么快**

* 纯内存
* 非阻塞 IO
* 避免线程切换和竞态消耗

**单线程要注意什么**

* 一次只运行一条命令

* 拒绝长(慢)命令, keys, flushall, flushdb, slow lua script, multi/exec, operate big value(collection)

* 其实不是单线程

    fysnc file descriptor

    close file descriptor





### 系统相关命令

| **命令**         | **描述**                                                     | **用法**                   |
| ---------------- | ------------------------------------------------------------ | -------------------------- |
| BGREWRITEAOF     | 1. 手动触发AOF重写操作, 用于减小AOF文件体积                  | BGREWRITEAOF               |
| BGSAVE           | 1. 后台异步保存当前数据库的数据到磁盘                        | BGSAVE                     |
| CLIENT KILL      | 1. 关闭地址为ip:port的客户端<br/>2. 由于Redis为单线程设计, 因此当当前命令执行完之后才会关闭客户端 | CLIENT KILL ip:port        |
| CLIENT LIST      | 1. 以可读的格式, 返回所有连接到服务器的客户端信息和统计数据  | CLIENT LIST                |
| CONFIG GET       | 1. 取得运行中的Redis服务器配置参数<br/>2. 支持*              | CONFIG GET parameter       |
| CONFIG RESETSTAT | 1. 重置INFO命令中的某些统计数据, 例如Keyspace hits, Keyspace misses等 | CONFIG RESETSTAT           |
| CONFIG REWRITE   | 1. 对**启动Redis时指定的redis.conf文件进行改写**             | CONFIG REWRITE             |
| CONFIG SET       | 1. 动态调整Redis服务器的配置而无需重启<br/>2. 修改后的配置**立即生效** | CONFIG SET parameter value |
| SELECT           | 1. 切换到指定数据库, 数据库索引index用数字指定, 以0作为起始索引值<br/>2. 默认使用0号数据库 | SELECT index               |
| DBSIZE           | 1. 返回当前数据库的Key的数量                                 | DBSIZE                     |
| DEBUG OBJECT     | 1. 这是一个调试命令, 不应当被客户端使用<br/>2. key存在时返回有关信息, key不存在时返回错误 | DEBUG OBJECT key           |
| FLUSHALL         | 1. 清空整个Redis服务器的数据<br />2. 线上禁用                | FLUSHALL                   |
| FLUSHDB          | 1. 清空当前数据库中的所有数据                                | FLUSHDB                    |
| INFO             | 1. 以一种易于解释且易于阅读的格式, 返回Redis服务器的各种信息和统计数值2. 通过给定可选参数section, 可以让命令只返回某一部分信息 | INFO [section]             |
| LASTSAVE         | 1. 返回最近一次Redis成功将数据保存到磁盘上的时间, 以UNIX时间戳格式表示 | LASTSAVE                   |
| MONITOR          | 1. 实时打印出Redis服务器接收到的命令, 调试用                 | MONITOR                    |
| SHUTDOWN         | 1. 停止所有客户端<br/>2. 如果至少有一个保存点在等待, 执行SAVE命令<br/>3. 如果AOF选项被打开, 更新AOF文件<br/>4. 关闭Redis服务器 | SHUTDOWN [SAVE\|NOSAVE]    |





### 字符串类型

实际上type=string代表value存储的是一个普通字符串, 那么对应的encoding可以是raw或者是int, 如果是int则代表实际redis内部是按数值型类存储和表示这个字符串的, 当然前提是这个字符串本身可以用数值表示, **比如"20"这样的字符串, 当遇到incr, decr等操作时会转成数值型进行计算, 此时redisObject的encoding字段为int**.如果你试图对name进行incr操作则报错.

#### 结构和命令

value 的值可是字符串, 可以是数字, 可以是 0, 1 的二进制位, 上限是 512MB, 建议 100k 以内, 适用于缓存, 计数器, 分布式锁等等

| **命令** | **描述**                                                     | **用法**                                              | 时间复杂度 |
| -------- | ------------------------------------------------------------ | ----------------------------------------------------- | :--------: |
| SET      | 1. 将字符串值 Value 关联到 Key<br/>2. Key 已关联则覆盖, 无视类型<br/>3. 原本 Key 带有生存时间 TTL, 那么 TTL 被清除 | set key value [EX seconds] [PX milliseconds] [NX\|XX] |    O(1)    |
| SETEX    | 1. 将 Value 关联到 Key<br/>2. 设置 Key 生存时间为 seconds, 单位为秒<br/>3. 如果 Key 对应的 Value 已经存在, 则覆盖旧值<br/>4. SET 同时也可以设置失效时间, 是一个原子操作, 即关联值与设置生存时间同一时间完成 | setex key seconds value                               |    O(1)    |
| SETNX    | 1. 将 Key 的值设置为Value, **当且仅当 Key 不存在**<br/>2. 若给定的 Key 已经存在 SEXNX 不做任何动作 | setnx key value                                       |    O(1)    |
| setxx    | 1. 将 Key 的值设置为 Value, **当且仅当 Key 存在**<br/>2. 若给定的 Key 不存在 SEXXX 不做任何动作 | set key value xx                                      |    O(1)    |
| GET      | 1. 返回 key 关联的字符串值<br/>2. Key 不存在返回 nil<br/>3. Key 存储的不是字符串, 返回错误, 因为 GET 只用于处理字符串 | GET key                                               |    O(1)    |
| MSET     | 1. 同时设置一个或多个 Key-Value 键值对<br/>2. 某个给定 Key 已经存在, 那么 MSET 新值会覆盖旧值<br/>3. 如果上面的覆盖不是希望的, 那么使用 MSETNX 命令, **所有 Key 都不存在才会进行覆盖**<br/>4. **MSET 是一个原子性操作**, 所有 Key 都会在同一时间被设置, 不会存在有些更新有些没更新的情况 | MSET key1 value1 [key1 value1 ...]                    |    O(n)    |
| MGET     | 1. 返回一个或多个给定 Key 对应的 Value<br/>2. 某个 Key 不存在那么这个 Key 返回 nil | MGET key1 [key2 ...]                                  |    O(n)    |
| INCR     | 1. Key 中存储的数字值 +1, 返回增加之后的值<br/>2. Key 不存在, 那么 Key 的值被初始化为 0 再执行 INCR<br/>3. 如果值包含错误类型或者字符串不能被表示为数字, 那么返回错误<br/>4. 值限制在64位有符号数字表示之内, 即-9223372036854775808~9223372036854775807 | INCR key                                              |    O(1)    |
| DECR     | 1. Key 中存储的数字值 -1<br/>2. 其余同 INCR                  | DECR key                                              |    O(1)    |
| INCRBY   | 1. 将 key 所存储的值加上增量返回增加之后的值<br/>2. 其余同 INCR | INCRBY key increment                                  |    O(1)    |
| DECRBY   | 1. 将 key 所存储的值减去减量 decrement<br/>2. 其余同 INCR    | DECRBY key decrement                                  |    O(1)    |
| APPEND   | 1. 给指定 key 的 value 追加字符串, 并返回新字符串的长度      | append key value                                      |    O(1)    |
| GETSET   | 1. 设置 key 的值, 并返回 key 旧的值                          | getset key newvalue                                   |    O(1)    |
| STRLEN   | 1. 取指定 key 的 value 的长度(注意中文)                      | strlen key                                            |    O(1)    |

#### 快速实战

记录网站每个用户个人主页的访问量

```bash
incr userid:pageview(单线程,  无竞争)
```

缓存视频的基本信息(数据源在 MySQL 中), 伪代码

```java
public VideoInfo get(long id){
	String redisKey = redisPrefix + id;
	VideoInfo videInfo = redis.get(redisKey);
	if(videoInfo == null) {
		videoInfo = mysql.get(id);
		if(videoInfo != null) {
			// 序列化
			redis.set(redisKey,  serialize(videoInfo));
		}
	}
    return videoInfo;
}
```

分布式 id 生成器, 不同的应用获取一个自增的 id, 因为 redis 单线程的, 所以不同的服务肯定获得不同的值

```bash
incr counter
```

### 哈希类型, 可以对key进行分类

#### 结构和命令

Hash是一个String类型的field和value之间的映射表, 即redis的Hash数据类型的key(hash表名称)对应的value实际的内部存储结构为一个HashMap, 因此Hash特别适合存储对象.相对于把一个对象的每个属性存储为String类型, 将整个对象存储在Hash类型中会占用更少内存.

当前HashMap的实现有两种方式: 当HashMap的成员比较少时Redis为了节省内存会采用类似一维数组的方式来紧凑存储, 而不会采用真正的HashMap结构, 这时对应的value的redisObject的encoding为zipmap, 当成员数量增大时会自动转成真正的HashMap, 此时encoding为ht.

用一个对象来存储用户信息, 商品信息, 订单信息等等.

<img src="http://www.milky.show/images/redis/redis_2.png" alt="http://www.milky.show/images/redis/redis_2.png" style="zoom:50%;" />

| **命令** | **描述**                                                     | **用法**                                    | 时间复杂度 |
| -------- | ------------------------------------------------------------ | ------------------------------------------- | ---------- |
| HSET     | 1. 将哈希表Key中的域field的值设为value<br/>2. key不存在, 一个新的Hash表被创建<br/>3. field已经存在, 旧的值被覆盖 | HSET key field value                        | O(1)       |
| HSETNX   | 1. 设置key对应的HashMap中的field的value, 如果 field 已经存在, 则失败 | hsetnx key field value                      | O(1)       |
| HGET     | 1. 返回哈希表key中给定域field的值                            | HGET key field                              | O(1)       |
| HDEL     | 1. 删除哈希表key中的一个或多个指定域<br/>2. 不存在的域将被忽略 | HDEL key filed1 [field2 ...]                | O(1)       |
| HEXISTS  | 1. 查看哈希表key中, 给定 field 是否存在, 存在返回1, 不存在返回0 | HEXISTS key field                           | O(1)       |
| HGETALL  | 1. 返回哈希表key中, 所有的域和值                             | HGETALL key                                 | O(n)       |
| HINCRBY  | 1. 为哈希表key中的域field加上增量increment<br/>2. 其余同INCR命令 | HINCRYBY key filed increment                | O(1)       |
| HLEN     | 1. 返回哈希表key中 field 的数量                              | HLEN key                                    | O(1)       |
| HMGET    | 1. 返回哈希表key中, 一个或多个给定域的值<br/>2. 如果给定的域不存在于哈希表, 那么返回一个nil值 | HMGET key field1 [field2 ...]               | O(n)       |
| HMSET    | 1. 同时将多个field-value对设置到哈希表key中<br/>2. 会覆盖哈希表中已存在的域<br/>3. key不存在, 那么一个空哈希表会被创建并执行HMSET操作 | HMSET key field1 value1 [field2 value2 ...] | O(n)       |
| HKEYS    | 1. 返回哈希表key中的所有域                                   | HKEYS key                                   | O(n)       |
| HVALS    | 1. 返回哈希表key中所有的值                                   | HVALS key                                   | O(n)       |

#### 快速实战

记录网站每个用户个人主页的访问量, 每次自增 1

```
hincrby user:1:info pageview 1
```

缓存视频的基本信息(数据源在 mysql 中)伪代码

```java
public VideoInfo get(long id) {
	String redisKey = redisPrefix + id;
	Map<String,  String> hashMap = redis.hgetAll(redisKey);
	VideoInfo videoInfo = transferMapToVideo(hashMap);
	if(videoInfo == null) {
		videoInfo = mysql.get(id);
		if(videoInfo != null) {
			redis.hmset(redisKey, transferVideoToMap(videoInfo));
		}
	}
}
```



### 列表类型, 元素有序可重复

Redis的List类型其实就是每一个元素都是String类型的**双向链表**.我们可以从链表的头部和尾部添加或者删除元素.这样的List既可以作为栈, 也可以作为队列使用.

如好友列表, 粉丝列表, 消息队列, 最新消息排行等.另外还有一个就是, 可以利用lrange命令, 做**基于redis的分页功能**, 性能极佳, 用户体验好.

![http://www.milky.show/images/redis/redis_3.png](http://www.milky.show/images/redis/redis_3.png)

#### 结构和命令

| **命令**  | **描述**                                                     | **用法**                              | 时间复杂度 |
| --------- | ------------------------------------------------------------ | ------------------------------------- | ---------- |
| LPUSH     | 1. 将一个或多个值value插入到列表key的表头<br/>2. 如果有多个value值, 那么各个value值按从左到右的顺序依次插入表头<br/>3. key不存在, 一个空列表会被创建并执行LPUSH操作<br/>4. key存在但不是列表类型, 返回错误 | LPUSH key value1 [value2 ...]         | O(1~n)     |
| LPUSHX    | 1. 将值value插入到列表key的表头, 当且key存在且为一个列表<br/>2. key不存在时, LPUSHX命令什么都不做 | LPUSHX key value1 [value2...]         | O(1~n)     |
| LPOP      | 1. 移除并返回列表key的头元素                                 | LPOP key                              | O(1)       |
| LRANGE    | 1. 返回列表key中指定区间内的元素, 区间以偏移量start和end指定<br/>2. start和end都以0位底<br/>3. 可使用负数下标, -1表示列表最后一个元素, -2表示列表倒数第二个元素, 以此类推<br/>4. start大于列表最大下标, 返回空列表<br/>5. stop大于列表最大下标, stop=列表最大下标 | LRANGE key start end(包含 end)        | O(n)       |
| LREM      | 1. 根据count的值, 移除列表中与value相等的元素<br/>2. count>0表示从头到尾搜索, 移除与value相等的元素, 数量为count<br/>3. count<0表示从从尾到头搜索, 移除与value相等的元素, 数量为count<br/>4. count=0表示移除表中所有与value相等的元素 | LREM key count value                  | O(n)       |
| LSET      | 1. 将列表key下标为index的元素值设为value<br/>2. index参数超出范围, 或对一个空列表进行LSET时, 返回错误 | LSET key index value                  | O(n)       |
| LINDEX    | 1. 返回列表key中, 下标为index的元素                          | LINDEX key index                      | O(n)       |
| LINSERT   | 1. 将值value插入列表key中, 位于pivot前面或者后面插入 value 元素<br/>2. pivot不存在于列表key时, 不执行任何操作<br/>3. key不存在, 不执行任何操作 | LINSERT key BEFORE\|AFTER pivot value | O(n)       |
| LLEN      | 1. 返回列表key的长度<br/>2. key不存在, 返回0                 | LLEN key                              | O(1)       |
| LTRIM     | 1. 对一个列表进行修剪, 让列表只返回指定区间内的元素, **不存在指定区间内的都将被移除** | LTRIM key start end                   | O(n)       |
| RPOP      | 1. 移除并返回列表key的尾元素                                 | RPOP key                              | O(1)       |
| RPOPLPUSH | 在一个原子时间内, 执行两个动作: <br/>1. 将列表source中最后一个元素弹出并返回给客户端<br/>2. 将source弹出的元素插入到列表desination, 作为destination列表的头元素 | RPOPLPUSH source destination          |            |
| RPUSH     | 1. 将一个或多个值value插入到列表key的表尾                    | RPUSH key value1 [value2 ...]         | O(1~n)     |
| RPUSHX    | 1. 将value插入到列表key的表尾, 当且仅当key存在并且是一个列表<br/>2. key不存在, RPUSHX什么都不做 | RPUSHX key value                      |            |

#### 快速实战

根据时间轴展示微博内容, 当有用户更新微博时, 将用户的 id 使用 rpush 存入 list 中, 每次 lrange 获取 id, 并根据 id 找到对应的微博内容

### 集合类型, 元素是无序的, 元素不能重复. 并集, 交集, 差集

因为set堆放的是一堆不重复值的集合.所以可以做**全局去重**的功能.为什么不用JVM自带的Set进行去重？因为我们的系统一般都是集群部署, 使用JVM自带的Set, 比较麻烦, 难道为了一个做一个全局去重, 再起一个公共服务, 太麻烦了.
另外, 就是利用交集, 并集, 差集等操作, 可以计算**共同喜好, 全部的喜好, 自己独有的喜好等功能**

Redis 集合(Set类型)是一个无序的String类型数据的集合, 类似List的一个列表, 与List不同的是Set不能有重复的数据.实际上, Set的内部是用HashMap实现的, Set只用了HashMap的key列来存储对象

**集合有取交集, 并集, 差集等操作, 因此可以求共同好友, 共同兴趣, 分类标签等**

#### 结构和命令

| **命令**    | **描述**                                                     | **用法**                              | 时间复杂度 |
| ----------- | ------------------------------------------------------------ | ------------------------------------- | ---------- |
| SADD        | 1. 将一个或多个member元素加入到key中, 已存在在集合的member将被忽略<br/>2. 假如key不存在, 则只创建一个只包含member元素做成员的集合<br/>3. 当key不是集合类型时, 将返回一个错误 | SADD key member1 [member2 ...]        | O(1)       |
| SCARD       | 1. 返回key对应的集合中的元素数量                             | SCARD key                             | O(1)       |
| SDIFF       | 1. 返回一个集合的全部成员, 该集合是第一个Key对应的集合和后面key对应的集合的差集 | SDIFF key [key ...]                   |            |
| SDIFFSTORE  | 1. 和SDIFF类似, 但结果保存到destination集合而不是简单返回结果集<br/>2.  destination如果已存在, 则覆盖 | SDIFFSTORE destionation key [key ...] |            |
| SINTER      | 1. 返回一个集合的全部成员, 该集合是所有给定集合的交集<br/>2. 不存在的key被视为空集 | SINTER key [key ...]                  |            |
| SINTERSTORE | 1. 和SINTER类似, 但结果保存早destination集合而不是简单返回结果集<br/>2. 如果destination已存在, 则覆盖<br/>3. destination可以是key本身 | SINTERSTORE destination key [key ...] |            |
| SUNION      | 1. 返回一个集合的全部成员, 该集合是所有给定集合的并集<br/>2. 不存在的key被视为空集 | SUNION key [key ...]                  |            |
| SUNIONSTORE | 1. 类似SUNION, 但结果保存到destination集合而不是简单返回结果集<br/>2. destination已存在, 覆盖旧值<br/>3. destination可以是key本身 | SUNION destination key [key ...]      |            |
| SISMEMBER   | 1. 判断member元素是否key的成员, 0表示不是, 1表示是           | SISMEMBER key member                  |            |
| SMEMBERS    | 1. 返回集合key中的所有成员<br/>2. 不存在的key被视为空集      | SMEMBERS key                          |            |
| SMOVE       | 1. 原子性地将member元素从source集合移动到destination集合<br/>2. source集合中不包含member元素, SMOVE命令不执行任何操作, 仅返回0<br/>3. destination中已包含member元素, SMOVE命令只是简单做source集合的member元素移除 | SMOVE source desination member        |            |
| SPOP        | 1. **移除**并返回集合中的一个随机元素, 如果count不指定那么随机返回一个随机元素<br/>2. count为正数且小于集合元素数量, 那么返回一个count个元素的数组且数组中的**元素各不相同**<br/>3. count为正数且大于等于集合元素数量, 那么返回整个集合<br/>4. count为负数那么命令返回一个数组, 数组中的**元素可能重复多次**, 数量为count的绝对值 | SPOP key [count]                      |            |
| SRANDMEMBER | 1. 如果count不指定, 那么返回集合中的一个随机元素<br/>2. count同上<br />3. 不会破坏集合元素 | SRANDMEMBER key [count]               |            |
| SREM        | 1. 移除集合key中的一个或多个member元素, 不存在的member将被忽略 | SREM key member1 [member2 ...]        | O(1)       |

#### 快速实战

打标签(tag), 可以方便查看标签下的用户, 也可以做交集并集查看共同标签

```
sadd user:1:tags tag1 tag2 tag5
sadd user:2:tags tag2 tag3 tag5
...
sadd user:k:tags tar1 tag2 tar4

sadd tag1:users user1 user3
sadd tag2:users user1 user2 user3
...
sadd tagk:users user1 user2
```



### 有序集合类型, 有序的set, 元素不能重复但有序

SortSet顾名思义, 是一个排好序的Set, 它在Set的基础上增加了一个顺序属性score, 这个属性在添加修改元素时可以指定, 每次指定后, SortSet会自动重新按新的值排序.

sorted set的内部使用HashMap和跳跃表(SkipList)来保证数据的存储和有序, HashMap里放的是成员到score的映射, 而跳跃表里存放的是所有的成员, 排序依据是HashMap里存的score. 

**可以做排行榜应用, 取TOP N操作.可以用来做延时任务.最后一个应用就是可以做范围查找.**

#### 结构和命令

| **命令**         | **描述**                                                     | **用法**                                                     | 时间复杂度  |
| ---------------- | ------------------------------------------------------------ | ------------------------------------------------------------ | ----------- |
| ZADD             | 1. 将一个或多个member元素及其score值加入有序集key中<br/>2. 如果member已经是有序集的成员, 那么更新member对应的score并重新插入member保证member在正确的位置上<br/>3. score可以是整数值或双精度浮点数 | ZADD key score1 member1 [[score2 member2] [score3 member3] ...] | O(logN)     |
| ZCARD            | 1. 返回有序集key的元素个数                                   | ZCARD key                                                    | O(1)        |
| ZCOUNT           | 1.  返回有序集key中, score值>=minScore且<=maxScore的成员的数量 | ZCOUNT key minScore maxScore                                 | O(logN + m) |
| ZSCORE           | 1.  返回元素的分数                                           | ZSCORE key member                                            | O(1)        |
| ZRANGE           | 1. 返回有序集key中指定区间内的成员, 成员位置按score从小到大排序<br/>2. 具有相同score值的成员按字典序排列<br/>3. 需要成员按score从大到小排列, 使用ZREVRANGE命令<br/>4. 下标参数start和end都以0为底, 也可以用负数, -1表示最后一个成员, -2表示倒数第二个成员<br/>5. 可通过WITHSCORES选项让成员和它的score值一并返回 | ZRANGE key start end [WITHSCORES]                            | O(logN + m) |
| ZREVRANGE        | 1. 返回有序集key中, 指定区间内的成员.其中成员的位置按score值递减(从大到小)来排列 | ZREVRANGE key start end                                      | O(logN + m) |
| ZRANGEBYSCORE    | 1. 返回有序集key中, 指定分数范围的元素列表                   | ZRANGEBYSCORE key minScore maxScore [WITHSCORES]             | O(logN + m) |
| ZRANK            | 1. 返回有序集key中成员member的排名, 有序集成员按score值从小到大排列<br/>2. 排名以0为底, 即score最小的成员排名为0<br/>3. ZREVRANK命令可将成员按score值从大到小排名 | ZRANK key member                                             |             |
| ZREVRANK         | 1. 得成员按score值递减(从大到小)排列的排名                   |                                                              |             |
| ZREM             | 1. 移除有序集key中的一个或多个成员, 不存在的成员将被忽略<br/>2. 当key存在但不是有序集时, 返回错误 | ZREM key member1 [member2 ...]                               |             |
| ZREMRANGEBYRANK  | 1. 移除有序集key中指定排名区间内的所有成员                   | ZREMRANGEBYRANK key start end                                | O(logN + m) |
| ZREMRANGEBYSCORE | 1. 移除有序集key中, 所有score值>=minScore且<=maxScore之间的成员 | ZREMRANGEBYSCORE key minScore maxScore                       | O(logN + m) |
| ZINCRBY          | 1. 如果key对应的zset中已经存在元素member, 则对member的score属性加指定的值 | ZINCRBY key score member                                     | O(1)        |



## Jedis 客户端

Jedis 是基于 Java 语言的 Redis 客户端

### Jedis 直连

生成一个 Jedis 对象, 这个对象负责和指定 Redis 节点通信

```java
Jedis jedis = new Jedis("127.0.0.1",  6379);
```

jedis 执行 set 操作

```java
jedis.set("hello",  "world");
```

jedis 执行 get 操作, value="world"

```java
String value = jedis.get("hello");
```

Jedis(String host, int port, int connectionTimeout, int soTimeout) 构造函数参数意义

host: Redis 节点的所在机器的 ip

port: Redis 节点的端口

connectionTimeout: 客户端连接超时

soTimeout: 客户端读写超时

### Jedis 连接池配置

初始化 Jedis 连接池, 通常来讲 JedisPool 是单例的

```java
GenericObjectPoolConfig poolConfig = new GenericObjectPoolConfig();
JedisPool jedisPool = new JedisPool(poolConfig,  "127.0.0.1",  6379);
```

**资源数配置**

| 参数名     | 含义                          | 默认值 | 使用建议 |
| ---------- | ----------------------------- | ------ | -------- |
| maxTotal   | 资源池最大连接数              | 8      |          |
| maxIdle    | 资源池允许最大空闲连接数      | 8      |          |
| minIdle    | 资源池确保最少空闲连接数      | 0      |          |
| jmxEnabled | 是否开启 jmx 监控, 可用于监控 | true   | 建议开启 |

* maxTotal

    这是一个比较难确定的参数值, 举个例子

    1. 命令平均执行时间 0.1ms = 0.001s
    2. 业务需要 50000QPS
    3. maxTotal 理论值 = 0.001 * 50000 = 50 个, 实际要偏大一些

    **业务希望 Redis 并发量**

    **客户端执行命令时间**

    **Redis 资源: 例如 nodes(应用个数) * maxTotal 是不能超过 redis 的最大连接数(config get maxclients)**

    **资源开销, 例如虽然希望控制空闲连接, 但是不希望因为连接池的频繁释放创建连接造成不必要开销**

* 适合的 maxIdle 和 minIdle

    建议 maxIdle = maxTotal, 假如 maxTotal 是 100, maxIdle 是 50, 当有第 51 个连接时, 就会使用 new Jedis 创建新的连接, 这个过程也是耗费资源的

    建议预热 minIdle, 减少第一次启动后的新连接开销



**借还参数**

| 参数名             | 含义                                                         | 默认值           | 使用建议         |
| ------------------ | ------------------------------------------------------------ | ---------------- | ---------------- |
| blockWhenExhausted | 当资源池用尽后, 调用者是否要等待. 只有当为 true 时, 下面的 maxWaitMillis 才会生效 | true             | 建议使用默认值   |
| maxWaitMillis      | 当资源池连接用尽后, 调用者的最大等待时间(单位为毫秒)         | -1: 表示永不超时 | 不建议使用默认值 |
| testOnBorrow       | 向资源池借用连接时是否做连接有效性检测(ping), 无效连接会被移除 | false            | 建议 false       |
| testOnReturn       | 向资源池归还连接时是否做连接有效性检测(ping), 无效连接会被移除 | false            | 建议 false       |



## 瑞士军刀 Redis

### 慢查询

#### 生命周期

1. 客户端发送命令
2. 排队
3. 执行命令
4. 返回结果

慢查询一般发生在第 3 阶段

客户端超时不一定慢查询, 但慢查询是客户端超时的一个因素

#### 两个配置

**慢查询是一个先进先出的队列, 队列是固定长度的, 满了之后会出队一个元素, 保存在内存中, 不会持久化**

**slowlog-max-len:** 设置队列长度

**slowlog-log-slower-than:** 慢查询阈值(单位: 微妙), 该值等于 0 记录所有命令, 小于 0 不记录任何命令, 1毫秒等于 1000 微妙

#### 配置方法

1. **默认值**

    config get slowlog-max-len=128

    config get slowlog-log-slower-than=10000

2. 修改配置文件重启(不推荐)

3. 动态配置

    config set slowlog-max-len 1000

    config set slowlog-log-slower-than 1000

#### 三个命令

slowlog get [n]: 获取 n 条慢查询队列

slowlog len: 获取慢查询队列长度

slowlog reset: 清空慢查询队列

#### 运维经验

slowlog-max-len 不要设置过小, 通常设置 1000 左右

slowlog-log-slower-than 不要设置过大, 默认 10ms, 通常设置 1ms = 1000 微秒, 根据业务 qps 来决定

理解命令生命周期, 更容易定位慢在哪里

定期持久化慢查询

### pipeline

如果我们发送 n 条命令, 那么就是 n 次网络时间 + n 次命令时间, 如果使用流水线(pipeline), 会将 n 条命令打包发送给服务端, 服务端会将 n 条结果一次返回, 消耗是 1 次网络时间 + n 次命令时间, 这就是流水线的作用, 减少网络开销

| 命令   | N 个命令操作        | 1 次 pipeline(N 个命令) |
| ------ | ------------------- | ----------------------- |
| 时间   | n 次网络 + n 次命令 | 1 次网络 + n 次命令     |
| 数据量 | 1 条命令            | n 条命令                |

#### 使用 JedisPipeline

没有 pipeline 设置 10000 个 key, 1W hset 花费 50s

```java
Jedis jedis = new Jedis("127.0.0.1",  6379);
for(int i = 0; i < 10000; i++) {
	jedis.hset("hashKey" + i,  "field" + i,  "value" + i);
}
```

**使用 pipeline 操作**, 拆分 10000 条命令, 执行 100 次, 每次执行 100 条命令, 花费 0.7s

```java
Jedis jedis = new Jedis("127.0.0.1",  6379);
for(int i = 0; i < 10000; i++) {
	Pipeline pipeline = jedis.pipelined();
	for(int j = i * 100; j < (i + 1) * 100; j++) {
		pipeline.hset("hashKey" + j,  "field" + j,  "value" + j);
	}
	pipeline.syncAndReturnAll();
}
```

#### 使用建议

注意每次 pipeline 携带数据量

pipeline 每次只能作用在一个 Redis 节点上

**注意原子性问题, 与 M 命令相比, pipeline 会将命令拆分执行, 不是原子的, 而 M 命令是原子的**

### 发布订阅

### Bitmap

Redis 可以直接操作数据的位数据

### HyperLogLog

### GEO

## Redis 持久化的取舍和选择

Redis 的所有数据都保持在内存中, 对数据的更新将异步地保存到磁盘上

持久化的方式

* 快照: 某一个时间点的备份, mysqldump, redis rdb
* 写日志: 将所有的操作都记录到日志中, 当需要恢复的时候只需要将日志中的操作从走一遍即可, mysql binlog, hbase hlog, redis aof

### RDB快照

把内存中的数据来一份一模一样的放在硬盘中, **会丢失掉最后一部分未存储的数据**, 适合大规模的数据恢复, 对数据完整性和一致性要求不高, 默认是这种方式

**Redis会单独创建(fork)一个子进程来进行持久化, 会先将数据写入到一个临时文件中, 待持久化过程结束后, 再用这个临时文件替换上次持久化的文件, 整个过程中, 主进程不进行任何IO操作, 这就确保了极高的性能**

**隐患: 若当前的进程数据量庞大, fork之后数据量 * 2, 会造成服务器压力过大, 所以超过服务器 50% 内存就会错误**

#### 触发机制

**save命令(同步):** 在 redis 客户端中执行 save 命令, 有个致命的问题是这个命令是一个阻塞操作 O(n), 不会使用 fork 子进程

**bgsave命令(异步):** 在 redis 客户端中执行 bgsave 命令, redis 会使用 fork()函数, fork 一个子进程进行备份

| 命令    | save             | bgsave                   |
| ------- | ---------------- | ------------------------ |
| IO 类型 | 同步             | 异步                     |
| 阻塞    | 是               | 是(阻塞发生在 fork 过程) |
| 复杂度  | O(n)             | O(n)                     |
| 优点    | 不会消耗额外内存 | 不阻塞客户端命令         |
| 缺点    | 阻塞客户端命令   | 需要 fork, 消耗内存      |

**自动备份:** Redis 提供了系统自动备份的功能, 需要在配置文件中进行配置, 内部使用 bgsave 方式, 缺点是不太好控制生成时机, 造成磁盘的读写有可能过多

#### 其他触发机制

全量复制: 当进行主从复制时, master 节点会进行 rdb 备份

debug reload: debug 级别的重启, 不会将内存数据清空, 也会触发 rdb

shutdown: 会执行 shutdown save, 生成 rdb 文件

#### 相关配置

| 配置                            | 说明                              | 建议                                  |
| ------------------------------- | --------------------------------- | ------------------------------------- |
| save 900 1                      | 900 秒内 1 次操作会触发备份       | 去除该条                              |
| save 300 10                     | 300 秒内 10 次操作会触发备份      | 去除该条                              |
| save 60 10000                   | 60 秒内 10000 次操作会触发备份    | 去除该条                              |
| save ""                         | 不备份                            | 采用这条                              |
| dbfilename dump.rdb             | 指定 rdb 文件的名字               | dbfilename dump-\${host}-\${port}.rdb |
| dir ./                          | 指定 rdb 文件, aof 文件的存储位置 | dir /bigdiskpath                      |
| stop-writes-on-bgsave-error yes | bgsave 错误时是否停止写入         | yes                                   |
| rdbcompression yes              | 是否采用压缩格式, 方便主从复制    | yes                                   |
| rdbchecksum yes                 | 是否对 rdb 文件进行校验           | yes                                   |

### AOF保存命令日志(Append Only File)

#### RDB 现存问题

耗时, 耗性能: O(n)数据非常耗时, fork()消耗内存, 磁盘 IO

不可控, 丢失数据

#### AOF 介绍

把**每一条**对 redis 的**写操作**命令, 保存到类似日志文件中文件采用Redis协议的格式来保存, **新命令会追加到文件末尾**, 也支持每秒同步(默认)和不同步, 在数据恢复时按照从前到后的顺序再将指令都执行一遍. 配置文件中 `appendonly yes` 开启 aof 持久化, 最大限度的保证了数据的完整性

AOF 方式的另一个好处, 我们通过一个“场景再现”来说明. 某同学在操作 redis 时, 不小心执行了 FLUSHALL, 导致 redis 内存中的数据全部被清空了, 这是很悲剧的事情.不过这也不是世界末日, 只要 redis 配置了 AOF 持久化方式, 且 AOF 文件还没有被重写(rewrite), 我们就可以用最快的速度暂停 redis 并编辑 AOF 文件, 将最后一行的 FLUSHALL 命令删除, 然后重启 redis, 就可以恢复redis 的所有数据到 FLUSHALL 之前的状态了. 是不是很神奇, 这就是 AOF 持久化方式的好处之一. 但是如果 AOF 文件已经被重写了, 那就无法通过这种方法来恢复数据了

#### AOF 三种策略

**Redis 写命令会刷新到缓冲区中**, 缓冲区会根据一定策略 fsync 到磁盘的 aof 文件中

always: 每条命令都会被 fsync 到磁盘, 有可能丢失最后一次命令, 推荐使用这种

everysec: 每秒把缓冲区 fsync 到磁盘, 有可能丢失最后一秒命令

no: 由 os 来决定什么时候进行 fsync

| 命令 | always                                      | everysec                   | no     |
| ---- | ------------------------------------------- | -------------------------- | ------ |
| 优点 | 不丢失数据                                  | 每秒一次 fsync 丢 1 秒数据 | 不用管 |
| 缺点 | IO 开销比较大, 一般的 sata 磁盘只有几百 TPS | 丢 1 秒数据                | 不可控 |

#### AOF 重写

因为采用了追加方式, 如果不做任何处理的话, AOF 文件会变得越来越大, 为此, redis  提供了AOF  文件重写(rewrite)机制, 即当 AOF文件的大小超过所设定的阈值时, redis 就会启动 AOF 文件的内容压缩, 只保留可以恢复数据的最小指令集. 举个例子或许更形象, 假如我们调用了 100 次 INCR 指令, 在 AOF 文件中就要存储 100 条指令, 但这明显是很低效的, 完全可以把这 100 条指令合并成一条SET 指令, 这就是重写机制的原理. **在进行 AOF 重写时, 仍然是采用先写临时文件, 全部完成后再替换的流程, 所以断电, 磁盘满等问题都不会影响 AOF 文件的可用性**

**命令行重写:** redis 客户端使用 bgrewriteaof 命令

**配置文件重写策略的参数设置, 自动配置**

1. 当前的 AOF 文件大小**超过**上一次重写时的 AOF 文件大小的百分之多少时, 会再次进行重写, 如果之前没有重写过, 则以启动时的 AOF 文件大小为依据

    ```
    auto-aof-rewrite-percentage 100
    ```

2. 限制了允许重写的最小 AOF 文件大小, 通常在 AOF 文件很小的时候, 即使其中有些冗余的命令也是可以忽略的

    ```
    auto-aof-rewrite-min-size 64mb
    ```

3. 统计当前 AOF 的尺寸, 单位字节

    ```
    aof_current_size
    ```

4. 统计 AOF 上次启动和重写的尺寸, 单位字节

    ```
    aof_base_size
    ```

5. 当满足如下条件时, 会自动触发 aof 重写

    `aof_current_size > auto-aof-rewrite-min-size`

    `(aof-current-size - aof_base_size)/aof_base_size > auto-aof-rewrite-percentage`

如果运气比较差, AOF 文件出现了被写坏的情况, 也不必过分担忧, redis 并不会贸然加载这个有问题的 AOF 文件, 而是报错退出.这时可以通过以下步骤来修复出错的文件: 

1. 备份被写坏的 AOF 文件
2. 运行 redis-check-aof –fix 进行修复
3. 用 diff -u 来看下两个文件的差异, 确认问题点
4. 重启 redis, 加载修复后的AOF文件

虽然优点多多, 但 AOF 方式也同样存在缺陷, 比如在同样数据规模的情况下, AOF 文件要比 RDB 文件的体积大.而且, AOF 方式的恢复速度也要慢于 RDB 方式.

#### 相关配置

| 配置                        | 说明                                                         | 建议                            |
| --------------------------- | ------------------------------------------------------------ | ------------------------------- |
| appendonly                  | 是否开启 aof 持久化                                          | 去除该条                        |
| appendfilename              | aof 文件的文件名                                             | appendonly-\${host}-${port}.aof |
| appendfsync                 | 同步策略                                                     | everysec                        |
| dir ./                      | 不备份                                                       | /bigdiskpath                    |
| no-appendfsync-on-rewrite   | 当 aof 重写时, 暂停 aof 持久化, 这样会提高性能, 但是有可能会丢失数据, no 的话相反, 具体选用哪种, 根据业务权衡 | yes                             |
| auto-aof-rewrite-percentage | 当前的AOF文件大小**超过**上一次重写时的AOF文件大小的百分之多少时, 会再次进行重写, 如果之前没有重写过, 则以启动时的AOF文件大小为依据 |                                 |
| auto-aof-rewrite-min-size   | 限制了允许重写的最小AOF文件大小, 通常在AOF文件很小的时候, 即使其中有些冗余的命令也是可以忽略的 |                                 |
| aof-load-truncated          | 遇到错误是否忽略                                             | yes                             |



### 使用建议

| 命令       | RDB    | AOF          |
| ---------- | ------ | ------------ |
| 启动优先级 | 低     | 高           |
| 体积       | 小     | 大           |
| 恢复速度   | 快     | 慢           |
| 数据安全性 | 丢数据 | 根据策略决定 |
| 轻重       | 重     | 轻           |

**如果只做缓存, 可以不使用任何持久化方式**

如果两个持久化方案同时开启, 优先采用 aof 方式, 因为 aof 保存的数据要比 rdb 完整

建议同时开启 rdb 和 aof, rdb 适合备份数据库, 因为 aof 在不断变化, 不好备份, 可以快速重启, 作为以防万一的手段

RDB 文件一旦被创建, 就不会进行任何修改. 当服务器要创建一个新的 RDB 文件时, 它先将文件的内容保存在一个临时文件里面, 当临时文件写入完毕时, 程序才使用 rename2.  原子地用临时文件替换原来的 RDB 文件.这也就是说, 无论何时, 复制 RDB 文件都是绝对安全的.创建一个定期任务(cron job), 每小时将一个 RDB 文件备份到一个文件夹, 并且每天将一个 RDB 文件备份到另一个文件夹

保证服务器有足够的内存, 做好监控(硬盘, 内存, 负载, 网络)



## Redis 企业备份方案

### 持久化配置

RBD 和 AOF 建议同时打开（Redis4.0之后支持）

RDB 做冷备，AOF 做数据恢复（数据更可靠）

RDB 采取默认配置即可，AOF 推荐采取 everysec 每秒策略

### 数据备份方案

#### 需求

我们需要定时备份rdb文件来做冷备，为什么？不是有aof和rbd了吗为什么还要单独写定时任务去备份？因为Redis的aof和rdb是仅仅有一个最新的，比如谁手贱再Redis宕机的时候执行`rm -rf aof/rdb`了，那不就GG了吗？或者rdb/aof文件损坏了等不可预期的情况。所以我们需要单独备份rdb文件以防万一。

为什么不定时备份aof而是rdb？定时备份aof没意义呀，**定时**本身就是冷备份，不是实时的，rdb文件又小恢复又快，她哪里不香？

#### 方案

写crontab定时调度脚本去做数据备份。

每小时都copy一份redis的rdb文件到一个其他目录中，这个目录里的rdb文件仅仅保留48小时内的。也就是每小时都做备份，保留2天内的rdb，只保留48个rdb。

每天0点0分copy一份redis的rdb文件到一个其他目录中，这个保留一个月的。也就是按天备份。

每天半夜找个时间将当前服务上的所有rdb备份都上传到云服务上。

#### 实现

**按小时**

每小时copy一次备份，删除48小时前的数据。

```shell
crontab -e
# 每小时都执行/usr/local/redis/copy/redis_rdb_copy_hourly.sh脚本
0 * * * * sh /usr/local/redis/copy/redis_rdb_copy_hourly.sh


# redis_rdb_copy_hourly.sh脚本的内容如下：

#!/bin/sh 
# +%Y%m%d%k == 年月日时
cur_date=`date +%Y%m%d%k`
rm -rf /usr/local/redis/rdb/$cur_date
mkdir /usr/local/redis/rdb/$cur_date
# 拷贝rdb到目录
cp /var/redis/6379/dump.rdb /usr/local/redis/rdb/$cur_date
# date -d -48hour +%Y%m%d%k == 48小时前的日期，比如今天2020060214，这个结果就是2020053114
del_date=`date -d -48hour +%Y%m%d%k`
# 删除48小时之前的目录
rm -rf /usr/local/redis/rdb/$del_date
```

**按天**

每天copy一次备份，删除一个月前的数据。

```shell
crontab -e
# 每天0点0分开始执行/usr/local/redis/copy/redis_rdb_copy_daily.sh脚本
0 0 * * * sh /usr/local/redis/copy/redis_rdb_copy_daily.sh

# redis_rdb_copy_daily.sh脚本的内容如下：

#!/bin/sh 
# 年月日
cur_date=`date +%Y%m%d`
rm -rf /usr/local/redis/rdb/$cur_date
mkdir /usr/local/redis/rdb/$cur_date
# 拷贝rdb到目录
cp /var/redis/6379/dump.rdb /usr/local/redis/rdb/$cur_date

# 获取一个月前的时间，比如今天是20200602，那么del_date就是20200502
del_date=`date -d -1month +%Y%m%d`
# 删除一个月前的数据
rm -rf /usr/local/redis/rdb/$del_date
```

**传到云**

没法演示，最终目的就是磁盘备份完上传到云，云保留多少天等策略自己看需求。

### 数据恢复方案

#### redis挂了

如果仅仅是redis进程挂了，那么直接重启redis进程即可，Redis会按照持久化配置直接基于持久化文件进行恢复数据。

如果有AOF则按照AOF，AOF和RDB一起开的话也走AOF。

#### 持久化文件丢了

如果持久化文件（rdb/aof）损坏了，或者直接丢失了。那么就要采取我们上面所做的rdb备份来进行恢复了。

**不要脑子一热想着很简单，就以为直接把rdb拖过来重启redis进程就完事了，这种想法有很多问题。慢慢道来。**

**问题一**

直接把备份的rdb扔到redis持久化目录下然后重启redis不行的原因在于：redis是按照先aof后rdb进行恢复的，所以都是开启aof的，redis启动后会重新生成新的aof文件，里面是空的。所以不会进行任何数据恢复，也就是说虽然你把rdb丢给redis了，但是redis会按照aof来恢复，而aof是redis启动的时候新生成的空文件，所以不会有任何数据进行恢复。

**问题二**

那么我们把rdb文件丢给redis后，先将redis的aof关闭再启动redis进程不就能按照rdb来进行恢复了吗？是这样的，没毛病！但是新的问题来了，我们aof肯定要开的，aof对数据保障更可靠。那什么我们按照rdb文件恢复完后再修改redis配置文件开启aof然后重启redis进程不就得了嘛？大哥…你打开aof然后重启redis，这时候redis又会生成一个空的aof文件，这时候恢复的时候又是啥数据都没了。

**因为数据是存到内存里，你重启后肯定没了，需要持久化文件来恢复。这时候aof是空的，我恢复个鸡毛啊。**



**具体方案**

我不管你是持久化文件丢了还是坏了，我都先`rm -rf *` 给他删了。

-   停止redis进程

-   删除坏掉的rdb和aof持久化文件。

-   修改配置文件关闭redis的aof持久化。

-   找到最新备份的rdb文件扔到redis的持久化目录里。（这里最新的肯定是按照小时备份的最后一个）

-   启动Redis进程

-   执行`set appendonly yes`动态打开aof持久化。

    也就是说打开aof的操作不是修改配置文件然后重启，而是先热修改让他生成aof，这次生成肯定是会带着内存中完整的数据的。然后再修改配置文件重启。

-   等aof文件生成后再修改redis配置文件打开aof。
-   重启redis进程。
-   完美收官。





## Redis 开发运维常见问题

### fork 操作

fork 操作是一个同步操作, 与内存量息息相关, 内存越大, 耗时越长, rdb 和 aof 的异步备份都需要 fork 一份子进程, 这个 fork 的过程就有可能阻塞住 redis 的主线程, 影响 qps

info 命令中有一个 latest_fork_usec 选项可以查看 fork 耗时的微秒数

如何改善 fork

* 优先使用物理机或者高效支持 fork 操作的虚拟化技术
* 控制 Redis 实例最大可用内存: maxmemory, 减少内存可以加快 fork
* 合理配置 Linux 内存分配策略: vm.overcommit_memory=1
* 降低 fork 频率: 例如放宽 AOF 重写自动触发时机, 不必要的全量复制

### 子进程开销和优化

CPU: RDB 和 AOF 文件生成, 属于 CPU 密集型, 我们部署 Redis 时, 不做 CPU 绑定, 不和 CPU 密集型的服务部署在一起

内存: fork 内存开销, copy-on-write 时会占用两份内存, 尽量不要大量写入

硬盘: AOF 和 RDB 文件写入, 可以结合 iostat, iotop 分析, 尽量将 Redis 单独部署一台服务器, 不要混用磁盘, 开启 no-appendfsync-on-rewrite=yes, 根据写入量使用 SSD 磁盘

### AOF 追加阻塞

主线程会向 AOF 缓冲区写入, 同时 AOF 会开启一个同步线程进行 AOF 同步, 主线程继续向下执行, 对比上次 fsync 的时间, 如果大于 2 秒, 阻塞主线程, 小于 2 秒, 正常执行

<img src="http://www.milky.show/images/redis/redis_64.png" alt="http://www.milky.show/images/redis/redis_64.png" style="zoom:50%;" />

如果发现 Redis 阻塞情况发生, 可以通过 Redis 日志查看是否有 AOF 阻塞: `Asynchronous AOF fsync is takine too long(disk in busy?)`, 也可以通过 top 命令查看 linux 系统的 IO 情况

这种情况一般都是磁盘 IO 太忙导致, 尽量将 Redis 单独部署一台服务器, 不要混用磁盘, 开启 `no-appendfsync-on-rewrite=yes`, 根据写入量使用 SSD 磁盘



## Redis 主从复制的原理和优化

如果单机部署 Redis 服务, 如果机器发生了故障, 虽然我们可以启动其他的服务迁移过去, 但是机器已经发生了故障, 数据就全部丢失了

Redis 的主从复制可以配置一台机器为 master 节点, 一台机器为 slave 节点, slave 节点会将 master 节点的数据根据一定策略全部拷贝一份, 达到一个备份的效果, 如果 master 节点的机器出现了故障, 那么 slave 节点就可以发挥作用了, Redis 还支持一主多从, 一份数据可以有多份备份, 还可以实现读写分离

一个 master 可以有多个 slave, 一个 slave 只能有一个 master, 数据流向是单向的, master 到 slave

### 主从复制配置

Redis 提供了两种主从复制的方式, 一种是使用 slaveof 命令, 另一种是使用配置文件进行配置, 第一次启动时建议使用配置文件, 配置文件方便集中管理, 后续有特殊修改可以使用命令的方式

#### slaveof 命令

如果我们希望 127.0.0.1:6380 成为 127.0.0.1:6379 的从节点, 就使用客户端连接到从节点的 redis 服务器执行命令, 这个命令是一个异步命令

```bash
slaveof 127.0.0.1 6379
```

如果我们需要取消 6380 的从节点, 可以执行如下命令, 但是 6380 原来同步过来的数据不会清除, 只是 6379 不在向 6380 同步数据, 需要手动清空数据, 如果 6380 节点再次执行 slaveof 命令成为其他主节点的从节点, 就会自动清空数据

```
slaveof no one
```

#### 配置文件

| 命令                           | 说明                                | 建议     |
| ------------------------------ | ----------------------------------- | -------- |
| slaveof ip port                | 将当前节点变为 ip port 节点的从节点 |          |
| slave-read-only yes            | 当前节点是不是只读的                | yes      |
| masterauth \<master-password\> | 配置主节点密码                      | 根据情况 |

info replication: 可以查看当前节点的备份信息, 节点状态等信息

### 全量复制和增量复制

#### 主从策略

主从刚刚连接的时候, 进行全量同步; 全同步结束后, 进行增量同步.当然, 如果有需要, slave 在任何时候都可以发起全量同步.redis 策略是, 无论如何, 首先会尝试进行增量同步, 如不成功, 要求从机进行全量同步.

#### 全量同步

Redis 全量复制一般发生在 Slave 初始化阶段, 这时 Slave 需要将 Master 上的所有数据都复制一份. 具体步骤如下

1. 从服务器连接主服务器, 发送 SYNC(Redis2.8 之后叫做 psync)命令, psync ?(run_id第一次不知道) -1(偏移量, 第一次是-1)
2. 从服务器接收主服务器的信息, runId, offset 保存

3. 主服务器接收到 SYNC 命名后, 主服务器 fork 一个子进程执行 BGSAVE 命令生成 RDB 文件, **并使用缓冲区(repl_back_buffer)记录此后执行的所有写命令**

4. 主服务器 BGSAVE 执行完后, 向所有从服务器发送快照文件, 并在发送期间继续记录被执行的写命令

5. 从服务器收到快照文件后丢弃所有旧数据, 载入收到的快照

6. 主服务器快照发送完毕后开始向从服务器发送缓冲区中的写命令

7. 从服务器完成对快照的载入, 开始接收命令请求, 并执行来自主服务器缓冲区的写命令

**全量复制的开销**

1. 主节点 bgsave 生成 rdb 文件的时间
2. rdb 文件网络传输时间
3. 从节点清空数据时间
4. 从节点加载 rdb 的时间
5. 可能的 aof 重写时间

#### 增量同步

Redis 增量复制是指 Slave 初始化后开始正常工作时主服务器发生的写操作同步到从服务器的过程. 增量复制的过程主要是主服务器每执行一个写命令就会向从服务器发送相同的写命令, 从服务器接收并执行收到的写命令.

### 开发运维常见问题

#### 读写分离

复制数据延迟, 这个不可避免

读到过期数据, redis 处理过期数据的三种方式是定时过期, 惰性过期, 定期过期, 在主从全量同步时, 有可能会把未过期的数据同步到从节点, 从节点读到过期数据时, 又不能处理过期数据, 因为从节点是只读的, redis3.2 已解决该问题

从节点故障, 需要手动将从节点的客户端迁移到其他节点, 后期使用 Redis Sentinel 解决

#### 主从配置不一致

maxmemory 不一致导致丢失数据

数据结构优化参数(例如 hash-max-ziplist-entries): 因为优化参数不一致, 导致内存大小不一致

#### 规避全量复制

第一次全量复制, 第一次不可避免, maxmemory 不要设置过大, 在低峰时刻进行

主节点重启(运行 id 变化)

复制挤压缓冲区不足

#### 规避复制风暴

一个 master 节点挂载了许多从节点, 当 master 节点重启后, 每个 slave 节点都需要传输一份数据, 要合理规划服务拓扑, Redis Sentinel 可解决



## Redis Sentinel

### 主从复制高可用

主从复制可以使程序的读写分离, 并且达到一个备份的效果, 但是出现故障后只能手动故障转移, 整个流程非常不方便操作, 另外是写能力和存储能力受限

假如 master 宕机了, 主从的增量同步会断掉, master 的客户端的写操作也会失败, 此时读操作还是正常的, 首先手动在一台 slave 节点执行 `slaveof no one` 命令, 让其成为 master 节点, 对其他 slave 节点执行 `slaveof host port` 命令找到新的 master, 所有的客户端都要改变 redis 地址, 整个过程虽然可以用脚本完成, 但是很复杂

### Redis Sentinel 架构

使用 Redis Sentinel 架构, Sentinel 会帮我们监控主从, 集群的信息, 客户端不在直接连接 Redis 服务, 而是连接 Sentinel 服务, 通过 Sentinel 提供给我们可用的 Redis 节点, Sentinel 是集群的, 只要保障了 Sentinel 的高可用, 就可以保证获取正确的 Redis 信息

<img src="http://www.milky.show/images/redis/redis_65.png" alt="http://www.milky.show/images/redis/redis_65.png" style="zoom:50%;" />

当主从发生了故障, 多个 sentinel 发现并确认 mster 有问题, 选举出一个 sentinel 作为领导, 这个领导选举出一个 slave 作为 master, 通知其余 slave 成为新的 master 的 slave, 通知客户端主从变化, 等待老的 master 复活成为新 master 的 slave

### 安装配置

<img src="http://www.milky.show/images/redis/redis_66.png" alt="http://www.milky.show/images/redis/redis_66.png" style="zoom:50%;" />

**Redis 主节点配置 redis-7000.conf**

```
daemonize yes
port 7000
dir "/Users/miaoqi/Documents/redis-5.0.7/data"
logfile "7000.log"
pidfile redis-7000.pid
# save 900 1
# save 300 10
# save 60 10000
stop-writes-on-bgsave-error yes
rdbcompression yes
rdbchecksum yes
dbfilename dump-7000.rdb
appendonly yes
appendfilename appendonly-7000.aof
appendfsync everysec
no-appendfsync-on-rewrite no
auto-aof-rewrite-percentage 100
auto-aof-rewrite-min-size 64mb
aof-load-truncated yes
```

**Redis 从节点配置 redis-7001.conf, redis-7002.conf**

```
daemonize yes
port 7001
dir "/Users/miaoqi/Documents/redis-5.0.7/data"
logfile "7001.log"
pidfile redis-7001.pid
# save 900 1
# save 300 10
# save 60 10000
stop-writes-on-bgsave-error yes
rdbcompression yes
rdbchecksum yes
dbfilename dump-7001.rdb
appendonly yes
appendfilename appendonly-7001.aof
appendfsync everysec
no-appendfsync-on-rewrite no
auto-aof-rewrite-percentage 100
auto-aof-rewrite-min-size 64mb
aof-load-truncated yes
slaveof 127.0.0.1 7000
```

**redis-sentinel-26379.conf, redis-sentinel-26380.conf, redis-sentinel-26381.conf 主要配置, 使用 redis-sentinel 命令启动**

```
daemonize yes
port 26379
dir "/Users/miaoqi/Documents/redis-5.0.7/data"
logfile "26379.log"
pidfile redis-26379.pid
# save 900 1
# save 300 10
# save 60 10000
stop-writes-on-bgsave-error yes
rdbcompression yes
rdbchecksum yes
dbfilename dump-26379.rdb
appendonly yes
appendfilename appendonly-26379.aof
appendfsync everysec
no-appendfsync-on-rewrite no
auto-aof-rewrite-percentage 100
auto-aof-rewrite-min-size 64mb
aof-load-truncated yes

# 2 代表至少有多少个 sentinel 发现 mymaster 有问题就进行故障转移
sentinel monitor mymaster 127.0.0.1 7000 2
# sentinel ping mymaster 多少毫秒不通就认为 mymaster 有问题
sentinel down-after-milliseconds mymaster 30000
# 选取新的 master 节点后,  旧的 slave 对新的 master 进行复制时一次复制几个节点
sentinel parallel-syncs mymaster 1
# 故障转移时间
sentinel failover-timeout mymaster 180000
```

### 客户端连接

客户端通过 masterName 获取 sentinel 集合, 选出一个可用的 sentinel 节点, 通过 sentinel 节点获取一个可用的 master 节点, 再次向 master 节点验证是否是 master 节点, 当 Redis 数据节点发生了变化, sentinel 节点会及时通知 client, 采用发布订阅方式

```java
JedisSentinelPool sentinelPool = new JedisSentinelPool(masterName, sentinelSet, poolConfig, timeout);
Jedis jedis = null;
try {
    jedis = redisSentinelPool.getResource();
    // jedis command
} catch(Exception e) {
    logger.error(e.getMessage(),  e);
} finally {
    if(jedis != null){
        jedis.close();
    }
}
```

### 故障转移原理

#### 三个定时任务

每 10 秒每个 sentinel 对 master 和 slave 执行 info

* 发现 slave 节点
* 确认主从关系

每 2 秒每个 sentinel 通过 master 节点的 cahnnel 交换信息(pub/sub)

* 通过__sentinel__:hello 频道交互
* 交互对节点的"看法"和自身信息

每 1 秒每个 sentinel 对其他 sentinel 和 redis 执行 ping

* 心跳检测, 判断失败

#### 主观下线和客观下线

```
sentinel monitor <masterName> <ip> <port> <quorum>
sentinel down-after-milliseconds <masterName> <timeout>
```

主观下线: 每个 sentinel 节点对 Redis 节点失败的"偏见", 有可能是因为网络不通导致, 所以是 sentinel 的主观

客观下线: 所有 sentinel 节点对 Redis 节点失败"达成共识"(超过 quorum 个统一), 通过 `sentinel is-master-down-by-addr` 命令询问其他 sentinel 节点达成共识

**注意:** 需要注意的是 slave 节点只需要主观下线即可, 而 master 节点需要达成客观下线, 因为 slave 节点不需要故障转移

#### 领导者选举

因为发生故障时只需要一个 sentinel 节点完成故障转移即可, 所以需要选举出一个领导者来做这件事

通过 sentinel is-master-down-by-addr 命令客观下线时都希望成为领导者

1. 每个做主观下线的 sentinel 节点向其他 sentinel 节点发送命令, 要求将它设置为领导者
2. 收到命令的 sentinel 节点如果没有同意通过其他 sentinel 节点发送的命令, 那么将同意该请求, 否则拒绝
3. 如果该 sentinel 节点发现自己的票数已经超过 sentinel 集合半数且超过 quorum, 那么它将成为领导者
4. 如果此过程有多个 sentinel 节点成为了领导者, 那么将等待一段时间重新进行选举

#### 故障转移(sentinel 领导者节点完成)

1. 从 slave 节点中选出一个"合适的"节点作为新的 master 节点
2. 对上面的 slave 节点执行 slaveof no one 命令让其成为 master 节点
3. 向剩余的 slave 节点发送命令, 让它们成为新 master 节点的 slave 节点, 复制规则和 parallel-syncs 参数有关
4. 更新对原理 master 节点配置为 slave, 并保持着对其"关注", 当其恢复后命令它去复制新的 master 节点

#### 选择"合适的"slave 节点

1. 选择 slave-priority(slave 节点优先级)最高的 slave 节点, 如果存在则返回, 不存在则继续
2. 选择复制偏移量最大的 slave 节点(复制的最完整), 㘝存在则返回, 不存在则继续
3. 选择 runId 最小的 slave 节点

### 常见开发运维问题

#### 节点下线

例如过保, CPU, 内存, 硬盘等性能不足, 服务不稳定等情况要对某台机器进行下线操作

**主节点**

`sentinel failover <masterName>`  对 sentinel 节点手动执行该命令, 可以跳过主观和客观下线进行故障转移

**从节点**

临时下线还是永久下线, 例如是否做一些清理工作, 但是要考虑读写分离的情况

**Sentinel 节点**

临时下线还是永久下线, 例如是否做一些清理工作, 但是要考虑读写分离的情况

#### 节点上线

**主节点**

sentinel failover 进行替换

**从节点**

slaveof 即可, sentinel 节点可以感知

**sentinel 节点**

参考其他 sentinel 节点直接启动即可

## Redis Cluster

* 所有的 redis 节点之间都是互联的(ping-pong 机制)

* 节点的 fail 是通过集群中超过半数的节点检测失效时才生效

* 客户端与 redis 节点直连, 不需要中间 proxy 层, 客户端不需要连接集群所有节点, 连接集群中任何一个可用节点即可

* redis-cluster 把所有的物理节点映射到[0-16383]slot 上, cluster 负责维护nodes<>slot<>value

* 单节点 fail: 所有 master 节点投票, 如果超过半数就认为节点挂掉

* 集群 fail: 集群任意 master 挂掉, 如果没有 slave 集群进入 fail 状态, 也可以理解为集群挂掉, 如果集群半数以上 master 挂掉, 无论是否有 slave, 集群都进入 fail 状态

### 呼唤集群

Redis 官方声明单节点可以达到 10 万/每秒的 ops, 但是假如我们的业务需要 100 万/每秒呢? 单台机器的内存 16~256G, 如果业务需要 500G 呢? 这时候就需要引入 Redis 集群解决上述问题了

### 数据分布

| 分布方式 | 特点                                                         | 典型产品                                                |
| -------- | ------------------------------------------------------------ | ------------------------------------------------------- |
| 哈希分布 | 数据分散度高<br />键值分布业务无关<br />无法顺序访问<br />支持批量操作 | 一致性哈希 Memcache<br />RedisCluster<br />其他缓存产品 |
| 顺序分布 | 数据分散度易倾斜<br />键值业务相关<br />可顺序访问<br />支持批量操作 | BigTable<br />HBase                                     |

#### 顺序分布

1~10 到一个分区, 11~20 到一个分区...

#### 哈希分区

##### 节点取余分区

hash(key) % nodes, 这种方法非常简单, 但是当我们添加一个节点后, 数据的存储位置就会发生变化, 可以采用多倍扩容减少数据迁移量, 也可以根据时间点选取不同的取模策略

<img src="http://www.milky.show/images/redis/redis_67.png" alt="http://www.milky.show/images/redis/redis_67.png" style="zoom:50%;" />

##### 一致性哈希分区

##### 虚拟槽分区

每个槽映射一个数据子集, 一般比节点数大, 服务端管理节点, 槽, 数据, 例如 RedisCluster, 必须将槽点和数据都分配给新增的节点才能被使用, 就不会存在丢数据的问题了

<img src="http://www.milky.show/images/redis/redis_68.png" alt="http://www.milky.show/images/redis/redis_68.png" style="zoom:50%;" />

### 集群架构

#### 节点

与普通节点相比多了如下配置

```
cluster-enabled yes
cluster-config-file nodes-${host}-${port}.conf
```

#### meet 通信

所有节点共享消息, 每 2 个槽都要进行通信

#### 指派槽

假设有 3 个节点, RedisCluster 的虚拟槽范围是 0~16383, 那么达到一个负载均衡的效果就为 A 分配 0~5460, B 分配 5461~10922, C 分配 10923~16383

对客户端来说, 首先要获取到 key 的 hash, keyhash=hash(key), 然后再根据 keyhash 获取槽, slot = keyhash%16383, RedisCluster 会根据 slot 找到对应的机器执行命令

### 搭建集群

#### 原生命令安装

1. 修改配置

    ```
    port ${port}
    daemonize yes
    dir "/Users/miaoqi/Documents/redis-5.0.7/data"
    logfile "7000.log"
    pidfile redis-7000.pid
    dbfilename dump-7000.rdb
    cluster-enabled yes
    cluster-node-timeout 15000
    cluster-config-file nodes-${host}-${port}.conf
    cluster-require-full-coverage no
    ```

2. 启动节点

    `redis-server redis-8001.conf`

    `redis-server redis-8002.conf`

    `redis-server redis-8003.conf`

    `redis-server redis-8004.conf`

    `redis-server redis-8005.conf`

    `redis-server redis-8006.conf`

3. meet 操作

    `redis-cli -h 127.0.0.1 -p 8001 cluster meet 127.0.0.1 8002`

    `redis-cli -h 127.0.0.1 -p 8001 cluster meet 127.0.0.1 8003`

    `redis-cli -h 127.0.0.1 -p 8001 cluster meet 127.0.0.1 8004`

    `redis-cli -h 127.0.0.1 -p 8001 cluster meet 127.0.0.1 8005`

    `redis-cli -h 127.0.0.1 -p 8001 cluster meet 127.0.0.1 8006`

4. 分配槽, 需要一个一个分配, 通过脚本遍历

    ```
    cluster addslots slot [slot...]
    
    redis-cli -h 127.0.0.1 -p 8001 cluster addslots {0...5461}
    redis-cli -h 127.0.0.1 -p 8002 cluster addslots {5462...10922}
    redis-cli -h 127.0.0.1 -p 8003 cluster addslots {10923...16383}
    ```

    ```shell
    sstart=$1
    end=$2
    port=$3
    for slot in `seq ${start} ${end}`
    do
        echo "slot:${slot}"
        redis-cli -p ${port} cluster addslots ${slot}
    done
    ```

    `sh addslots.sh 0 5461 8001`, `sh addslots.sh 5462 10922 8002`, `sh addslots.sh 10923 16383 8003`

5. 设置主从, 8004 拷贝 8001, 8005 拷贝 8002, 8006 拷贝 8003, 通过 cluster nodes 查看 node-id

    ```
    cluster replicate node-id
    
    redis-cli -h 127.0.0.1 -p 8004 cluster replicate ${node-id-8001}
    redis-cli -h 127.0.0.1 -p 8005 cluster replicate ${node-id-8002}
    redis-cli -h 127.0.0.1 -p 8006 cluster replicate ${node-id-8003}
    ```

6. 查看集群信息

    查看集群信息: `redis-cli -p 8001 cluster info`

    查看节点 meet 信息: `redis-cli -p 8001 cluster nodes`

    查看槽信息: `redis-cli -p 8001 cluster slots`

    集群模式连接: `redis-cli -c -p 8001 `
    
    查看 key 对应的槽是多少: `redis-cli -p 8001 cluster keyslot {key}`

#### 官方工具安装

1. 下载, 编译, 安装 ruby

    `brew install ruby`

2. 安装 rubygem redis

    `gem install redis`

3. 使用 redis-trib.rb 安装集群

    当前共 6 个节点, \-\-replicas 1 代表为每个 master 节点指定 1 个从节点, 那么 redis-trib.rb 就会认为前 3 个是 master 节点, 8004 是 8001 的从节点, 8005 是 8002 的从节点..以此类推

    `./redis-trib.rb create --replicas 1 127.0.0.1:8001 127.0.0.1:8002 127.0.0.1:8003 127.0.0.1:8004 127.0.0.1:8005 127.0.0.1:8006`

    redis5.0 变成了如下命令

    `./redis-cli --cluster create 127.0.0.1:8001 127.0.0.1:8002 127.0.0.1:8003 127.0.0.1:8004 127.0.0.1:8005 127.0.0.1:8006 --cluster-replicas 1`

    

### 集群伸缩

#### 伸缩原理

<img src="http://www.milky.show/images/redis/redis_69.png" alt="http://www.milky.show/images/redis/redis_69.png" style="zoom:50%;" />

#### 扩容集群

1. 准备新节点, redis-8007.conf, redis-8008.conf

    集群模式

    配置和其他节点统一

    启动后是孤儿节点

2. 加入集群, 为它迁移槽和数据实现扩容, 作为从节点负责故障转移

    cluster meet 127.0.0.1 8007

    cluster meet 127.0.0.1 8008

    cluster nodes 查看这两个节点已经变为集群的一员

    建议使用 redis-trib.rb add-node new_host:new_port existing_host:existing_port \-\-slave \-\-master-id

    `redis-trib.rb add-node 127.0.0.1:8007 127.0.0.1:8001`

3. 迁移槽和数据

    对目标节点发送: cluster setslot {slot} importing {sourceNodeId} 命令, 让目标节点准备导入槽的数据

    对源节点发送: cluster setslot {slot} migrating {targetNodeId} 命令, 让源节点准备迁出槽的数据

    源节点循环执行 cluster getkeysinslot {slot} {count} 命令, 每次获取 count 个属于槽的键

    在源节点上执行 migrate {targetIp} {targetPort} key 0 {timeout} 命令把指定 key 迁移

    重复执行步骤 3~4 直到槽下所有的键数据迁移到目标节点

    向洁群内所有主节点发送 cluster setslot {slot} node {targetNodeId} 命令, 通知槽分配给目标节点

    建议使用 `redis-trib.rb reshard 127.0.0.1:8001` 命令迁移槽和数据

#### 缩容集群

1. 迁移槽

    `redis-trib.rb reshard --from {sourceNodeId} --to {targetNodeId} --slots 1366 127.0.0.1:8007`

    需要执行多次将槽分别迁移到其他 master 节点

2. **忘记操作, forget 命令, 先下从节点, 再下主节点, 避免故障转移**

    `redis-trib.rb del-node 127.0.0.1:8001 {offlineNodeId} `

### 客户端路由

#### moved 重定向

<img src="http://www.milky.show/images/redis/redis_70.png" alt="http://www.milky.show/images/redis/redis_70.png" style="zoom:50%;" />

当我们向集群发送一条命令时, 如果该 key 的槽不在这个节点上, 那么就会抛出 moved 异常, 客户端需要手动重定向到对应的槽中执行命令

`cluster keyslot hello` 可以查看键所对应的槽是多少, 使用 `redis-cli -c -p 8001` 集群模式连接, 可以帮助我们自动跳转到相应的槽中

#### ask 重定向

<img src="http://www.milky.show/images/redis/redis_71.png" alt="http://www.milky.show/images/redis/redis_71.png" style="zoom:67%;" />

ask 异常发生在槽的迁移过程中, 如果发现槽在当前节点, 但是数据已经被迁移到其他节点了, 就会抛出 ask 异常

#### smart 客户端实现原理

1. 从集群中选一个可运行节点, 使用 cluster slots 初始化槽和节点映射
2. 将 cluster slots 的结果映射到本地, 为每个节点创建 JedisPool
3. 准备执行命令

<img src="http://www.milky.show/images/redis/redis_72.png" alt="http://www.milky.show/images/redis/redis_72.png" style="zoom:50%;" />

### JedisCluster客户端

#### 基本使用

内部封装了连接池

```java
Set<HostAndPort> nodeList = new HashSet<HostAndPort>();
nodeList.add(new HostAndPort(HOST1,  PORT1));
nodeList.add(new HostAndPort(HOST1,  PORT2));
nodeList.add(new HostAndPort(HOST1,  PORT3));
nodeList.add(new HostAndPort(HOST1,  PORT4));
nodeList.add(new HostAndPort(HOST1,  PORT5));
nodeList.add(new HostAndPort(HOST1,  PORT6));
JedisCluster redisCluster = new JedisCluster(nodeList,  timeout,  poolConfig);
redisCluster.command...
```

#### 使用技巧

1. 定义成单例的, 内置了所有节点的连接池, 保证资源的唯一性, 也不会资源浪费
2. 无需手动借还连接池, JedisCluster 内部已经封装好了
3. 合理设置 commons-pool

### 整合 SpringBoot

### 故障转移

RedisCluster 不需要 RedisSentinel, 因为集群自身实现了高可用, 不需要外部的辅助就可以完成故障发现与故障恢复

#### 故障发现

通过 ping/pong 消息实现故障发现, **不需要 sentinel**

##### 主观下线

某个节点认为另一个节点不可用, 属于"偏见", 不代表所有节点的认知

节点 1 中发送 ping 消息到节点 2, 如果成功回复 pong 消息, 更新与节点 2 的最后通信时间, 如果没有返回, 则断开与节点 2 的连接, 同时会有定时任务, 定时任务判断与节点 2 最后通信时间超过 node-timeout 的时间后, 就标记为 pfail 状态

##### 客观下线

当半数以上持有槽的主节点都标记某节点主观下线

通知集群内所有节点标记故障节点为客观下线

通知故障节点的从节点触发故障转移流程

#### 故障恢复

##### 资格检查

每个从节点检查与故障主节点的断线时间

超过 cluster-node-timeout * cluster-slave-validity-factor 取消资格

cluster-slave-validity-factor 默认是 10

##### 准备选举时间

偏移量更大的节点的准备时间越短, 因为偏移量越大代表数据可能越全, 越优先让该节点成为主节点

##### 选举投票

收集选票, 选票数大于 N/2 + 1, 可替换主节点

##### 替换主节点

1. 当前从节点取消复制变为主节点(slaveof no one)
2. 执行 clusterDelSlot 撤销故障主节点负责的槽, 并执行 clusterAddSlot 把这些槽分配给自己

3. 向集群广播自己的 pong 消息, 表名已经替换了故障从节点

### 开发运维常见问题

#### 集群完整性

主要是根据 `cluster-require-full-coverage` 配置默认为 yes, 如果开启该配置, 代表集群中 16384 个槽都可用, 节点故障或者正在故障转移, 整个集群就不可用了

大多数业务无法容忍某个槽发生问题导致整个集群无法使用, `cluster-require-full-coverage` 建议设置为 no

#### 带宽消耗

官方建议 1000 个节点

消息发送频率: 节点发现与其他节点最后通信时间超过 cluster-node-timeout/2 时会直接发送 ping 消息

消息数据量: slots 槽数组(2kb 空间)和整个集群 1/10 的状态数据(10 个节点状态数据约 1KB)

节点部署的机器规模: 集群分布的机器越多且每台机器酷啊分的节点数越均匀, 则集群内整体的可用带宽越高

**避免使用大集群, 大业务可以多集群**

#### Pub/Sub 广播

#### 数据倾斜

某一个节点上的数据比其他节点要多

##### 节点和槽分配不均

`redis-trib.rb info ip:port` 查看节点, 槽, 键值分布

`redis-trib.rb rebalance ip:port` 进行均衡(谨慎使用)

##### 不同槽对应键值数量差异较大

CRC16 正常情况下比较均匀

可能存在 hash_tag

cluster countkeysinslot {slot} 获取槽对应键值个数

##### 包含 bigkey

例如大字符串, 几百万的元素的 hash, set 等

从节点使用 redis-cli \-\-bigkeys 查找 bigkey

优化数据结构

##### 内存相关配置不一致

hash-max-ziplist-value, set-max-intset-entries

定期"检查"配置一致性

#### 请求倾斜

热点 key: 重要的 key 或者 bigkey

优化

* 避免 bigkey
* 热键不要用 hash_tag
* 当一致性不高时, 可以用本地缓存 + mq

#### 读写分离

只读连接: 集群模式的从节点不接收任何读写请求

* 在从节点发送读命令, 会重定向到负责槽的主节点
* readonly 命令可以读: 这是一个连接级别的命令

读写分离: 更加复杂

* 同样的问题: 复制延迟, 读取过期数据, 从节点故障
* 修改客户端: cluster slaves {nodeId}

#### 数据迁移

官方迁移工具: redis-trib.rb import

* 只能从单机迁移到集群

* 不支持在线迁移: source 需要停写
* 不支持断点续传
* 单线程迁移: 影响性能

在线迁移

* 唯品会 redis-migrate-tool
* 豌豆荚 redis-port

#### 集群 VS 单机

##### 集群限制

key 批量操作支持有限: 例如 mget, mset 必须在一个 slot

key 事务和 Lua 支持有限: 操作的 key 必须在一个节点

key 是数据分区的最小粒度: 不支持 bigkey 分区

不支持多个数据库: 集群模式下只有一个 db0

复制只支持一层: 不支持树形复制结构

##### 思考-分布式 Redis 不一定好

RedisCluster: 满足容量和性能的扩展性, 很多业务"不需要"

* 大多数时客户端性能会"降低"
* 命令无法跨节点使用mget, keys, scan, flush, sinter等
* Lua 和事务无法跨节点使用
* 客户端维护更复杂: sdk 和应用本身消耗(例如更多的连接池)

很多场景 Redis Sentinel 已经足够好



### 集群命令

* 集群(cluster)  

    CLUSTER INFO 打印集群的信息 
    CLUSTER NODES 列出集群当前已知的所有节点(node), 以及这些节点的相关信息.   

* 节点(node)  

    CLUSTER MEET \<ip> \<port> 将 ip 和 port 所指定的节点添加到集群当中, 让它成为集群的一份子. 
    CLUSTER FORGET <node_id> 从集群中移除 node_id 指定的节点. 
    CLUSTER REPLICATE <node_id> 将当前节点设置为 node_id 指定的节点的从节点. 
    CLUSTER SAVECONFIG 将节点的配置文件保存到硬盘里面.   

* 槽(slot) 
    CLUSTER ADDSLOTS \<slot> [slot ...] 将一个或多个槽(slot)指派(assign)给当前节点. 
    CLUSTER DELSLOTS \<slot> [slot ...] 移除一个或多个槽对当前节点的指派. 
    CLUSTER FLUSHSLOTS 移除指派给当前节点的所有槽, 让当前节点变成一个没有指派任何槽的节点. 
    CLUSTER SETSLOT \<slot> NODE <node_id> 将槽 slot 指派给 node_id 指定的节点, 如果槽已经指派给另一个节点, 那么先让另一个节点删除该槽>, 然后再进行指派. 
    CLUSTER SETSLOT \<slot> MIGRATING <node_id> 将本节点的槽 slot 迁移到 node_id 指定的节点中. 
    CLUSTER SETSLOT \<slot> IMPORTING <node_id> 从 node_id 指定的节点中导入槽 slot 到本节点. 
    CLUSTER SETSLOT \<slot> STABLE 取消对槽 slot 的导入(import)或者迁移(migrate).   

* 键 (key) 
    CLUSTER KEYSLOT \<key> 计算键 key 应该被放置在哪个槽上.
    CLUSTER COUNTKEYSINSLOT \<slot> 返回槽 slot 目前包含的键值对数量.
    CLUSTER GETKEYSINSLOT \<slot> \<count> 返回 count 个 slot 槽中的键. 

**这些命令是集群所独有的.执行上述命令要先登录** 



## Redis 常见问题

### 无底洞问题

2010 年, Facebook 有了 3000 个 Memcache 节点, 但是发现了一个问题, 加了一个机器后, 性能没能提升, 反而下降了, 因为在集群模式下, 批量操作会随着机器节点数的增加, 时间复杂度而增加, 批量操作的 key 会分散到不同的机器上去执行, 那么这条命令的性能就要等到最慢的那台机器返回才是真正执行完成

**如何优化**

* 命令本身优化: 例如慢查询 keys, hgetall bigkey

* 减少网络通信次数
* 降低接入成本: 例如客户端长连接/连接池, NIO 等

### 缓存穿透

缓存穿透是指查询一个根本不存在的数据, 缓存层和存储层都不会命中

缓存穿透将导致不存在的数据每次请求都要到存储层去查询, 失去了缓存保护后端存储的意义

#### 造成缓存穿透的原因

业务自身代码或者数据出现问题

一些恶意攻击, 爬虫等造成大量空命中

#### 如何发现

监控业务的响应时间, 如果业务的响应时间突然变慢, 那么有可能是大量请求打到了存储层

业务本身逻辑问题

相关指标: 总调用数, 缓存层命中数, 存储层命中数

#### 解决方法

##### 缓存空对象

空值做缓存, 再次接收到同样的查询请求时, 若命中缓存并且值为空, 就会直接返回, 不会透传到数据库, 避免缓存击穿, **即缓存层中存了更多的键, 这就需要更多的内存空间, 可以对其设置一个较短的过期时间, 让其自动清除**, 优点是实时性高, 代码维护简单. 当然, 有时恶意袭击者可以猜到我们使用了这种方案, 每次都会使用不同的参数来查询, 这就需要我们对输入的参数进行过滤, 例如, 如果我们使用ID进行查询, 则可以对ID的格式进行分析, 如果不符合产生ID的规则, 就直接拒绝, 或者在ID上放入时间信息, 根据时间信息判断ID是否合法, 或者是否是我们曾经生成的ID, 这样可以拦截一定的无效请求.

##### 布隆过滤器拦截

如果布隆过滤器认为某个键不存在, 那么就不会访问存储层, 适用于数据命中不高, 数据相对固定实时性低(通常是数据集较大)的应用场景, 代码维护较为复杂, 但是缓存空间占用少

**互斥锁**

利用互斥锁，缓存失效的时候，先去获得锁，得到锁了，再去请求数据库。没得到锁，则休眠一段时间重试。

#### 如何选择

针对于一些恶意攻击, 攻击带过来的大量 key 是不存在的, 那么我们采用第一种方案就会缓存大量不存在 key 的数据.此时我们采用第一种方案就不合适了, 我们完全可以先对使用第二种方案进行过滤掉这些 key.针对这种 key 异常多, 请求重复率比较低的数据, 我们就没有必要进行缓存, 使用第二种方案直接过滤掉.而对于空数据的 key 有限的, 重复率比较高的, 我们则可以采用第一种方式进行缓存.

### 缓存雪崩(并发)

缓存并发的问题通常发生在高并发的场景下, 当一个缓存 key 过期时, 因为访问这个缓存 key 的请求量较大, 多个请求同时发现缓存过期, 因此多个请求会同时访问数据库来查询最新数据, 并且回写缓存, 这样会造成应用和数据库的负载增加, 性能降低, 由于并发较高, 甚至会导致数据库被压死.

#### 解决方法

##### 分布式锁

使用分布式锁, 保证对于每个 key 同时只有一个线程去查询后端服务, 其他线程没有获得分布式锁的权限, 因此只需要等待即可. 这种方式将高并发的压力转移到了分布式锁, 因此对分布式锁的考验很大.

##### 本地锁

与分布式锁类似, 我们通过本地锁的方式来限制只有一个线程去数据库中查询数据, 而其他线程只需等待, 等前面的线程查询到数据后再访问缓存.但是, 这种方法只能限制一个服务节点只有一个线程去数据库中查询, 如果一个服务有多个节点, 则还会有多个数据库查询操作, 也就是说在节点数量较多的情况下并没有完全解决缓存并发的问题.

##### 软过期

软过期指对缓存中的数据设置失效时间, 就是不使用缓存服务提供的过期时间, 而是业务层在数据中存储过期时间信息, 由业务程序判断是否过期并更新, 在发现了数据即将过期时, 将缓存的时效延长, 程序可以派遣一个线程去数据库中获取最新的数据, 其他线程这时看到延长了的过期时间, 就会继续使用旧数据, 等派遣的线程获取最新数据后再更新缓存.

也可以通过异步更新服务来更新设置软过期的缓存, 这样应用层就不用关心缓存并发的问题了.

##### 设置不同的失效时间

对不同的数据使用不同的失效时间, 甚至对相同的数据, 不同的请求使用不同的失效时间, 例如, 我们要缓存 user 数据, 会对每个用户的数据设置不同的缓存过期时间, 可以定义一个基础时间, 假设10秒, 然后加上一个两秒以内的随机数, 过期时间为10～12秒, 就会避免缓存雪崩. 避免同一时间缓存全部失效

**双缓存**

缓存A和B，比如A的失效时间是20分钟，B不失效。比如从A中没读到，就去B中读，然后异步起一个线程同步到A。

### 缓存击穿

是指一个key非常热点（类似于爆款），在不停的扛着大并发，大并发集中对这一个点进行访问，当这个key在失效的瞬间，持续的大并发就穿破缓存，直接请求数据库，就像在一个屏障上凿开了一个洞。

**永久缓存**

可以将爆款的缓存失效时间设置为永久。

### Redis, MySQL双写一致性问题

最经典的缓存+数据库读写的模式, 就是 Cache Aside Pattern.读的时候, 先读缓存, 缓存没有的话, 就读数据库, 然后取出数据后放入缓存, 同时返回响应.更新的时候, 先更新数据库, 然后再删除缓存.

**为什么是删除缓存, 而不是更新缓存？**

原因很简单, 很多时候, 在复杂点的缓存场景, 缓存不单单是数据库中直接取出来的值.比如可能更新了某个表的一个字段, 然后其对应的缓存, 是需要查询另外两个表的数据并进行运算, 才能计算出缓存最新的值的.

另外更新缓存的代价有时候是很高的.是不是说, 每次修改数据库的时候, 都一定要将其对应的缓存更新一份？也许有的场景是这样, 但是对于比较复杂的缓存数据计算的场景, 就不是这样了.

如果你频繁修改一个缓存涉及的多个表, 缓存也频繁更新.但是问题在于, 这个缓存到底会不会被频繁访问到？

举个栗子, 一个缓存涉及的表的字段, 在 1 分钟内就修改了 20 次, 或者是 100 次, 那么缓存更新 20 次, 100 次; 但是这个缓存在 1 分钟内只被读取了 1 次, 有大量的冷数据.实际上, 如果你只是删除缓存的话, 那么在 1 分钟内, 这个缓存不过就重新计算一次而已, 开销大幅度降低, 用到缓存才去算缓存.

其实删除缓存, 而不是更新缓存, 就是一个 lazy 计算的思想, 不要每次都重新做复杂的计算, 不管它会不会用到, 而是让它到需要被使用的时候再重新计算.

像 mybatis, hibernate 都有懒加载思想.查询一个部门, 部门带了一个员工的 list, 没有必要说每次查询部门, 都把里面的 1000 个员工的数据也同时查出来.80% 的情况, 查这个部门, 就只是要访问这个部门的信息就可以了.先查部门, 同时要访问里面的员工, 那么这个时候只有在你要访问里面的员工的时候, 才会去数据库里面查询 1000 个员工.

#### 先更新数据库, 后更新缓存

<img src="http://www.milky.show/images/redis/redis_74.png" alt="http://www.milky.show/images/redis/redis_74.png" style="zoom: 67%;" />

由上面流程图可知道, **请求 A 更新缓存应该比请求 B 更新缓存早才对, 但是因为网络等原因, B 却比 A 更早更新了缓存.**

这就导致了**脏数据**, 因此不考虑 先更新数据库, 后更新缓存 这个更新策略.



#### 先删除缓存, 在更新数据库

<img src="http://www.milky.show/images/redis/redis_75.png" alt="http://www.milky.show/images/redis/redis_75.png" style="zoom:67%;" />

如果同时有一个**请求 A 进行更新操作, 另一个请求 B 进行查询操作**.

**就会导致不一致的情形出现**.而且, 如果不采用给缓存设置过期时间策略, 该数据永远都是脏数据.



#### 先更新数据库, 在删除缓存

因为可能存在删除缓存失败的问题, 提供一个补偿措施即可, 例如利用消息队列.

FaceBook 也是采用这种方式.

当然, 这种方式也会产生数据不一致问题.

1.  缓存刚好失效

2.  请求A查询数据库, 得一个旧值

3.  请求B将新值写入数据库

4.  请求B删除缓存

5.  请求A将查到的旧值写入缓存



#### 小结

一致性问题是分布式常见问题, 还可以再分为最终一致性和强一致性.数据库和缓存双写, 就必然会存在不一致的问题.答这个问题, 先明白一个前提.就是如果对数据有强一致性要求, 不能放缓存.我们所做的一切, 只能保证最终一致性.另外, 我们所做的方案其实从根本上来说, 只能说降低不一致发生的概率, 无法完全避免.**因此, 有强一致性要求的数据, 不能放缓存.**





### 热点 key 重建优化

#### 三个目标

减少重建缓存的次数

数据尽可能一致

减少潜在危险

#### 两个解决方法

**互斥锁(mutex key)**

```java
String get(String key) {
	String value = redis.get(key);
    if(value == null) {
        String mutexKey = "mutexKey:" + key;
        if(redis.set(mutexKey,  "1",  "ex 180",  "nx")) {
            value = db.get(key);
            redis.set(key,  value);
            redis.delete(mutexKey);
        } else {
            // 其他线程休息 50 毫秒后重试
            Thread.sleep(50);
            get(key);
        }
    }
    return value;
}
```

**永不过期**

* 缓存层面: 没有设置过期使用(没有使用 expire)
* 功能层面: 为每个 value 添加逻辑过期时间, 但发现超过逻辑过期时间后, 会使用单独的线程去构建缓存

```java
String get(final String key) {
    V v = redis.get(key);
    String value = v.getValue();
    long logicTimeout = v.getValue();
    if (logicTimeout >= System.currentTimeMillis) {
        String mutexKey = "mutexKey:" + key;
        if (redis.set(mutexKey,  "1",  "ex 180",  "nx")) {
            // 异步更新后台执行
            threadPool.execute(new Runnable(){
                public void run() {
                    String dbValue = db.get(key);
                    redis.set(key,  (dbValue,  newLoginTimeout));
                    redis.delete(keyMutex);
                }
            });
        }
    }
    return value;
}
```

|   方案   |           优点            |                       缺点                       |
| :------: | :-----------------------: | :----------------------------------------------: |
|  互斥锁  |   思路简单, 保持一致性    |          代码复杂度增加, 存在死锁的风险          |
| 永不过期 | 基本杜绝热点 key 重建问题 | 不保证一致性, 逻辑过期时间增加维护成本和内存成本 |

## Redis 常见应用

### 使用 Redis 实现分布式锁

和 Memcached 的方式类似, 利用 Redis 的 setnx 命令.此命令同样是原子性操作, 只有在 key 不存在的情况下, 才能 set 成功.(setnx 命令并不完善, 后续会介绍替代方案)

1. 加锁

    最简单的方法是使用 setnx 命令, key 是锁的唯一标识, 按业务来决定命名.比如想要给一种商品的秒杀活动加锁, 可以给 key 命名为 “lock_sale_商品ID”, 而 value 设置成什么呢？我们可以姑且设置成 1.加锁的伪代码如下:     

    ```shell
    setnx(key, 1)
    ```

    当一个线程执行 setnx 返回 1, 说明 key 原本不存在, 该线程成功得到了锁; 当一个线程执行 setnx 返回 0, 说明 key 已经存在, 该线程抢锁失败.

2. 解锁

    有加锁就得有解锁. 当得到锁的线程执行完任务, 需要释放锁, 以便其他线程可以进入.释放锁的最简单方式是执行 del 指令, 伪代码如下: 

        del(key)

    释放锁之后, 其他线程就可以继续执行setnx命令来获得锁

3. 锁超时

    锁超时是什么意思呢？如果一个得到锁的线程在执行任务的过程中挂掉, 来不及显式地释放锁, 这块资源将会永远被锁住, 别的线程再也别想进来.所以, setnx的key必须设置一个超时时间, 以保证即使没有被显式释放, 这把锁也要在一定时间后自动释放.setnx不支持超时参数, 所以需要额外的指令, 伪代码如下: 

        expire(key, 30)

    综合起来, 我们分布式锁实现的第一版伪代码如下: 

    ```java
    if(setnx(key,  1) == 1){
        expire(key,  30)
        try {
            do something ......
        } finally {
            del(key)
        }
    }
    ```

4. 第一版存在的问题

    *   setnx 和 expire 的非原子性, 当 A 线程得到了锁, 还未来得及设置超时时间就挂掉了, 会导致锁没有超时时间, 在Redis2.6.12 以上版本增加了 set(key, 1, 30, NX) 取代了 setnx

    *   del 导致误删, 假如 A 线程得到了锁, 并且设置 30 秒超时, 如果某些原因导致了 A 超过了 30 秒, 自动释放锁, B 线程获得了锁, 当 A 运行完成后, 删除了锁, 直接删除的是 B 线程的锁, 可以再 del 之前判断一下这个锁是不是自己的, 即将 value 设置成线程 id, 每次删除前判断一下是不是自己的锁, 这样实际上有并发问题

    *   还是刚才第二点所描述的场景, 虽然我们避免了线程 A 误删掉 key 的情况, 但是同一时间有 A, B 两个线程在访问代码块, 仍然是不完美的.怎么办呢？我们可以让获得锁的线程开启一个守护线程, 用来给快要过期的锁“续航”.这样就避免了 A 线程执行时间过长, 导致锁自动释放的问题, 假设锁是 30 秒, 让守护线程 29 秒时给锁续命 20 秒, 当 A 线程销毁时, 守护线程也就销毁了 

### 基于 Redis 的分布式布隆过滤器

#### 引出布隆过滤器

现有 50 亿个电话号码, 现有 10 万个电话号码, 要**快速准备**判断这些电话号码是否已经存在

1. 通过数据库查询: 实现**快速**有点难
2. 数据预放在集合中: 50 亿 * 8 字节 ~ 40GB(内存浪费或不够)
3. hyperloglog: **准确**有点难

类似的还有垃圾邮件过滤, 文字处理软件的错误单词检测, 网络爬虫重复 url 检测, Hbase行过滤

#### 布隆过滤器原理

1970年伯顿.布隆提出, 用很小的空间解决上述问题

实现原理: 一个很长的二进制向量和若干个哈希函数

参数: m 个二进制向量, n 个预备数据, k 个 hash 函数

构建布隆过滤器: n 个预备数据走一遍上面过程

判断元素存在: 走一边上面过程: 如果都是 1, 则表明存在, 反之不存在

#### 布隆过滤器的误差率

肯定存在误差: 恰好都命中了

直观因素: m/n 的比率, hash 函数的个数

#### 本地布隆过滤器

现有库: Guava

本地布隆过滤器的问题

1. 容量受限制
2. 多个应用存在多个布隆过滤器, 多个布隆过滤器之间的同步问题

#### Redis 单机布隆过滤器

基于 Redis 的位图实现

定义布隆过滤器构造函数: m, n, k, 误差概率

定义布隆过滤器操作函数: add 和 contain

封装 Redis 位图操作

开发测试样例

#### Redis 分布式布隆过滤器

多个布隆过滤器: 二次路由, 解决容量受限的问题



## Redis 开发规范

### Key 设计

可读性和可管理型: 以业务名(或数据库名)为前缀(防止 key 冲突), 用冒号分割, 比如业务名:表名:id, 如 ugc:video:1

简洁性: 保证语义的前提下, 控制 key 的长度, 当 key 较多时, 内存占用也不容忽略, 如 `user:{uid}:friends:messages:{mid}` 简化为 `u:{uid}:fr:m:{mid}`

**不要包含特殊字符: 反例, 包含空格, 换行, 单双引号以及其他转义字符**

**Redis3 embstr 测试**

| key-value 个数 | 39 字节 | 40 字节 |
| -------------- | ------- | ------- |
| 10 万          | 15.69M  | 18.75M  |
| 100 万         | 146.29M | 176.81M |
| 1000 万        | 1.47G   | 1.77G   |
| 1 亿           | 14.6G   | 17.7G   |

### Value 设计

#### 拒绝 bigkey

string 类型控制在 10KB 以内, 10240 个英文, 3413 个中文

hash, list, set, zset 元素个数不要超过 5000

redis-cli \-\-bigkeys 查看 bigkey

#### 选择合适的数据结构

实体类型(要合理控制和使用数据结构内存编码优化配置, 例如ziplist, 但也要注意节省内存和性能之间的平衡)

#### 过期设计

控制 key 的生命周期, redis不是垃圾桶

object idle time 可以找到垃圾 key-value

过期时间不宜集中: 缓存穿透和雪崩等问题

### 命令使用技巧

O(N)以上命令关注 N 的数量: hgetall, lrange, smembers, zrang, sinter 等并非不能使用, 但是需要明确 N 的值. 有遍历的需求可以使用 hscan, sscan, zscan 代替

禁用命令: 线上禁用 keys, flushall, flushdb 等, 通过 redis 的 rename 机制禁掉命令, 或者使用 scan 的方式渐进式处理

合理使用 select: redis 的多数据库较弱, 使用数字进行区分, 很多客户端支持较差, 同时多业务用多数据库实际还是单线程处理

Redis 事务功能较弱, 不建议使用: Redis 的事务功能较弱, 不支持回滚 

Redis 集群版在使用 Lua 上有特殊要求

必要情况下使用 monitor 命令时, 要注意不要长时间使用



### Java 客户端优化

避免多个应用使用一个Redis实例: 不相干的业务拆分, 公共数据做服务化.

使用带有连接池的数据库, 可以有效控制连接, 同时提高效率

高并发下建议客户端添加熔断功能(例如netflix hystrix)

设置合理的密码, 如有必要可以使用SSL加密访问

根据自身业务类型, 选好maxmemory-policy(最大内存淘汰策略), 设置好过期时间.

默认策略是volatile-lru, 即超过最大内存后, 在过期键中使用lru算法进行key的剔除, 保证不过期数据不被删除, 但是可能会出现OOM问题.

### 连接池参数优化

#### 空闲连接参数

| 序号 | 参数名                        | 含义                                                         | 默认值               | 使用建议                                                     |
| ---- | ----------------------------- | ------------------------------------------------------------ | -------------------- | ------------------------------------------------------------ |
| 1    | testWhileIdle                 | 是否开启空闲资源监测                                         | false                | true                                                         |
| 2    | timeBetweenEvictionRunsMillis | 空闲资源的监测周期(单位为毫秒)                               | -1: 不检测           | 建议设置, 周期自行选择, 也可以默认也可以使用下面 JedisPoolConfig 中的配置 |
| 3    | minEvictableIdleTimeMillis    | 资源池中资源最小空闲时间(单位为毫秒), 达到此值后空闲资源将被移除 | 1000 60 30 = 30 分钟 | 可以根据自身业务决定, 大部分默认即可, 也可以考虑使用下面 JedisPoolConfig 中的配置 |
| 4    | numTestsPerEvicationRun       | 做空闲资源监测时, 每次的采样数                               | 3                    | 可以根据自身应用连接数进行微调, 如设置-1, 就是对所有连接做控线检测 |

#### 如何预估最大连接池

maxIdle 接近 maxTotal 即可

maxTotal 考虑业务希望 Redis 并发量, 客户端执行命令时间, node(应用个数) * maxTotal 不能超过 Redis 最大连接数



### 删除bigkey

**非字符串的 bigkey, 不要使用 del 删除, 使用 hscan, sscan, zscan 方式渐进式删除, 同时要注意防止 bigkey 过期时间自动删除问题(例如一个 200 万的 zset 设置 1 小时过期, 会触发 del 操作, 造成阻塞, 而且该操作不会出现在慢查询中(latency可查)), 查找方法和删除方法**

Hash 删除: hscan + hdel

```java
public void delBigHash(String host,  int port,  String password,  String bigHashKey) {
    Jedis jedis = new Jedis(host,  port);
    if (password != null && !"".equals(password)) {
        jedis.auth(password);
    }
    ScanParams scanParams = new ScanParams().count(100);
    String cursor = "0";
    do {
        ScanResult<Entry<String,  String>> scanResult = jedis.hscan(bigHashKey,  cursor,  scanParams);
        List<Entry<String,  String>> entryList = scanResult.getResult();
        if (entryList != null && !entryList.isEmpty()) {
            for (Entry<String,  String> entry : entryList) {
                jedis.hdel(bigHashKey,  entry.getKey());
            }
        }
        cursor = scanResult.getStringCursor();
    } while (!"0".equals(cursor));

    //删除bigkey
    jedis.del(bigHashKey);
}
```

List 删除: ltrim

```java
public void delBigList(String host,  int port,  String password,  String bigListKey) {
    Jedis jedis = new Jedis(host,  port);
    if (password != null && !"".equals(password)) {
        jedis.auth(password);
    }
    long llen = jedis.llen(bigListKey);
    int counter = 0;
    int left = 100;
    while (counter < llen) {
        //每次从左侧截掉100个
        jedis.ltrim(bigListKey,  left,  llen);
        counter += left;
    }
    //最终删除key
    jedis.del(bigListKey);
}
```

Set 删除: sscan + srem

```java
public void delBigSet(String host,  int port,  String password,  String bigSetKey) {
    Jedis jedis = new Jedis(host,  port);
    if (password != null && !"".equals(password)) {
        jedis.auth(password);
    }
    ScanParams scanParams = new ScanParams().count(100);
    String cursor = "0";
    do {
        ScanResult<String> scanResult = jedis.sscan(bigSetKey,  cursor,  scanParams);
        List<String> memberList = scanResult.getResult();
        if (memberList != null && !memberList.isEmpty()) {
            for (String member : memberList) {
                jedis.srem(bigSetKey,  member);
            }
        }
        cursor = scanResult.getStringCursor();
    } while (!"0".equals(cursor));

    //删除bigkey
    jedis.del(bigSetKey);
}
```

SortedSet 删除: zscan + zrem

```java
public void delBigZset(String host,  int port,  String password,  String bigZsetKey) {
    Jedis jedis = new Jedis(host,  port);
    if (password != null && !"".equals(password)) {
        jedis.auth(password);
    }
    ScanParams scanParams = new ScanParams().count(100);
    String cursor = "0";
    do {
        ScanResult<Tuple> scanResult = jedis.zscan(bigZsetKey,  cursor,  scanParams);
        List<Tuple> tupleList = scanResult.getResult();
        if (tupleList != null && !tupleList.isEmpty()) {
            for (Tuple tuple : tupleList) {
                jedis.zrem(bigZsetKey,  tuple.getElement());
            }
        }
        cursor = scanResult.getStringCursor();
    } while (!"0".equals(cursor));

    //删除bigkey
    jedis.del(bigZsetKey);
}
```



## Redis 内存优化

### 内存消耗

#### 内存使用统计

| 属性名                  | 属性说明                                               |
| ----------------------- | ------------------------------------------------------ |
| used_memory             | Redis 分配器分配的内存量, 也就是实际存储数据的内存总量 |
| used_memory_human       | 以可读格式返回 Redis 使用的内存总量                    |
| used_memory_rss         | 从操作系统的角度, Redis 进程只用的总物理内存           |
| used_memory_peak        | 内存分配器分配的最大内存, 代表 used_memory 的历史峰值  |
| used_memory_peak_human  | 以可读的格式显示内存消耗峰值                           |
| used_memory_lua         | Lua 引擎所消耗的内存                                   |
| mem_fragmentation_ratio | used_memory_rss/used_memory 比值, 表示内存碎片率       |
| mem_allocator           | Redis 所使用的内存分配器, 默认 jemalloc                |

#### 内存消耗划分

used_memory: 自身内存, 对象内存, 缓冲内存, Lua 内存

used_memory_rss-used_memory: 内存碎片

<img src="http://www.milky.show/images/redis/redis_73.png" alt="http://www.milky.show/images/redis/redis_73.png" style="zoom: 33%;" />

输入缓冲区: 客户端发送命令, 会将命令放到输入缓冲区, 最大 1GB, 超过后会强制断开连接, 不可动态设置

输出缓冲区: 对应的配置骨子额是 `client-output-buffer-limie <class> <hard limit> <soft limit> <soft seconds>`

* \<class\>: 客户端类型, 分为三种(a)normal: 普通客户端 (b)slave: 从节点用于复制, 伪装成客户端 (c)pubsub: 发布订阅客户端

* \<hard limit\>: 如果客户端使用的输出缓冲区大于\<hard limit\>, 客户端会被立即关闭
* \<soft limit\>和\<soft seconds\>: 如果客户端使用的输出缓冲区超过了\<soft limit\>并且持续了\<soft limit\>秒, 客户端会被立即关闭

普通客户端缓冲区: `client-output-buffer-limit normal 0 0 0`, 没有限制客户端缓冲, 防止大的命令或者 monitor

slave 客户端缓冲区: `client-output-buffer-limit slave 256mb 64mb 60`, 主从延迟较高, 或者从节点过多, 建议设置较大, 从节点不要超过 2 个

pubsub 客户端: `client-output-buffer-limit pubsub 32mb 8mb 60`, 不是一个主流的使用方法

缓冲内存: 此部分内存独享, 考虑不分肤质, 默认 1MB, 可以设置更大

AOF 缓冲区: AOF 的缓冲区, 没有容量限制

### 内存管理

#### 设置内存上线

定义实例最大内存, 便于管理机器内存, 一般要预留 30%, config set maxmemory 6GB

#### 内存回收策略

删除过期键值

* 惰性删除: 访问 key -> expired ditc -> del key
* 定时删除: 每秒运行 10 次, 采样删除

超过 maxmemory 后触发响应策略, 由 maxmemory-policy 控制

* noeviction: 默认策略, 不会删除任何数据, 拒绝写入操作并返回客户端错误信息
* volatile-lru: 根据 lru 算法删除设置了超时属性(expire)的键, 直到腾出足够空间为止, 如果没有可删除的键对象, 回退到 noeviction 策略

* volatile-random: 随机删除过期键, 直到腾出足够空间为止
* volatile-ttl: 根据键值对象的 ttl 属性, 删除最近将要过期数据, 如果没有, 回退到 noeviction 策略

* allkeys-lru: 根据 lru 算法删除键, 不管数据有没有设置超时属性, 直到腾出足够空间为止
* allkeys-random: 随机删除所有键, 直到腾出足够空间为止





## Redis 的过期策略

### Redis 的 Key 过期策略

我们都知道, Redis 是 key-value 数据库, 我们可以设置 Redis 中缓存的 key 的过期时间. Redis 的过期策略就是指当 Redis 中缓存的key 过期了, Redis 如何处理.

过期策略通常有以下三种: 

- 定时过期: 每个设置过期时间的 key 都需要创建一个定时器, 到过期时间就会立即清除.该策略可以立即清除过期的数据, 对内存很友好; **但是会占用大量的CPU资源去处理过期的数据, 从而影响缓存的响应时间和吞吐量.**
- 惰性过期: 只有当访问一个 key 时, 才会判断该 key 是否已过期, 过期则清除.该策略可以最大化地节省 CPU 资源, 却对内存非常不友好. 极端情况可能出现大量的过期 key 没有再次被访问, 从而不会被清除, 占用大量内存.
- 定期过期: **Redis 默认每隔 100ms** 会随机抽取进行检查一定数量的数据库的 expires 字典中的 key, 并清除其中已过期的 key.该策略是前两者的一个折中方案.通过调整定时扫描的时间间隔和每次扫描的限定耗时, 可以在不同情况下使得 CPU 和内存资源达到最优的平衡效果.(expires 字典会保存所有设置了过期时间的 key 的过期时间数据, 其中 key 是指向键空间中的某个键的指针, value 是该键的毫秒精度的 UNIX 时间戳表示的过期时间. 键空间是指该 Redis 集群中保存的所有键)
    1. Redis配置项hz定义了serverCron任务的执行周期, 默认为10, 即CPU空闲时每秒执行10次
    2. 每次过期key清理的时间不超过CPU时间的25%, 即若hz=1, 则一次清理时间最大为250ms, 若hz=10, 则一次清理时间最大为25ms
    3. 清理时依次遍历所有的db
    4. 从db中随机取20个key, 判断是否过期, 若过期, 则逐出
    5. 若有5个以上key过期, 则重复步骤4, 否则遍历下一个db
    6. 在清理过程中, 若达到了25%CPU时间, 退出清理过程

**Redis采用的是定期删除+惰性删除策略**

* 如果定期删除没删除key.然后你也没即时去请求key, 也就是说惰性删除也没生效.这样, redis的内存会越来越高.那么就应该采用内存淘汰机制.

    在redis.conf中有一行配置

    ```
    # maxmemory-policy volatile-lru
    ```

    该配置就是配内存淘汰策略的

### Redis 的内存淘汰策略

Redis的内存淘汰策略是指在Redis的用于缓存的内存不足时, 怎么处理需要新写入且需要申请额外空间的数据. 超过 maxmemory 后触发响应策略, 由 maxmemory-policy 控制.

- noeviction(默认): 当内存不足以容纳新写入数据时, 新写入操作会报错, 读和删除可继续. **应该没人用吧**
- allkeys-lru: 当内存不足以容纳新写入数据时, 在键空间中, 移除最近最少使用的 key. **推荐使用, 目前项目在用这种**
- allkeys-random: 当内存不足以容纳新写入数据时, 在键空间中, 随机移除某个 key. **你不删最少使用 Key, 去随机删**
- volatile-lru: 当内存不足以容纳新写入数据时, 在设置了过期时间的键空间中, 移除最近最少使用的key. **这种情况一般是把redis既当缓存, 又做持久化存储的时候才用**
- volatile-random: 当内存不足以容纳新写入数据时, 在设置了过期时间的键空间中, 随机移除某个key. **依然不推荐**
- volatile-ttl: 当内存不足以容纳新写入数据时, 在设置了过期时间的键空间中, 有更早过期时间的key优先移除. **不推荐**

**如果没有设置 expire 的 key, 不满足先决条件(prerequisites); 那么 volatile-lru, volatile-random 和 volatile-ttl 策略的行为, 和 noeviction(不删除) 基本上一致.**

#### Redis LRU 近似算法

Redis 使用的是一种近似 LRU 算法: 

1. key增加最近访问时间戳字段

2. 选取一定数量的key(默认5, server.maxmemory_samples进行配置), 比较最近访问时间.按照LRU算法淘汰key.

当 Redis 执行写操作时, 发现内存超出 maxmemory, 就会执行一次 LRU 淘汰算法.

注意: maxmemory_samples的值越大, Redis的近似LRU算法就越接近于严格LRU算法(队列结构重排, 批量非热点数据缓存垃圾), 但是相应消耗也变高, 对性能有一定影响, 样本值默认为5.



## Redis 中使用密码

Redis默认配置是不需要密码认证的, 也就是说只要连接的Redis服务器的host和port正确, 就可以连接使用.这在安全性上会有一定的问题, 所以需要启用Redis的认证密码, 增加Redis服务器的安全性.

1. 修改配置文件

    Redis的配置文件默认在/etc/redis.conf, 找到如下行: 

    \#requirepass foobared

    去掉前面的注释, 并修改为所需要的密码: 

    requirepass myPassword (其中myPassword就是要设置的密码)

2. 启动redis服务

3. 登录验证

    设置Redis认证密码后, 客户端登录时需要使用-a参数输入认证密码, 不添加该参数虽然也可以登录成功, 但是没有任何操作权限.如下: 

    ```bash
    $ ./redis-cli -h 127.0.0.1 -p 6379
    127.0.0.1:6379> keys *
    (error) NOAUTH Authentication required.
    ```

    使用密码认证登录, 并验证操作权限

    ```bash
    $ ./redis-cli -h 127.0.0.1 -p 6379 -a myPassword
    127.0.0.1:6379> config get requirepass
    1) "requirepass"
    2) "myPassword"
    ```

4. 在Redis集群中使用认证密码

    如果Redis服务器, 使用了集群.除了在master中配置密码外, 也需要在slave中进行相应配置.在slave的配置文件中找到如下行, 去掉注释并修改与master相同的密码即可: 

    ```
    # masterauth master-password    
    ```



## Redis 选型

### **复杂数据结构, 选择redis更合适**

value是哈希, 列表, 集合, 有序集合这类复杂的数据结构时, 会选择redis, 因为mc无法满足这些需求.

最典型的场景, 用户订单列表, 用户消息, 帖子评论列表等.



### **持久化, 选择redis更合适**

mc无法满足持久化的需求, 只得选择redis.

但是, 这里要提醒的是, **真的使用对了redis的持久化功能么？**

千万不要把redis当作数据库用: 

* redis的定期快照不能保证数据不丢失; 

* redis的AOF会降低效率, 并且不能支持太大的数据量; 

不要期望redis做固化存储会比mysql做得好, 不同的工具做各自擅长的事情, 把redis当作数据库用, 这样的设计八成是错误的.



**缓存场景, 开启固化功能, 有什么利弊？**

如果只是缓存场景, 数据存放在数据库, 缓存在redis, 此时如果开启固化功能: 

**优点是**, redis挂了再重启, 内存里能够快速恢复热数据, 不会瞬时将压力压到数据库上, 没有一个cache预热的过程.

**缺点是**, 在redis挂了的过程中, 如果数据库中有数据的修改, 可能导致redis重启后, 数据库与redis的数据不一致.

因此, 只读场景, 或者允许一些不一致的业务场景, 可以尝试开启redis的固化功能.

### **高可用, 选择redis更合适**

redis 天然支持集群功能, 可以实现主动复制, 读写分离.

redis 官方也提供了 sentinel 集群管理工具, 能够实现主从服务监控, 故障自动转移, 这一切, 对于客户端都是透明的, 无需程序改动, 也无需人工介入.

***画外音: memcache, 要想要实现高可用, 需要进行二次开发, 例如客户端的双读双写, 或者服务端的集群同步.***

但是, 这里要提醒的是, **大部分业务场景, 缓存真的需要高可用么？**

* 缓存场景, 很多时候, 是允许cache miss

* 缓存挂了, 很多时候可以通过DB读取数据

所以, 需要认真剖析业务场景, 高可用, 是否真的是对缓存的主要需求？

***画外音: 即时通讯业务中, 用户的在线状态, 就有高可用需求.***

 

### 存储的内容比较大, 选择 redis 更合适

memcache 的 value 存储, 最大为 1 M, 如果存储的 value 很大, 只能使用 redis.

当然, redis 与 memcache 相比, 由于底层实现机制的差异, **也有一些“劣势”的情况.**



**情况一: 由于内存分配机制的差异, redis 可能导致内存碎片**

memcache 使用预分配内存池的方式管理内存, 能够省去内存分配时间.

redis 则是临时申请空间, 可能导致碎片.

从这一点上, mc 会更快一些.

 

**情况二: 由于虚拟内存使用的差异, redis 可能会刷盘影响性能**

memcache 把所有的数据存储在物理内存里.

redis 有自己的 VM 机制, 理论上能够存储比物理内存更多的数据, 当数据超量时, 会引发 swap, 把冷数据刷到磁盘上.

从这一点上, 数据量大时, mc 会更快一些.

***画外音: 新版本 redis 已经优化.***

 

**情况三: 由于网络模型的差异, redis 可能会因为 CPU 计算影响 IO 调度**

memcache 使用非阻塞 IO 复用模型, redis 也是使用非阻塞 IO 复用模型.

但由于 redis 还提供一些非 KV 存储之外的排序, 聚合功能, 在执行这些功能时, 复杂的 CPU 计算, 会阻塞整个 IO 调度.

从这一点上, 由于 redis 提供的功能较多, mc 会更快一些.

 

**情况四: 由于线程模型的差异, redis 难以利用多核特效提升性能**

memcache 使用多线程, 主线程监听, worker 子线程接受请求, 执行读写, 这个过程中, 可能存在锁冲突.

redis 使用单线程, 虽无锁冲突, 但难以利用多核的特性提升整体吞吐量.

从这一点上, mc 会快一些.



**情况五: 由于缺乏 auto-sharding, redis 只能手动水平扩展**

不管是 redis 还是 memcache, 服务端集群没有天然支持水平扩展, 需要在客户端进行分片, 这其实对调用方并不友好.如果能服务端集群能够支持水平扩展, 会更完美一些.



## SCAN 命令

**SCAN [key] cursor [MATCH pattern] [COUNT count]**

SCAN 命令及其相关的 SSCAN 命令,  HSCAN 命令和 ZSCAN 命令都用于增量地迭代(incrementally iterate)一集元素(a collection of elements):

* SCAN 命令用于迭代当前数据库中的所有数据库键.

* SSCAN 命令用于迭代集合键中的元素.

* HSCAN 命令用于迭代哈希键中的键值对.

* ZSCAN 命令用于迭代有序集合中的元素(包括元素成员和元素分值).

以上列出的四个命令都支持增量式迭代, 它们每次执行都只会返回少量元素, 所以这些命令可以用于生产环境, 而不会出现像 KEYS 命令,  SMEMBERS 命令带来的问题 —— 当 KEYS 命令被用于处理一个大的数据库时, 又或者 SMEMBERS 命令被用于处理一个大的集合键时, 它们可能会阻塞服务器达数秒之久.

不过, 增量式迭代命令也不是没有缺点的:  举个例子, 使用 SMEMBERS 命令可以返回集合键当前包含的所有元素, 但是对于 SCAN 这类增量式迭代命令来说, 因为在对键进行增量式迭代的过程中, 键可能会被修改, 所以增量式迭代命令只能对被返回的元素提供有限的保证 (offer limited guarantees about the returned elements).

**需要注意的是:**

* SSCAN 命令,  HSCAN 命令和 ZSCAN 命令的第一个参数总是一个数据库键.

* 而 SCAN 命令则不需要在第一个参数提供任何数据库键, 因为它迭代的是当前数据库中的所有数据库键.

### SCAN 命令基本用法

SCAN 命令是一个基于游标的迭代器(cursor based iterator):  SCAN 命令每次被调用之后, 都会向用户返回一个新的游标, 用户在下次迭代时需要使用这个新游标作为 SCAN 命令的游标参数, 以此来延续之前的迭代过程.

当 SCAN 命令的游标参数被设置为 0 时, 服务器将开始一次新的迭代, 而当服务器向用户返回值为 0 的游标时, 表示迭代已结束.

首先使用 `keys *` 可以看到数据库中一共有19条数据, key* 共14条, akey\* 共5条

```
127.0.0.1:6379> keys *
 1) "key13"
 2) "key7"
 3) "akey5"
 4) "key11"
 5) "key12"
 6) "key14"
 7) "key6"
 8) "key2"
 9) "akey3"
10) "key3"
11) "key9"
12) "key10"
13) "key1"
14) "akey4"
15) "key5"
16) "akey2"
17) "akey1"
18) "key4"
19) "key8"
```

使用 `scan` 命令迭代过程如下:

```
127.0.0.1:6379> scan 0
1) "30"
2)  1) "key13"
    2) "key3"
    3) "key4"
    4) "key11"
    5) "key12"
    6) "akey1"
    7) "akey5"
    8) "key1"
    9) "key2"
   10) "akey3"
127.0.0.1:6379> scan 30
1) "0"
2) 1) "key9"
   2) "key10"
   3) "key7"
   4) "key6"
   5) "key8"
   6) "key14"
   7) "akey4"
   8) "key5"
   9) "akey2"
127.0.0.1:6379>
```

在上面这个例子中, 第一次迭代使用 0 作为游标, 表示开始一次新的迭代.

第二次迭代使用的是第一次迭代时返回的游标, 也即是命令回复第一个元素的值 —— 30 .

从上面的示例可以看到, SCAN 命令的回复是一个包含两个元素的数组, 第一个数组元素是用于进行下一次迭代的新游标, 而第二个数组元素则是一个数组, 这个数组中包含了所有被迭代的元素.

在第二次调用 SCAN 命令时, 命令返回了游标 0 , 这表示迭代已经结束, 整个数据集(collection)已经被完整遍历过了.

以 0 作为游标开始一次新的迭代, 一直调用 SCAN 命令, 直到命令返回游标 0 , 我们称这个过程为一次**完整遍历**(full iteration).

### SCAN 命令的保证(guarantees)

SCAN 命令, 以及其他增量式迭代命令, 在进行完整遍历的情况下可以为用户带来以下保证:  从完整遍历开始直到完整遍历结束期间, 一直存在于数据集内的所有元素都会被完整遍历返回;  这意味着, 如果有一个元素, 它从遍历开始直到遍历结束期间都存在于被遍历的数据集当中, 那么 SCAN 命令总会在某次迭代中将这个元素返回给用户.

然而因为增量式命令仅仅使用游标来记录迭代状态, 所以这些命令带有以下缺点: 

* 同一个元素可能会被返回多次. 处理重复元素的工作交由应用程序负责, 比如说, 可以考虑将迭代返回的元素仅仅用于可以安全地重复执行多次的操作上.
* 如果一个元素是在迭代过程中被添加到数据集的, 又或者是在迭代过程中从数据集中被删除的, 那么这个元素可能会被返回, 也可能不会, 这是未定义的(undefined).

### SCAN 命令每次执行返回的元素数量

增量式迭代命令并不保证每次执行都返回某个给定数量的元素.

增量式命令甚至可能会返回零个元素, 但只要命令返回的游标不是 `0` , 应用程序就不应该将迭代视作结束.

不过命令返回的元素数量总是符合一定规则的, 在实际中: 

- 对于一个大数据集来说, 增量式迭代命令每次最多可能会返回数十个元素; 
- 而对于一个足够小的数据集来说, 如果这个数据集的底层表示为编码数据结构(encoded data structure, 适用于是小集合键, 小哈希键和小有序集合键), 那么增量迭代命令将在一次调用中返回数据集中的所有元素.

最后, 用户可以通过增量式迭代命令提供的 `COUNT` 选项来指定每次迭代返回元素的最大值.

### COUNT 选项

虽然增量式迭代命令不保证每次迭代所返回的元素数量, 但我们可以使用 `COUNT` 选项, 对命令的行为进行一定程度上的调整.

基本上, `COUNT` 选项的作用就是让用户告知迭代命令, 在每次迭代中应该从数据集里返回多少元素.

虽然 `COUNT` 选项**只是对增量式迭代命令的一种提示**(hint), 但是在大多数情况下, 这种提示都是有效的.

- `COUNT` 参数的默认值为 `10` .
- 在迭代一个足够大的, 由哈希表实现的数据库, 集合键, 哈希键或者有序集合键时, 如果用户没有使用 `MATCH` 选项, 那么命令返回的元素数量通常和 `COUNT` 选项指定的一样, 或者比 `COUNT` 选项指定的数量稍多一些.
- 在迭代一个编码为整数集合(intset, 一个只由整数值构成的小集合),  或者编码为压缩列表(ziplist, 由不同值构成的一个小哈希或者一个小有序集合)时, 增量式迭代命令通常会无视 `COUNT` 选项指定的值, 在第一次迭代就将数据集包含的所有元素都返回给用户.

### MATCH 选项

和 [*KEYS*](http://doc.redisfans.com/key/keys.html#keys) 命令一样, 增量式迭代命令也可以通过提供一个 glob 风格的模式参数, 让命令只返回和给定模式相匹配的元素, 这一点可以通过在执行增量式迭代命令时, 通过给定 `MATCH <pattern>` 参数来实现.

以下是一个使用 `MATCH` 选项进行迭代的示例:

```
127.0.0.1:6379> SCAN 0 match key* count 5
1) "26"
2) 1) "key13"
   2) "key3"
   3) "key4"
   4) "key11"
   5) "key12"
127.0.0.1:6379> SCAN 26 match key* count 5
1) "30"
2) 1) "key1"
   2) "key2"
127.0.0.1:6379> SCAN 30 match key* count 5
1) "3"
2) 1) "key9"
   2) "key10"
   3) "key7"
   4) "key6"
   5) "key8"
127.0.0.1:6379> SCAN 3 match key* count 5
1) "0"
2) 1) "key14"
   2) "key5"
```

### 并发执行多个迭代

在同一时间, 可以有任意多个客户端对同一数据集进行迭代, 客户端每次执行迭代都需要传入一个游标, 并在迭代执行之后获得一个新的游标, 而这个游标就包含了迭代的所有状态, 因此, 服务器无须为迭代记录任何状态.

### 中途停止迭代

因为迭代的所有状态都保存在游标里面, 而服务器无须为迭代保存任何状态, 所以客户端可以在中途停止一个迭代, 而无须对服务器进行任何通知.

即使有任意数量的迭代在中途停止, 也不会产生任何问题.

### 使用错误的游标进行增量式迭代

使用间断的(broken), 负数, 超出范围或者其他非正常的游标来执行增量式迭代并不会造成服务器崩溃, 但可能会让命令产生未定义的行为.

未定义行为指的是, 增量式命令对返回值所做的保证可能会不再为真.

只有两种游标是合法的: 

1. 在开始一个新的迭代时, 游标必须为 `0` .
2. 增量式迭代命令在执行之后返回的, 用于延续(continue)迭代过程的游标.

### 迭代终结的保证

增量式迭代命令所使用的算法只保证在数据集的大小有界(bounded)的情况下, 迭代才会停止, 换句话说, 如果被迭代数据集的大小不断地增长的话, 增量式迭代命令可能永远也无法完成一次完整迭代.

从直觉上可以看出, 当一个数据集不断地变大时, 想要访问这个数据集中的所有元素就需要做越来越多的工作, 能否结束一个迭代取决于用户执行迭代的速度是否比数据集增长的速度更快.



## Redis 底层结构

### RedisObject

Redis 一共有 5 大种数据类型, 但是在 Redis 中, 这几种数据类型底层是由什么数据结构构造的呢？我们可以使用`OBJECT ENCODING key`查看 5 大数据类型的**底层数据结构**

**Redis内部使用一个redisObject对象来表示所有的key和value**

redisObject主要的信息包括数据类型(type), 编码方式(encoding), 数据指针(ptr), 虚拟内存(vm)等.type代表一个value对象具体是何种数据类型(应用结构), encoding是不同数据类型在redis内部式(底层结构).

```c
typedef struct redisObject {  
  
    // 类型  
    unsigned type: 4;          

    // 编码方式  
    unsigned encoding: 4;  
  
    // 引用计数  
    int refcount;  
  
    // 指向底层实现数据结构的指针
    void *ptr
    
    // 虚拟内存和其他信息等.....
  
} robj; 
```



<img src="http://www.milky.show/images/redis/redis_4.png" alt="http://www.milky.show/images/redis/redis_4.png" style="zoom:50%;" />

5 大种数据结构对应的 type 值

| 类型常量     | 对象的名称   | type值 |
| ------------ | ------------ | ------ |
| REDIS_STRING | 字符串对象   | string |
| REDIS_LIST   | 列表对象     | list   |
| REDIS_HASH   | 哈希对象     | hash   |
| REDIS_SET    | 集合对象     | set    |
| REDIS_ZSET   | 有序集合对象 | zset   |



### Redis 底层数据结构

**Redis 一共有 8 种底层数据结构对应 redisObject 的 encoding:**

| 编码常量                  | 编码所对应的底层数据结构            |
| :------------------------ | :---------------------------------- |
| REDIS_ENCODING_INT        | long 类型的整数                     |
| REDIS_ENCODING_EMBSTR     | embstr编码的SDS(简单动态字符串对象) |
| REDIS_ENCODING_RAW        | row编码的SDS                        |
| REDIS_ENCODING_LINKEDLIST | 双端链表                            |
| REDIS_ENCODING_HT         | 字典                                |
| REDIS_ENCODING_SKIPLIST   | 跳跃表和字典                        |
| REDIS_ENCODING_INTSET     | 整数集合                            |
| REDIS_ENCODING_ZIPLIST    | 压缩列表                            |

#### 简单动态字符串(embstr, raw)

Redis 没有直接使用 C 语言传统的字符串表示(以空字符结尾的字符数组, 以下简称 C 字符串), 而是自己构建了一种名为简单动态字符串(simple dynamic string, SDS)的抽象类型, 并将 SDS 用作 Redis 的默认字符串表示.

在 Redis 里面, C 字符串只会作为字符串字面量(string literal), 用在一些无须对字符串值进行修改的地方, 比如打印日志: 

```
redisLog(REDIS_WARNING, "Redis is now ready to exit,  bye bye...");
```

当 Redis 需要的不仅仅是一个字符串字面量, 而是一个可以被修改的字符串值时, Redis 就会使用 SDS 来表示字符串值:  比如在 Redis 的数据库里面, 包含字符串值的键值对在底层都是由 SDS 实现的.

举个例子, 如果客户端执行命令: 

```
redis> SET msg "hello world"
OK
```

那么 Redis 将在数据库中创建了一个新的键值对, 其中: 

键值对的键是一个字符串对象, 对象的底层实现是一个保存着字符串 "msg" 的 SDS .
键值对的值也是一个字符串对象, 对象的底层实现是一个保存着字符串 "hello world" 的 SDS .
又比如说, 如果客户端执行命令: 

```
redis> RPUSH fruits "apple" "banana" "cherry"
(integer) 3
```

那么 Redis 将在数据库中创建一个新的键值对, 其中: 

键值对的键是一个字符串对象, 对象的底层实现是一个保存了字符串 "fruits" 的 SDS .
 键值对的值是一个列表对象, 列表对象包含了三个字符串对象, 这三个字符串对象分别由三个 SDS 实现:  第一个 SDS 保存着字符串 "apple" , 第二个 SDS 保存着字符串 "banana" , 第三个 SDS 保存着字符串 "cherry" .
 除了用来保存数据库中的字符串值之外, SDS 还被用作缓冲区(buffer):  AOF 模块中的 AOF 缓冲区, 以及客户端状态中的输入缓冲区, 都是由 SDS 实现的, 在之后介绍 AOF 持久化和客户端状态的时候, 我们会看到 SDS 在这两个模块中的应用.

**SDS 的定义:**

```c
struct sdshdr{

     //记录buf数组中已使用字节的数量
     //等于 SDS 保存字符串的长度
     int len;

     //记录 buf 数组中未使用字节的数量
     int free;

     //字节数组,  用于保存字符串
     char buf[];
}
```

<img src="http://www.milky.show/images/redis/redis_5.png" alt="http://www.milky.show/images/redis/redis_5.png" style="zoom: 50%;" />

我们看上面对于 SDS 数据类型的定义: 

- free 属性的值为 0, 表示这个 SDS 没有分配任何未使用空间.
- len 属性的值为 5, 表示这个 SDS 保存了一个五字节长的字符串.
- buf 属性是一个 char 类型的数组, 数组的前五个字节分别保存了 'R', 'e', 'd', 'i', 's' 五个字符, 而最后一个字节则保存了空字符 '\0' .

上面的定义相对于 C 语言对于字符串的定义, 多出了 len 属性以及 free 属性.为什么不使用C语言字符串实现, 而是使用 SDS呢？这样实现有什么好处？

1. **常数复杂度获取字符串长度**

    由于 len 属性的存在, 我们获取 SDS 字符串的长度只需要读取 len 属性, 时间复杂度为 O(1) .而对于 C 语言, 获取字符串的长度通常是经过遍历计数来实现的, 时间复杂度为 O(n).**通过 strlen key 命令可以获取 key 的字符串长度.**

    设置和更新 SDS 长度的工作是由 SDS 的 API 在执行时自动完成的, 使用 SDS 无须进行任何手动修改长度的工作. 

    通过使用 SDS 而不是 C 字符串, Redis 将获取字符串长度所需的复杂度从 O(N) 降低到了 O(1)  , 这确保了获取字符串长度的工作不会成为 Redis 的性能瓶颈.

    比如说, 因为字符串键在底层使用 SDS 来实现, 所以即使我们对一个非常长的字符串键反复执行 STRLEN 命令, 也不会对系统性能造成任何影响, 因为 STRLEN 命令的复杂度仅为 O(1)  .

2. **杜绝缓冲区溢出**

    除了获取字符串长度的复杂度高之外, C 字符串不记录自身长度带来的另一个问题是容易造成缓冲区溢出(buffer overflow).

    举个例子, <string.h>/strcat 函数可以将 src 字符串中的内容拼接到 dest 字符串的末尾: 

    ```c
    char *strcat(char *dest,  const char *src);
    ```

    因为 C 字符串不记录自身的长度, 所以 strcat 假定用户在执行这个函数时, 已经为 dest 分配了足够多的内存, 可以容纳 src 字符串中的所有内容, 而一旦这个假定不成立时, 就会产生缓冲区溢出.

    举个例子, 假设程序里有两个在内存中紧邻着的 C 字符串 s1 和 s2 , 其中 s1 保存了字符串 "Redis" , 而 s2 则保存了字符串 "MongoDB"

    <img src="http://www.milky.show/images/redis/redis_19.png" alt="http://www.milky.show/images/redis/redis_19.png" style="zoom: 33%;" />

    如果一个程序员决定通过执行: 

    ```C
    strcat(s1,  " Cluster");
    ```

    将 s1 的内容修改为 "Redis Cluster" , 但粗心的他却忘了在执行 strcat 之前为 s1 分配足够的空间, 那么在 strcat 函数执行之后, s1 的数据将溢出到 s2 所在的空间中, 导致 s2 保存的内容被意外地修改, 如图 2-8 所示.

    <img src="http://www.milky.show/images/redis/redis_20.png" alt="http://www.milky.show/images/redis/redis_20.png" style="zoom:33%;" />

    与 C 字符串不同, SDS 的空间分配策略完全杜绝了发生缓冲区溢出的可能性:  当 SDS API 需要对 SDS 进行修改时, API 会先检查 SDS 的空间是否满足修改所需的要求, 如果不满足的话, API 会自动将 SDS 的空间扩展至执行修改所需的大小, 然后才执行实际的修改操作, 所以使用 SDS 既不需要手动修改 SDS 的空间大小, 也不会出现前面所说的缓冲区溢出问题.

    举个例子, SDS 的 API 里面也有一个用于执行拼接操作的 sdscat 函数, 它可以将一个 C 字符串拼接到给定 SDS 所保存的字符串的后面, 但是在执行拼接操作之前, sdscat 会先检查给定 SDS 的空间是否足够, 如果不够的话, sdscat 就会先扩展 SDS 的空间, 然后才执行拼接操作.

    比如说, 如果我们执行: 

    ```c
    sdscat(s,  " Cluster");
    ```

    其中 SDS 值 s 如图 2-9 所示, 那么 sdscat 将在执行拼接操作之前检查 s 的长度是否足够, 在发现 s 目前的空间不足以拼接 " Cluster" 之后, sdscat 就会先扩展 s 的空间, 然后才执行拼接 " Cluster" 的操作, 如图所示.

    <img src="http://www.milky.show/images/redis/redis_17.png" alt="http://www.milky.show/images/redis/redis_17.png" style="zoom: 50%;" />

    <img src="http://www.milky.show/images/redis/redis_18.png" alt="http://www.milky.show/images/redis/redis_18.png" style="zoom: 33%;" />

    **sdscat 不仅对这个 SDS 进行了拼接操作, 它还为 SDS 分配了 13 字节的未使用空间, 并且拼接之后的字符串也正好是 13 字节长, 这种现象既不是 bug 也不是巧合, 它和 SDS 的空间分配策略有关.**

3. **减少修改字符串的内存重新分配次数**

    因为 C 字符串并不记录自身的长度, 所以对于一个包含了 N 个字符的 C 字符串来说, 这个 C 字符串的底层实现总是一个 N+1 个字符长的数组(额外的一个字符空间用于保存空字符).

    因为 C 字符串的长度和底层数组的长度之间存在着这种关联性, 所以每次增长或者缩短一个 C 字符串, 程序都总要对保存这个 C 字符串的数组进行一次内存重分配操作: 

    - 如果程序执行的是增长字符串的操作, 比如拼接操作(append), 那么在执行这个操作之前, 程序需要先通过内存重分配来扩展底层数组的空间大小 —— 如果忘了这一步就会产生缓冲区溢出.
    - 如果程序执行的是缩短字符串的操作, 比如截断操作(trim), 那么在执行这个操作之后, 程序需要通过内存重分配来释放字符串不再使用的那部分空间 —— 如果忘了这一步就会产生内存泄漏.

    因为内存重分配涉及复杂的算法, 并且可能需要执行系统调用, 所以它通常是一个比较耗时的操作: 

    - 在一般程序中, 如果修改字符串长度的情况不太常出现, 那么每次修改都执行一次内存重分配是可以接受的.
    - 但是 Redis 作为数据库, 经常被用于速度要求严苛, 数据被频繁修改的场合, 如果每次修改字符串的长度都需要执行一次内存重分配的话, 那么光是执行内存重分配的时间就会占去修改字符串所用时间的一大部分, 如果这种修改频繁地发生的话, 可能还会对性能造成影响.

    **而对于SDS, 由于len属性和free属性的存在, 对于修改字符串SDS实现了空间预分配和惰性空间释放两种策略: **

    - **空间预分配: **空间预分配用于优化 SDS 的字符串增长操作:  当 SDS 的 API 对一个 SDS 进行修改, 并且需要对 SDS 进行空间扩展的时候, 程序不仅会为 SDS 分配修改所必须要的空间, 还会为 SDS 分配额外的未使用空间.其中, 额外分配的未使用空间数量由以下公式决定: 

        - 如果对 SDS 进行修改之后, SDS 的长度(也即是 len 属性的值)将小于 1 MB , 那么程序分配和 len 属性同样大小的未使用空间, 这时 SDS len 属性的值将和 free 属性的值相同. 举个例子, 如果进行修改之后, SDS 的 len 将变成 13 字节, 那么程序也会分配 13 字节的未使用空间, SDS 的 buf 数组的实际长度将变成 13 + 13 + 1 = 27 字节(额外的一字节用于保存空字符).
        - 如果对 SDS 进行修改之后, SDS 的长度将大于等于 1 MB , 那么程序会分配 1 MB 的未使用空间. 举个例子, 如果进行修改之后, SDS 的 len 将变成 30 MB , 那么程序会分配 1 MB 的未使用空间, SDS 的 buf 数组的实际长度将为 30 MB + 1 MB + 1 byte.

        通过空间预分配策略, Redis 可以减少连续执行字符串增长操作所需的内存重分配次数.

    - **惰性空间释放: **对字符串进行缩短操作时, 程序不立即使用内存重新分配来回收缩短后多余的字节, 而是使用 free 属性将这些字节的数量记录下来, 等待后续使用.(当然SDS也提供了相应的API, 当我们有需要时, 也可以手动释放这些未使用的空间.)

4. **二进制安全**

    C 字符串中的字符必须符合某种编码(比如 ASCII), 并且除了字符串的末尾之外, 字符串里面不能包含空字符, 否则最先被程序读入的空字符将被误认为是字符串结尾 —— 这些限制使得 C 字符串只能保存文本数据, 而不能保存像图片, 音频, 视频, 压缩文件这样的二进制数据.

    虽然数据库一般用于保存文本数据, 但使用数据库来保存二进制数据的场景也不少见, 因此, 为了确保 Redis 可以适用于各种不同的使用场景, SDS 的 API 都是二进制安全的(binary-safe):  所有 SDS API 都会以处理二进制的方式来处理 SDS 存放在 buf 数组里的数据, 程序不会对其中的数据做任何限制, 过滤, 或者假设 —— 数据在写入时是什么样的, 它被读取时就是什么样. SDS 是以 len 属性表示的长度来判断字符串是否结束

    这也是我们将 SDS 的 buf 属性称为字节数组的原因 —— Redis 不是用这个数组来保存字符, 而是用它来保存一系列二进制数据.

5. **兼容部分 C 字符串函数**

    虽然 SDS 的 API 都是二进制安全的, 但它们一样遵循 C 字符串以空字符结尾的惯例:  这些 API 总会将 SDS 保存的数据的末尾设置为空字符, 并且总会在为 buf 数组分配空间时多分配一个字节来容纳这个空字符, 这是为了让那些保存文本数据的 SDS 可以重用一部分 <string.h> 库定义的函数.

| C 字符串                                     | SDS                                          |
| -------------------------------------------- | -------------------------------------------- |
| 获取字符串长度的复杂度为 O(N)                | 获取字符串长度的复杂度为O(1)                 |
| API 是不安全的, 可能会造成缓冲区溢出         | API 是安全的, 不会造成溢出                   |
| 修改字符串 N 次**必然**需要执行 N 次内存分配 | 修改字符串 N 次**最多**需要执行 N 次内存分配 |
| 只能保存文本数据                             | 可以保存文本或者二进制数据                   |
| 可以使用所有<string.h>库中的函数             | 可以使用一部分<string.h>库中的函数           |

**重点回顾**

- Redis 只会使用 C 字符串作为字面量, 在大多数情况下, Redis 使用 SDS (Simple Dynamic String, 简单动态字符串)作为字符串表示.
- 比起 C 字符串, SDS 具有以下优点:  
    1. 常数复杂度获取字符串长度.
    2. 杜绝缓冲区溢出.
    3. 减少修改字符串长度时所需的内存重分配次数.
    4. 二进制安全.
    5. 兼容部分 C 字符串函数.

#### 双端链表(linkedlist)

链表提供了高效的节点重排能力, 以及顺序性的节点访问方式, 并且可以通过增删节点来灵活地调整链表的长度.

作为一种常用数据结构, 链表内置在很多高级的编程语言里面, 因为 Redis 使用的 C 语言并没有内置这种数据结构, 所以 Redis 构建了自己的链表实现.

链表在 Redis 中的应用非常广泛, 比如列表键的底层实现之一就是链表:  **当一个列表键包含了数量比较多的元素, 又或者列表中包含的元素都是比较长的字符串时, Redis 就会使用链表作为列表键的底层实现**.

**链表节点定义**

```c
typedef struct listNode {

    // 前置节点
    struct listNode *prev;

    // 后置节点
    struct listNode *next;

    // 节点的值
    void *value;

} listNode;
```

**通过多个 listNode 结构就可以组成链表, 这是一个双端链表, Redis还提供了操作链表的数据结构: **

```c
typedef struct list {

    // 表头节点
    listNode *head;

    // 表尾节点
    listNode *tail;

    // 链表所包含的节点数量
    unsigned long len;

    // 节点值复制函数
    void *(*dup)(void *ptr);

    // 节点值释放函数
    void (*free)(void *ptr);

    // 节点值对比函数
    int (*match)(void *ptr,  void *key);

} list;
```

list 结构为链表提供了表头指针 head , 表尾指针 tail , 以及链表长度计数器 len , 而 dup ,  free 和 match 成员则是用于实现多态链表所需的类型特定函数: 

- dup 函数用于复制链表节点所保存的值; 
- free 函数用于释放链表节点所保存的值; 
- match 函数则用于对比链表节点所保存的值和另一个输入值是否相等.

<img src="http://www.milky.show/images/redis/redis_21.png" alt="http://www.milky.show/images/redis/redis_21.png" style="zoom: 33%;" />

Redis 的链表实现的特性可以总结如下: 

- 双端:  链表节点带有 prev 和 next 指针, 获取某个节点的前置节点和后置节点的复杂度都是 O(1)  .
- 无环:  表头节点的 prev 指针和表尾节点的 next 指针都指向 NULL , 对链表的访问以 NULL 为终点.
- 带表头指针和表尾指针:  通过 list 结构的 head 指针和 tail 指针, 程序获取链表的表头节点和表尾节点的复杂度为 O(1)  .
- 带链表长度计数器:  程序使用 list 结构的 len 属性来对 list 持有的链表节点进行计数, 程序获取链表中节点数量的复杂度为 O(1)  .
- 多态:  链表节点使用 void* 指针来保存节点值, 并且可以通过 list 结构的 dup ,  free ,  match 三个属性为节点值设置类型特定函数, 所以链表可以用于保存各种不同类型的值.

**重点回顾**

- 链表被广泛用于实现 Redis 的各种功能, 比如列表键, 发布与订阅, 慢查询, 监视器, 等等.
- 每个链表节点由一个 listNode 结构来表示, 每个节点都有一个指向前置节点和后置节点的指针, 所以 Redis 的链表实现是双端链表.
- 每个链表使用一个 list 结构来表示, 这个结构带有表头节点指针, 表尾节点指针, 以及链表长度等信息.
- 因为链表表头节点的前置节点和表尾节点的后置节点都指向 NULL , 所以 Redis 的链表实现是无环链表.
- 通过为链表设置不同的类型特定函数, Redis 的链表可以用于保存各种不同类型的值.

#### 字典(ht)

字典, 又称符号表(symbol table), 关联数组(associative array)或者映射(map), 是一种用于保存键值对(key-value pair)的抽象数据结构.

在字典中, 一个键(key)可以和一个值(value)进行关联(或者说将键映射为值), 这些关联的键和值就被称为键值对.

字典中的每个键都是独一无二的, 程序可以在字典中根据键查找与之关联的值, 或者通过键来更新值, 又或者根据键来删除整个键值对, 等等.

字典经常作为一种数据结构内置在很多高级编程语言里面, 但 Redis 所使用的 C 语言并没有内置这种数据结构, 因此 Redis 构建了自己的字典实现.

字典在 Redis 中的应用相当广泛, 比如 Redis 的数据库就是使用字典来作为底层实现的, 对数据库的增, 删, 查, 改操作也是构建在对字典的操作之上的.

举个例子, 当我们执行命令

```
redis> SET msg "hello world"
OK
```

在数据库中创建一个键为 "msg" , 值为 "hello world" 的键值对时, 这个键值对就是保存在代表数据库的字典里面的.

除了用来表示数据库之外, 字典还是哈希键的底层实现之一:  当一个哈希键包含的键值对比较多, 又或者键值对中的元素都是比较长的字符串时, Redis 就会使用字典作为哈希键的底层实现.

**哈希表结构定义:**

```c
typedef struct dictht{

     // 哈希表数组
     dictEntry **table;

     // 哈希表大小
     unsigned long size;

     // 哈希表大小掩码,  用于计算索引值
     // 总是等于 size-1
     unsigned long sizemask;

     // 该哈希表已有节点的数量
     unsigned long used;

} dictht
```

**table** 属性是一个数组, 数组中的每个元素都是一个指向 dict.h/dictEntry 结构的指针, 每个 dictEntry 结构保存着一个键值对.

**size** 属性记录了哈希表的大小, 也即是 table 数组的大小, 而 used 属性则记录了哈希表目前已有节点(键值对)的数量.

**sizemask** 属性的值总是等于 size - 1 , 这个属性和哈希值一起决定一个键应该被放到 table 数组的哪个索引上面.

<img src="http://www.milky.show/images/redis/redis_22.png" alt="http://www.milky.show/images/redis/redis_22.png" style="zoom: 50%;" />

**哈希表是由数组 table 组成, table 中每个元素都是指向 dict.h/dictEntry 结构, dictEntry 结构定义如下**

```c
typedef struct dictEntry{

     // 键
     void *key;

     // 值
     union{
          void *val;
          uint64_tu64;
          int64_ts64;
     } v;

     // 指向下一个哈希表节点,  形成链表
     struct dictEntry *next;

} dictEntry;
```

**key** 属性保存着键值对中的键

**v** 属性则保存着键值对中的值, 其中键值对的值可以是一个指针, 或者是一个 uint64_t 整数, 又或者是一个 int64_t 整数.

**next** 属性是指向另一个哈希表节点的指针, 这个指针可以将多个哈希值相同的键值对连接在一次, 以此来解决键冲突(collision)的问题.

举个例子, 图 4-2 就展示了如何通过 next 指针, 将两个索引值相同的键 k1 和 k0 连接在一起.

注意这里还有一个指向下一个哈希表节点的指针, 我们知道哈希表最大的问题是存在哈希冲突, 如何解决哈希冲突, 有开放地址法和链地址法.**这里采用的便是链地址法**, 通过next这个指针可以将多个哈希值相同的键值对连接在一起, 用来解决**哈希冲突**.

<img src="http://www.milky.show/images/redis/redis_6.png" alt="http://www.milky.show/images/redis/redis_6.png" style="zoom: 33%;" />

**字典定义: Redis 中的字典由 dict.h/dict 结构表示: **

```c
typedef struct dict {

    // 类型特定函数
    dictType *type;

    // 私有数据
    void *privdata;

    // 哈希表
    dictht ht[2];

    // rehash 索引
    // 当 rehash 不在进行时,  值为 -1
    int rehashidx; /* rehashing not in progress if rehashidx == -1 */

} dict;
```

type 属性和 privdata 属性是针对不同类型的键值对, 为创建多态字典而设置的: 

**type** 属性是一个指向 dictType 结构的指针, 每个 dictType 结构保存了一簇用于操作特定类型键值对的函数, Redis 会为用途不同的字典设置不同的类型特定函数.

**privdata** 属性则保存了需要传给那些类型特定函数的可选参数.

```c
typedef struct dictType {

    // 计算哈希值的函数
    unsigned int (*hashFunction)(const void *key);

    // 复制键的函数
    void *(*keyDup)(void *privdata,  const void *key);

    // 复制值的函数
    void *(*valDup)(void *privdata,  const void *obj);

    // 对比键的函数
    int (*keyCompare)(void *privdata,  const void *key1,  const void *key2);

    // 销毁键的函数
    void (*keyDestructor)(void *privdata,  void *key);

    // 销毁值的函数
    void (*valDestructor)(void *privdata,  void *obj);

} dictType;
```

ht 属性是一个包含两个项的数组, 数组中的每个项都是一个 dictht 哈希表, 一般情况下, 字典只使用 ht[0] 哈希表, ht[1] 哈希表只会在对 ht[0] 哈希表进行 rehash 时使用.

除了 ht[1] 之外, 另一个和 rehash 有关的属性就是 rehashidx :  它记录了 rehash 目前的进度, 如果目前没有在进行 rehash , 那么它的值为 -1 .

**一个普通状态下(没有进行 rehash)的字典: **

<img src="http://www.milky.show/images/redis/redis_23.png" alt="http://www.milky.show/images/redis/redis_23.png" style="zoom:33%;" />



**哈希算法: **

当要将一个新的键值对添加到字典里面时, 程序需要先根据键值对的键计算出哈希值和索引值, 然后再根据索引值, 将包含新键值对的哈希表节点放到哈希表数组的指定索引上面.

Redis 计算哈希值和索引值的方法如下: 

```
# 使用字典设置的哈希函数, 计算键 key 的哈希值
hash = dict->type->hashFunction(key);

# 使用哈希表的 sizemask 属性和哈希值, 计算出索引值
# 根据情况不同, ht[x] 可以是 ht[0] 或者 ht[1]
index = hash & dict->ht[x].sizemask;
```

如果我们要将一个键值对 k0 和 v0 添加到字典里面, 那么程序会先使用语句: 

```
hash = dict->type->hashFunction(k0);
```

计算键 k0 的哈希值.

假设计算得出的哈希值为 8 , 那么程序会继续使用语句: 

```
index = hash & dict->ht[0].sizemask = 8 & 3 = 0;
```

计算出键 k0 的索引值 0 , 这表示包含键值对 k0 和 v0 的节点应该被放置到哈希表数组的索引 0 位置上



![http://www.milky.show/images/redis_24.png](http://www.milky.show/images/redis_24.png)

当字典被用作数据库的底层实现, 或者哈希键的底层实现时, Redis 使用 MurmurHash2 算法来计算键的哈希值.

MurmurHash 算法最初由 Austin Appleby 于 2008 年发明, 这种算法的优点在于, 即使输入的键是有规律的, 算法仍能给出一个很好的随机分布性, 并且算法的计算速度也非常快.



**解决哈希冲突: **

当有两个或以上数量的键被分配到了哈希表数组的同一个索引上面时, 我们称这些键发生了冲突(collision).

Redis 的哈希表使用链地址法(separate chaining)来解决键冲突:  每个哈希表节点都有一个 next 指针, 多个哈希表节点可以用 next 指针构成一个单向链表, 被分配到同一个索引上的多个节点可以用这个单向链表连接起来, 这就解决了键冲突的问题.

举个例子, 假设程序要将键值对 k2 和 v2 添加到图 4-6 所示的哈希表里面, 并且计算得出 k2 的索引值为 2 , 那么键 k1 和 k2 将产生冲突, 而解决冲突的办法就是使用 next 指针将键 k2 和 k1 所在的节点连接起来

<img src="http://www.milky.show/images/redis/redis_25.png" alt="http://www.milky.show/images/redis/redis_25.png" style="zoom:33%;" />

因为 dictEntry 节点组成的链表没有指向链表表尾的指针, 所以为了速度考虑, 程序总是将新节点添加到链表的表头位置(复杂度为 O(1) ), 排在其他已有节点的前面.



**rehash:**

随着操作的不断执行, 哈希表保存的键值对会逐渐地增多或者减少, 为了让哈希表的负载因子(load factor)维持在一个合理的范围之内, 当哈希表保存的键值对数量太多或者太少时, 程序需要对哈希表的大小进行相应的扩展或者收缩.

扩展和收缩哈希表的工作可以通过执行 rehash (重新散列)操作来完成, Redis 对字典的哈希表执行 rehash 的步骤如下: 

1. 为字典的 ht[1] 哈希表分配空间, 这个哈希表的空间大小取决于要执行的操作, 以及 ht[0] 当前包含的键值对数量 (也即是 ht[0].used 属性的值):  
    - 如果执行的是扩展操作, 那么 ht[1] 的大小为第一个大于等于 ht[0].used * 2 的 2^n (2 的 n 次方幂); 
    - 如果执行的是收缩操作, 那么 ht[1] 的大小为第一个大于等于 ht[0].used 的 2^n .
2. 将保存在 ht[0] 中的所有键值对 rehash 到 ht[1] 上面:  rehash 指的是重新计算键的哈希值和索引值, 然后将键值对放置到 ht[1] 哈希表的指定位置上.
3. 当 ht[0] 包含的所有键值对都迁移到了 ht[1] 之后 (ht[0] 变为空表), 释放 ht[0] , 将 ht[1] 设置为 ht[0] , 并在 ht[1] 新创建一个空白哈希表, 为下一次 rehash 做准备.

举个例子, 假设程序要对图 4-8 所示字典的 ht[0] 进行扩展操作, 那么程序将执行以下步骤: 

1. ht[0].used 当前的值为 4 , 4 * 2 = 8 , 而 8 (2^3)恰好是第一个大于等于 4 的 2 的 n 次方, 所以程序会将 ht[1] 哈希表的大小设置为 8 . 图 4-9 展示了 ht[1] 在分配空间之后, 字典的样子.
2. 将 ht[0] 包含的四个键值对都 rehash 到 ht[1] , 如图 4-10 所示.
3. 释放 ht[0] , 并将 ht[1] 设置为 ht[0] , 然后为 ht[1] 分配一个空白哈希表, 如图 4-11 所示.

至此, 对哈希表的扩展操作执行完毕, 程序成功将哈希表的大小从原来的 4 改为了现在的 8 .

1. 执行 rehash 之前的字典

    <img src="http://www.milky.show/images/redis/redis_32.png" alt="http://www.milky.show/images/redis/redis_32.png" style="zoom:33%;" />

2. 为字典的 ht[1] 哈希表分配空间

    <img src="http://www.milky.show/images/redis/redis_33.png" alt="http://www.milky.show/images/redis/redis_33.png" style="zoom:33%;" />

3. ht[0] 的所有键值对都已经被迁移到 ht[1]

    <img src="http://www.milky.show/images/redis/redis_34.png" alt="http://www.milky.show/images/redis/redis_34.png" style="zoom:33%;" />

4. 完成 rehash 之后的字典

    <img src="http://www.milky.show/images/redis/redis_35.png" alt="http://www.milky.show/images/redis/redis_35.png" style="zoom:33%;" />

**扩容和收缩: **

当哈希表保存的键值对太多或者太少时, 就要通过 rerehash(重新散列)来对哈希表进行相应的扩展或者收缩.具体步骤: 

1. 如果执行扩展操作, 会基于原哈希表创建一个大小等于 ht[0].used*2n 的哈希表(也就是每次扩展都是根据原哈希表已使用的空间扩大一倍创建另一个哈希表).相反如果执行的是收缩操作, 每次收缩是根据已使用空间缩小一倍创建一个新的哈希表.
2. 重新利用上面的哈希算法, 计算索引值, 然后将键值对放到新的哈希表位置上.
3. 所有键值对都迁徙完毕后, 释放原哈希表的内存空间.

**触发扩容的条件: **

当以下条件中的任意一个被满足时, 程序会自动开始对哈希表执行扩展操作: 

- 服务器目前没有执行 BGSAVE 命令或者 BGREWRITEAOF 命令, 并且负载因子大于等于1.

- 服务器目前正在执行 BGSAVE 命令或者 BGREWRITEAOF 命令, 并且负载因子大于等于5.

- 负载因子 = 哈希表已保存节点数量 / 哈希表大小.

    ```
    # 负载因子 = 哈希表已保存节点数量 / 哈希表大小
    load_factor = ht[0].used / ht[0].size
    ```

    比如说, 对于一个大小为 `4` , 包含 `4` 个键值对的哈希表来说, 这个哈希表的负载因子为: 

    ```
    load_factor = 4 / 4 = 1
    ```

    又比如说, 对于一个大小为 `512` , 包含 `256` 个键值对的哈希表来说, 这个哈希表的负载因子为: 

    ```
    load_factor = 256 / 512 = 0.5
    ```

    根据 BGSAVE 命令或 BGREWRITEAOF 命令是否正在执行, 服务器执行扩展操作所需的负载因子并不相同, 这是因为在执行 BGSAVE命令或 BGREWRITEAOF 命令的过程中, Redis 需要创建当前服务器进程的子进程, 而大多数操作系统都采用写时复制([copy-on-write](http://en.wikipedia.org/wiki/Copy-on-write))技术来优化子进程的使用效率, 所以在子进程存在期间, 服务器会提高执行扩展操作所需的负载因子, 从而尽可能地避免在子进程存在期间进行哈希表扩展操作, 这可以避免不必要的内存写入操作, 最大限度地节约内存.

    另一方面, 当哈希表的负载因子小于 `0.1` 时, 程序自动开始对哈希表执行收缩操作.



**渐近式 rehash**

扩展或收缩哈希表需要将 ht[0] 里面的所有键值对 rehash 到 ht[1] 里面, 但是, 这个 rehash 动作并不是一次性, 集中式地完成的, 而是分多次, 渐进式地完成的.

这样做的原因在于, 如果 ht[0] 里只保存着四个键值对, 那么服务器可以在瞬间就将这些键值对全部 rehash 到 ht[1] ;  但是, 如果哈希表里保存的键值对数量不是四个, 而是四百万, 四千万甚至四亿个键值对, 那么要一次性将这些键值对全部 rehash 到 ht[1] 的话, 庞大的计算量可能会导致服务器在一段时间内停止服务.

因此, 为了避免 rehash 对服务器性能造成影响, 服务器不是一次性将 ht[0] 里面的所有键值对全部 rehash 到 ht[1] , 而是分多次, 渐进式地将 ht[0] 里面的键值对慢慢地 rehash 到 ht[1] .

以下是哈希表渐进式 rehash 的详细步骤: 

1. 为 ht[1] 分配空间, 让字典同时持有 ht[0] 和 ht[1] 两个哈希表.
2. 在字典中维持一个索引计数器变量 rehashidx , 并将它的值设置为 0 , 表示 rehash 工作正式开始.
3. 在 rehash 进行期间, 每次对字典执行添加, 删除, 查找或者更新操作时, 程序除了执行指定的操作以外, 还会顺带将 ht[0] 哈希表在 rehashidx 索引上的所有键值对 rehash 到 ht[1] , 当 rehash 工作完成之后, 程序将 rehashidx 属性的值增一.
4. 随着字典操作的不断执行, 最终在某个时间点上, ht[0] 的所有键值对都会被 rehash 至 ht[1] , 这时程序将 rehashidx 属性的值设为 -1 , 表示 rehash 操作已完成.

渐进式 rehash 的好处在于它采取分而治之的方式, 将 rehash 键值对所需的计算工作均滩到对字典的每个添加, 删除, 查找和更新操作上, 从而避免了集中式 rehash 而带来的庞大计算量.

一次完整的渐进式 rehash 过程, 注意观察在整个 rehash 过程中, 字典的 rehashidx 属性是如何变化的



1. 准备开始rehash

    <img src="http://www.milky.show/images/redis/redis_26.png" alt="http://www.milky.show/images/redis/redis_26.png" style="zoom:33%;" />

2. rehash 索引 0 上的键值对

    <img src="http://www.milky.show/images/redis/redis_27.png" alt="http://www.milky.show/images/redis/redis_27.png" style="zoom:33%;" />

3. rehash 索引 1 上的键值对

    <img src="http://www.milky.show/images/redis/redis_28.png" alt="http://www.milky.show/images/redis/redis_28.png" style="zoom:33%;" />

4. rehash 索引 2 上的键值对

    <img src="http://www.milky.show/images/redis/redis_29.png" alt="http://www.milky.show/images/redis/redis_29.png" style="zoom:33%;" />

5. rehash 索引 3 上的键值对

    <img src="http://www.milky.show/images/redis/redis_30.png" alt="http://www.milky.show/images/redis/redis_30.png" style="zoom:33%;" />

6. rehash 完毕

    <img src="http://www.milky.show/images/redis/redis_31.png" alt="http://www.milky.show/images/redis/redis_31.png" style="zoom: 33%;" />



**因为在进行渐进式 rehash 的过程中, 字典会同时使用 ht[0] 和 ht[1] 两个哈希表, 所以在渐进式 rehash 进行期间, 字典的删除(delete), 查找(find), 更新(update)等操作会在两个哈希表上进行:  比如说, 要在字典里面查找一个键的话, 程序会先在 ht[0] 里面进行查找, 如果没找到的话, 就会继续到 ht[1] 里面进行查找, 诸如此类.**

**另外, 在渐进式 rehash 执行期间, 新添加到字典的键值对一律会被保存到 ht[1] 里面, 而 ht[0] 则不再进行任何添加操作:  这一措施保证了 ht[0] 包含的键值对数量会只减不增, 并随着 rehash 操作的执行而最终变成空表.**

**重点回顾**

- 字典被广泛用于实现 Redis 的各种功能, 其中包括数据库和哈希键.
- Redis 中的字典使用哈希表作为底层实现, 每个字典带有两个哈希表, 一个用于平时使用, 另一个仅在进行 rehash 时使用.
- 当字典被用作数据库的底层实现, 或者哈希键的底层实现时, Redis 使用 MurmurHash2 算法来计算键的哈希值.
- 哈希表使用链地址法来解决键冲突, 被分配到同一个索引上的多个键值对会连接成一个单向链表.
- 在对哈希表进行扩展或者收缩操作时, 程序需要将现有哈希表包含的所有键值对 rehash 到新哈希表里面, 并且这个 rehash 过程并不是一次性地完成的, 而是渐进式地完成的.



#### 跳跃表(skiplist)

跳跃表(skiplist)是一种有序数据结构, 它通过在每个节点中维持多个指向其他节点的指针, 从而达到快速访问节点的目的.

跳跃表支持平均 O(log N) 最坏 O(N) 复杂度的节点查找, 还可以通过顺序性操作来批量处理节点.

**在大部分情况下, 跳跃表的效率可以和平衡树相媲美, 并且因为跳跃表的实现比平衡树要来得更为简单, 所以有不少程序都使用跳跃表来代替平衡树.**

Redis 使用跳跃表作为有序集合键的底层实现之一:  如果一个有序集合包含的元素数量比较多, 又或者有序集合中元素的成员(member)是比较长的字符串时, Redis 就会使用跳跃表来作为有序集合键的底层实现.

具有如下性质: 

1. 由很多层结构组成; 
2. 每一层都是一个有序的链表, 排列顺序为由高层到底层, 都至少包含两个链表节点, 分别是前面的head节点和后面的nil节点; 
3. 最底层的链表包含了所有的元素; 
4. 如果一个元素出现在某一层的链表中, 那么在该层之下的链表也全都会出现(上一层的元素是当前层的元素的子集); 
5. 链表中的每个节点都包含两个指针, 一个指向同一层的下一个链表节点, 另一个指向下一层的同一个链表节点; 

举个例子, fruit-price 是一个有序集合键, 这个有序集合以水果名为成员, 水果价钱为分值, 保存了 130 款水果的价钱: 

```
redis> ZRANGE fruit-price 0 2 WITHSCORES
1) "banana"
2) "5"
3) "cherry"
4) "6.5"
5) "apple"
6) "8"

redis> ZCARD fruit-price
(integer) 130
```

`fruit-price` 有序集合的所有数据都保存在一个跳跃表里面, 其中每个跳跃表节点(node)都保存了一款水果的价钱信息, 所有水果按价钱的高低从低到高在跳跃表里面排序: 

- 跳跃表的第一个元素的成员为 `"banana"` , 它的分值为 `5` ; 
- 跳跃表的第二个元素的成员为 `"cherry"` , 它的分值为 `6.5` ; 
- 跳跃表的第三个元素的成员为 `"apple"` , 它的分值为 `8` ; 

和链表, 字典等数据结构被广泛地应用在 Redis 内部不同, Redis 只在两个地方用到了跳跃表, 一个是实现有序集合键, 另一个是在集群节点中用作内部数据结构, 除此之外, 跳跃表在 Redis 里面没有其他用途.



Redis 的跳跃表由 redis.h/zskiplistNode 和 redis.h/zskiplist 两个结构定义, 其中 zskiplistNode 结构用于表示跳跃表节点, 而 zskiplist 结构则用于保存跳跃表节点的相关信息, 比如节点的数量, 以及指向表头节点和表尾节点的指针, 等等.

<img src="http://www.milky.show/images/redis/redis_8.png" alt="http://www.milky.show/images/redis/redis_8.png" style="zoom: 33%;" />

位于图片最左边的是 zskiplist 结构, 该结构包含以下属性: 

- header : 指向跳跃表的表头节点.
- tail : 指向跳跃表的表尾节点.
- level : 记录目前跳跃表内, 层数最大的那个节点的层数(表头节点的层数不计算在内).
- length : 记录跳跃表的长度, 也即是, 跳跃表目前包含节点的数量(表头节点不计算在内).

位于 zskiplist 结构右方的是四个 zskiplistNode 结构, 该结构包含以下属性: 

- 层(level): 节点中用 L1 ,  L2 ,  L3 等字样标记节点的各个层, L1 代表第一层, L2 代表第二层, 以此类推.每个层都带有两个属性: 前进指针和跨度.前进指针用于访问位于表尾方向的其他节点, 而跨度则记录了前进指针所指向节点和当前节点的距离.在上面的图片中, 连线上带有数字的箭头就代表前进指针, 而那个数字就是跨度.当程序从表头向表尾进行遍历时, 访问会沿着层的前进指针进行.
- 后退(backward)指针: 节点中用 BW 字样标记节点的后退指针, 它指向位于当前节点的前一个节点.后退指针在程序从表尾向表头遍历时使用.
- 分值(score): 各个节点中的 1.0 ,  2.0 和 3.0 是节点所保存的分值.在跳跃表中, 节点按各自所保存的分值从小到大排列.
- 成员对象(obj): 各个节点中的 o1 ,  o2 和 o3 是节点所保存的成员对象.

注意表头节点和其他节点的构造是一样的:  表头节点也有后退指针, 分值和成员对象, 不过表头节点的这些属性都不会被用到, 所以图中省略了这些部分, 只显示了表头节点的各个层.



**跳跃表节点: 跳跃表节点的实现由 redis.h/zskiplistNode 结构定义**

```c
typedef struct zskiplistNode {

    // 后退指针
    struct zskiplistNode *backward;

    // 分值
    double score;

    // 成员对象
    robj *obj;

    // 层
    struct zskiplistLevel {

        // 前进指针
        struct zskiplistNode *forward;

        // 跨度
        unsigned int span;

    } level[];

} zskiplistNode;
```

**层**

跳跃表节点的 `level` 数组可以包含多个元素, 每个元素都包含一个指向其他节点的指针, 程序可以通过这些层来加快访问其他节点的速度, 一般来说, 层的数量越多, 访问其他节点的速度就越快.

每次创建一个新跳跃表节点的时候, 程序都根据幂次定律 ([power law](http://en.wikipedia.org/wiki/Power_law), 越大的数出现的概率越小) 随机生成一个介于 `1` 和 `32` 之间的值作为 `level` 数组的大小, 这个大小就是层的“高度”.

分别展示了三个高度为 `1` 层,  `3` 层和 `5` 层的节点, 因为 C 语言的数组索引总是从 `0` 开始的, 所以节点的第一层是 `level[0]` , 而第二层是 `level[1]` , 以此类推.

<img src="http://www.milky.show/images/redis/redis_36.png" alt="http://www.milky.show/images/redis/redis_36.png" style="zoom: 40%;" />

**前进指针**

每个层都有一个指向表尾方向的前进指针(`level[i].forward` 属性), 用于从表头向表尾方向访问节点.

虚线表示出了程序从表头向表尾方向, 遍历跳跃表中所有节点的路径: 

1. 迭代程序首先访问跳跃表的第一个节点(表头), 然后从第四层的前进指针移动到表中的第二个节点.
2. 在第二个节点时, 程序沿着第二层的前进指针移动到表中的第三个节点.
3. 在第三个节点时, 程序同样沿着第二层的前进指针移动到表中的第四个节点.
4. 当程序再次沿着第四个节点的前进指针移动时, 它碰到一个 `NULL` , 程序知道这时已经到达了跳跃表的表尾, 于是结束这次遍历.

<img src="http://www.milky.show/images/redis/redis_37.png" alt="http://www.milky.show/images/redis/redis_37.png" style="zoom: 40%;" />

**跨度**

层的跨度(`level[i].span` 属性)用于记录两个节点之间的距离: 

- 两个节点之间的跨度越大, 它们相距得就越远.
- 指向 `NULL` 的所有前进指针的跨度都为 `0` , 因为它们没有连向任何节点.

初看上去, 很容易以为跨度和遍历操作有关, 但实际上并不是这样 —— 遍历操作只使用前进指针就可以完成了, 跨度实际上是用来计算排位(rank)的:  在查找某个节点的过程中, 将沿途访问过的所有层的跨度累计起来, 得到的结果就是目标节点在跳跃表中的排位.

举个例子, 虚线标记了在跳跃表中查找分值为 `3.0` ,  成员对象为 `o3` 的节点时, 沿途经历的层:  查找的过程只经过了一个层, 并且层的跨度为 `3` , 所以目标节点在跳跃表中的排位为 `3` .

<img src="http://www.milky.show/images/redis/redis_38.png" alt="http://www.milky.show/images/redis/redis_38.png" style="zoom:33%;" />

再举个例子, 用虚线标记了在跳跃表中查找分值为 2.0 ,  成员对象为 o2 的节点时, 沿途经历的层:  在查找节点的过程中, 程序经过了两个跨度为 1 的节点, 因此可以计算出, 目标节点在跳跃表中的排位为 2 .

<img src="http://www.milky.show/images/redis/redis_39.png" alt="http://www.milky.show/images/redis/redis_39.png" style="zoom:33%;" />

**后退指针**

节点的后退指针(`backward` 属性)用于从表尾向表头方向访问节点:  跟可以一次跳过多个节点的前进指针不同, 因为每个节点只有一个后退指针, 所以每次只能后退至前一个节点.

图 5-6 用虚线展示了如果从表尾向表头遍历跳跃表中的所有节点:  程序首先通过跳跃表的 `tail` 指针访问表尾节点, 然后通过后退指针访问倒数第二个节点, 之后再沿着后退指针访问倒数第三个节点, 再之后遇到指向 `NULL` 的后退指针, 于是访问结束.

<img src="http://www.milky.show/images/redis/redis_40.png" alt="http://www.milky.show/images/redis/redis_40.png" style="zoom:33%;" />

**分值和成员**

节点的分值(`score` 属性)是一个 `double` 类型的浮点数, 跳跃表中的所有节点都按分值从小到大来排序.

节点的成员对象(`obj` 属性)是一个指针, 它指向一个字符串对象, 而字符串对象则保存着一个 SDS 值.

在同一个跳跃表中, 各个节点保存的成员对象必须是唯一的, 但是多个节点保存的分值却可以是相同的:  分值相同的节点将按照成员对象在字典序中的大小来进行排序, 成员对象较小的节点会排在前面(靠近表头的方向), 而成员对象较大的节点则会排在后面(靠近表尾的方向).

举个例子, 在图 5-7 所示的跳跃表中, 三个跳跃表节点都保存了相同的分值 `10086.0` , 但保存成员对象 `o1` 的节点却排在保存成员对象 `o2`和 `o3` 的节点之前, 而保存成员对象 `o2` 的节点又排在保存成员对象 `o3` 的节点之前, 由此可见, `o1` ,  `o2` ,  `o3` 三个成员对象在字典中的排序为 `o1 <= o2 <= o3` .

<img src="http://www.milky.show/images/redis/redis_41.png" alt="http://www.milky.show/images/redis/redis_41.png" style="zoom: 33%;" />

虽然仅靠多个跳跃表节点就可以组成一个跳跃表, 但通过使用一个 zskiplist 结构来持有这些节点, 程序可以更方便地对整个跳跃表进行处理, 比如快速访问跳跃表的表头节点和表尾节点, 又或者快速地获取跳跃表节点的数量(也即是跳跃表的长度)等信息

**zskiplist 结构的定义如下: **

```c
typedef struct zskiplist {

    // 表头节点和表尾节点
    struct zskiplistNode *header,  *tail;

    // 表中节点的数量
    unsigned long length;

    // 表中层数最大的节点的层数
    int level;

} zskiplist;
```

header 和 tail 指针分别指向跳跃表的表头和表尾节点, 通过这两个指针, 程序定位表头节点和表尾节点的复杂度为 O(1)  .

通过使用 length 属性来记录节点的数量, 程序可以在 O(1)  复杂度内返回跳跃表的长度.

level 属性则用于在 O(1)  复杂度内获取跳跃表中层高最大的那个节点的层数量, 注意表头节点的层高并不计算在内.



**重点回顾**

- 跳跃表是有序集合的底层实现之一, 除此之外它在 Redis 中没有其他应用.
- Redis 的跳跃表实现由 `zskiplist` 和 `zskiplistNode` 两个结构组成, 其中 `zskiplist` 用于保存跳跃表信息(比如表头节点, 表尾节点, 长度), 而 `zskiplistNode` 则用于表示跳跃表节点.
- 每个跳跃表节点的层高都是 `1` 至 `32` 之间的随机数.
- 在同一个跳跃表中, 多个节点可以包含相同的分值, 但每个节点的成员对象必须是唯一的.
- 跳跃表中的节点按照分值大小进行排序, 当分值相同时, 节点按照成员对象的大小进行排序.



<img src="http://www.milky.show/images/redis/redis_7.png" alt="http://www.milky.show/images/redis/redis_7.png" style="zoom: 33%;" />



**搜索: **从最高层的链表节点开始, 如果比当前节点要大和比当前层的下一个节点要小, 那么则往下找, 也就是和当前层的下一层的节点的下一个节点进行比较, 以此类推, 一直找到最底层的最后一个节点, 如果找到则返回, 反之则返回空.

**插入: **首先确定插入的层数, 有一种方法是假设抛一枚硬币, 如果是正面就累加, 直到遇见反面为止, 最后记录正面的次数作为插入的层数.当确定插入的层数k后, 则需要将新元素插入到从底层到k层.

**删除: **在各个层中找到包含指定值的节点, 然后将节点从链表中删除即可, 如果删除以后只剩下头尾两个节点, 则删除这一层.



#### 整数集合(intset)

整数集合(intset)是集合键的底层实现之一:  它可以保存类型为int16_t, int32_t 或者int64_t 的整数值, 并且保证集合中不会出现重复元素.当一个集合只包含整数值元素, 并且这个集合的元素数量不多时, Redis 就会使用整数集合作为集合键的底层实现.

举个例子, 如果我们创建一个只包含五个元素的集合键, 并且集合中的所有元素都是整数值, 那么这个集合键的底层实现就会是整数集合: 

```
redis> SADD numbers 1 3 5 7 9
(integer) 5

redis> OBJECT ENCODING numbers
"intset"
```

**每个 intset.h/intset 结构表示一个整数集合: 整数集合定义如下:**

```c
typedef struct intset {

    // 编码方式
    uint32_t encoding;

    // 集合包含的元素数量
    uint32_t length;

    // 保存元素的数组
    int8_t contents[];

} intset;
```

contents 数组是整数集合的底层实现:  整数集合的每个元素都是 contents 数组的一个数组项(item), 各个项在数组中按值的大小从小到大有序地排列, 并且数组中不包含任何重复项.

length 属性记录了整数集合包含的元素数量, 也即是 contents 数组的长度.

虽然 intset 结构将 contents 属性声明为 int8_t 类型的数组, 但实际上 contents 数组并不保存任何 int8_t 类型的值 —— contents 数组的真正类型取决于 encoding 属性的值: 

- 如果 encoding 属性的值为 INTSET_ENC_INT16 , 那么 contents 就是一个 int16_t 类型的数组, 数组里的每个项都是一个 int16_t 类型的整数值 (最小值为 -32, 768 , 最大值为 32, 767 ).
- 如果 encoding 属性的值为 INTSET_ENC_INT32 , 那么 contents 就是一个 int32_t 类型的数组, 数组里的每个项都是一个 int32_t 类型的整数值 (最小值为 -2, 147, 483, 648 , 最大值为 2, 147, 483, 647 ).
- 如果 encoding 属性的值为 INTSET_ENC_INT64 , 那么 contents 就是一个 int64_t 类型的数组, 数组里的每个项都是一个 int64_t 类型的整数值 (最小值为 -9, 223, 372, 036, 854, 775, 808 , 最大值为 9, 223, 372, 036, 854, 775, 807 ).

展示了一个整数集合示例: 

- encoding 属性的值为 INTSET_ENC_INT16 , 表示整数集合的底层实现为 int16_t 类型的数组, 而集合保存的都是 int16_t 类型的整数值.
- length 属性的值为 5 , 表示整数集合包含五个元素.
- contents 数组按从小到大的顺序保存着集合中的五个元素.
- 因为每个集合元素都是 int16_t 类型的整数值, 所以 contents 数组的大小等于 sizeof(int16_t) * 5 = 16 * 5 = 80 位.

<img src="http://www.milky.show/images/redis/redis_42.png" alt="http://www.milky.show/images/redis/redis_42.png" style="zoom:50%;" />	

展示了另一个整数集合示例: 

- encoding 属性的值为 INTSET_ENC_INT64 , 表示整数集合的底层实现为 int64_t 类型的数组, 而数组中保存的都是 int64_t 类型的整数值.
- length 属性的值为 4 , 表示整数集合包含四个元素.
- contents 数组按从小到大的顺序保存着集合中的四个元素.
- 因为每个集合元素都是 int64_t 类型的整数值, 所以 contents 数组的大小为 sizeof(int64_t) * 4 = 64 * 4 = 256 位.

<img src="http://www.milky.show/images/redis/redis_43.png" alt="http://www.milky.show/images/redis/redis_43.png" style="zoom: 50%;" />	

虽然 contents 数组保存的四个整数值中, 只有 -2675256175807981027 是真正需要用 int64_t 类型来保存的, 而其他的 1 ,  3 ,  5 三个值都可以用 int16_t 类型来保存, 不过根据整数集合的升级规则, 当向一个底层为 int16_t 数组的整数集合添加一个 int64_t 类型的整数值时, 整数集合已有的所有元素都会被转换成 int64_t 类型, 所以 contents 数组保存的四个整数值都是 int64_t 类型的, 不仅仅是 -2675256175807981027 .



**升级**

当我们新增的元素类型比原集合元素类型的长度要大时, 需要对整数集合进行升级, 才能将新元素放入整数集合中.

1. 根据新元素类型, 扩展整数集合底层数组的大小, 并为新元素分配空间.
2. 将底层数组现有的所有元素都转成与新元素相同类型的元素, 并将转换后的元素放到正确的位置, 放置过程中, 维持整个元素顺序都是有序的.
3. 将新元素添加到整数集合中(保证有序).

　　升级能极大地节省内存.

举个例子, 假设现在有一个 INTSET_ENC_INT16 编码的整数集合, 集合中包含三个 int16_t 类型的元素

<img src="http://www.milky.show/images/redis/redis_44.png" alt="http://www.milky.show/images/redis/redis_44.png" style="zoom: 33%;" />	

因为每个元素都占用 16 位空间, 所以整数集合底层数组的大小为 3 * 16 = 48 位, 图 6-4 展示了整数集合的三个元素在这 48 位里的位置.

<img src="http://www.milky.show/images/redis/redis_45.png" alt="http://www.milky.show/images/redis/redis_45.png" style="zoom: 33%;" />	

现在, 假设我们要将类型为 int32_t 的整数值 65535 添加到整数集合里面, 因为 65535 的类型 int32_t 比整数集合当前所有元素的类型都要长, 所以在将 65535 添加到整数集合之前, 程序需要先对整数集合进行升级. 

升级首先要做的是, 根据新类型的长度, 以及集合元素的数量(包括要添加的新元素在内), 对底层数组进行空间重分配.

整数集合目前有三个元素, 再加上新元素 65535 , 整数集合需要分配四个元素的空间, 因为每个 int32_t 整数值需要占用 32 位空间, 所以在空间重分配之后, 底层数组的大小将是 32 * 4 = 128 位, 如图 6-5 所示.

<img src="http://www.milky.show/images/redis/redis_46.png" alt="http://www.milky.show/images/redis/redis_46.png" style="zoom: 33%;" />

虽然程序对底层数组进行了空间重分配, 但数组原有的三个元素 1 ,  2 ,  3 仍然是 int16_t 类型, 这些元素还保存在数组的前 48 位里面, 所以程序接下来要做的就是将这三个元素转换成 int32_t 类型, 并将转换后的元素放置到正确的位上面, 而且在放置元素的过程中, 需要维持底层数组的有序性质不变.

首先, 因为元素 3 在 1 ,  2 ,  3 ,  65535 四个元素中排名第三, 所以它将被移动到 contents 数组的索引 2 位置上, 也即是数组 64 位至 95 位的空间内, 如图 6-6 所示.

<img src="http://www.milky.show/images/redis/redis_47.png" alt="http://www.milky.show/images/redis/redis_47.png" style="zoom: 50%;" />

接着, 因为元素 2 在 1 ,  2 ,  3 ,  65535 四个元素中排名第二, 所以它将被移动到 contents 数组的索引 1 位置上, 也即是数组的 32 位至 63 位的空间内, 如图 6-7 所示.

<img src="http://www.milky.show/images/redis/redis_48.png" alt="http://www.milky.show/images/redis/redis_48.png" style="zoom: 33%;" />

之后, 因为元素 1 在 1 ,  2 ,  3 ,  65535 四个元素中排名第一, 所以它将被移动到 contents 数组的索引 0 位置上, 也即是数组的 0 位至 31 位的空间内, 如图 6-8 所示.

<img src="http://www.milky.show/images/redis/redis_49.png" alt="http://www.milky.show/images/redis/redis_49.png" style="zoom: 33%;" />

然后, 因为元素 65535 在 1 ,  2 ,  3 ,  65535 四个元素中排名第四, 所以它将被添加到 contents 数组的索引 3 位置上, 也即是数组的 96 位至 127 位的空间内, 如图 6-9 所示.

<img src="http://www.milky.show/images/redis/redis_50.png" alt="http://www.milky.show/images/redis/redis_50.png" style="zoom: 33%;" />

最后, 程序将整数集合 encoding 属性的值从 INTSET_ENC_INT16 改为 INTSET_ENC_INT32 , 并将 length 属性的值从 3 改为 4 , 设置完成之后的整数集合如图 6-10 所示.

<img src="http://www.milky.show/images/redis/redis_51.png" alt="http://www.milky.show/images/redis/redis_51.png" style="zoom: 50%;" />

因为每次向整数集合添加新元素都可能会引起升级, 而每次升级都需要对底层数组中已有的所有元素进行类型转换, 所以向整数集合添加新元素的时间复杂度为 O(N) . 

其他类型的升级操作, 比如从 INTSET_ENC_INT16 编码升级为 INTSET_ENC_INT64 编码, 或者从 INTSET_ENC_INT32 编码升级为 INTSET_ENC_INT64 编码, 升级的过程都和上面展示的升级过程类似.

**升级之后新元素的摆放位置**
 因为引发升级的新元素的长度总是比整数集合现有所有元素的长度都大, 所以这个新元素的值要么就大于所有现有元素, 要么就小于所有现有元素

- 在新元素小于所有现有元素的情况下, 新元素会被放置在底层数组的最开头(索引 0 ); 
- 在新元素大于所有现有元素的情况下, 新元素会被放置在底层数组的最末尾(索引 length-1 ).

**升级的好处:**

- ##### 提升灵活性

    因为 C 语言是静态类型语言, 为了避免类型错误, 我们通常不会将两种不同类型的值放在同一个数据结构里面.

    比如说, 我们一般只使用 int16_t 类型的数组来保存 int16_t 类型的值, 只使用 int32_t 类型的数组来保存 int32_t 类型的值, 诸如此类.

    但是, 因为整数集合可以通过自动升级底层数组来适应新元素, 所以我们可以随意地将 int16_t ,  int32_t 或者 int64_t 类型的整数添加到集合中, 而不必担心出现类型错误, 这种做法非常灵活.

- ##### 节约内存

    当然, 要让一个数组可以同时保存 int16_t ,  int32_t ,  int64_t 三种类型的值, 最简单的做法就是直接使用 int64_t 类型的数组作为整数集合的底层实现. 不过这样一来, 即使添加到整数集合里面的都是 int16_t 类型或者 int32_t 类型的值, 数组都需要使用 int64_t 类型的空间去保存它们, 从而出现浪费内存的情况.

    而整数集合现在的做法既可以让集合能同时保存三种不同类型的值, 又可以确保升级操作只会在有需要的时候进行, 这可以尽量节省内存.

    比如说, 如果我们一直只向整数集合添加 int16_t 类型的值, 那么整数集合的底层实现就会一直是 int16_t 类型的数组, 只有在我们要将 int32_t 类型或者 int64_t 类型的值添加到集合时, 程序才会对数组进行升级.



**降级**

整数集合不支持降级操作, 一旦对数组进行了升级, 编码就会一直保持升级后的状态.

举个例子, 对于图 6-11 所示的整数集合来说, 即使我们将集合里唯一一个真正需要使用 int64_t 类型来保存的元素 4294967295 删除了, 整数集合的编码仍然会维持 INTSET_ENC_INT64 , 底层数组也仍然会是 int64_t 类型的, 



**重点回顾**

- 整数集合是集合键的底层实现之一.
- 整数集合的底层实现为数组, 这个数组以有序, 无重复的方式保存集合元素, 在有需要时, 程序会根据新添加元素的类型, 改变这个数组的类型.
- 升级操作为整数集合带来了操作上的灵活性, 并且尽可能地节约了内存.
- 整数集合只支持升级操作, 不支持降级操作.



#### 压缩列表(ziplist)

压缩列表(ziplist)是列表键和哈希键的底层实现之一.

当一个列表键只包含少量列表项, 并且每个列表项要么就是小整数值, 要么就是长度比较短的字符串, 那么 Redis 就会使用压缩列表来做列表键的底层实现.

比如说, 执行以下命令将创建一个压缩列表实现的列表键: 

```
redis> RPUSH lst 1 3 5 10086 "hello" "world"
(integer) 6

redis> OBJECT ENCODING lst
"ziplist"
```

因为列表键里面包含的都是 1 ,  3 ,  5 ,  10086 这样的小整数值, 以及 "hello" ,  "world" 这样的短字符串.

另外, 当一个哈希键只包含少量键值对, 并且每个键值对的键和值要么就是小整数值, 要么就是长度比较短的字符串, 那么 Redis 就会使用压缩列表来做哈希键的底层实现.

**压缩列表的构成**

压缩列表是 Redis 为了节约内存而开发的, 由一系列特殊编码的连续内存块组成的顺序型(sequential)数据结构.

一个压缩列表可以包含任意多个节点(entry), 每个节点可以保存一个字节数组或者一个整数值.

**压缩列表并不是对数据利用某种算法进行压缩, 而是将数据按照一定规则编码在一块连续的内存区域, 目的是节省内存.**

<img src="http://www.milky.show/images/redis/redis_9.png" alt="http://www.milky.show/images/redis/redis_9.png" style="zoom: 33%;" />

| 属性    | 类型     | 长度   | 用途                                                         |
| ------- | -------- | ------ | ------------------------------------------------------------ |
| zlbytes | uint32_t | 4字节  | 记录整个压缩列表占用的内存字节数: 再对压缩列表进行内存重分配, 或者计算zlend的位置时使用 |
| zltail  | uint32_t | 4 字节 | 记录压缩列表表尾节点距离压缩列表的起始地址有多少字节: 通过这个偏移量, 程序无需遍历整个压缩列表就可以确定表尾节点的地址 |
| zllen   | uint16_t | 2 字节 | 记录了压缩列表包含的节点数据: 当这个属性的值小于uint16_max(65535)时, 这个属性的值就是压缩列表包含节点的数量;当这个值等于uint16_max 时, 节点的真实数量需要遍历整个压缩列表才能计算得出 |
| entryX  | 列表节点 | 不定   | 压缩列表包含的各个节点, 节点的长度由节点保存的内容决定       |
| zlend   | uint8_t  | 1 字节 | 特殊值0xFF(十进制 255), 用于标记压缩列表的末端               |



一个压缩列表示例: 

- 列表 zlbytes 属性的值为 0x50 (十进制 80), 表示压缩列表的总长为 80 字节.
- 列表 zltail 属性的值为 0x3c (十进制 60), 这表示如果我们有一个指向压缩列表起始地址的指针 p , 那么只要用指针 p 加上偏移量 60 , 就可以计算出表尾节点 entry3 的地址.
- 列表 zllen 属性的值为 0x3 (十进制 3), 表示压缩列表包含三个节点.

<img src="http://www.milky.show/images/redis/redis_52.png" alt="http://www.milky.show/images/redis/redis_52.png" style="zoom:50%;" />

另一个压缩列表示例: 

- 列表 zlbytes 属性的值为 0xd2 (十进制 210), 表示压缩列表的总长为 210 字节.
- 列表 zltail 属性的值为 0xb3 (十进制 179), 这表示如果我们有一个指向压缩列表起始地址的指针 p , 那么只要用指针 p 加上偏移量 179 , 就可以计算出表尾节点 entry5 的地址.
- 列表 zllen 属性的值为 0x5 (十进制 5), 表示压缩列表包含五个节点.

<img src="http://www.milky.show/images/redis/redis_53.png" alt="http://www.milky.show/images/redis/redis_53.png" style="zoom: 50%;" />



**压缩列表的每个节点构成如下: **

<img src="http://www.milky.show/images/redis/redis_10.png" alt="http://www.milky.show/images/redis/redis_10.png" style="zoom:50%;" />

- previous_entry_ength: 记录压缩列表前一个字节的长度.previous_entry_ength的长度可能是1个字节或者是5个字节, 如果上一个节点的长度小于254, 则该节点只需要一个字节就可以表示前一个节点的长度了, 如果前一个节点的长度大于等于254, 则previous length的第一个字节为254, 后面用四个字节表示当前节点前一个节点的长度.利用此原理即当前节点位置减去上一个节点的长度即得到上一个节点的起始位置, 压缩列表可以从尾部向头部遍历.这么做很有效地减少了内存的浪费.
- encoding: 节点的encoding保存的是节点的content的内容类型以及长度, encoding类型一共有两种, 一种字节数组一种是整数, encoding区域长度为1字节, 2字节或者5字节长.
- content: content区域用于保存节点的内容, 节点内容类型和长度由encoding决定.

**连锁更新**

前面说过, 每个节点的 previous_entry_length 属性都记录了前一个节点的长度: 

如果前一节点的长度小于 254 字节, 那么 previous_entry_length 属性需要用 1 字节长的空间来保存这个长度值.
 如果前一节点的长度大于等于 254 字节, 那么 previous_entry_length 属性需要用 5 字节长的空间来保存这个长度值.
 现在, 考虑这样一种情况:  在一个压缩列表中, 有多个连续的, 长度介于 250 字节到 253 字节之间的节点 e1 至 eN 

<img src="http://www.milky.show/images/redis/redis_54.png" alt="http://www.milky.show/images/redis/redis_54.png" style="zoom:50%;" />

因为 e1 至 eN 的所有节点的长度都小于 254 字节, 所以记录这些节点的长度只需要 1 字节长的 previous_entry_length 属性, 换句话说, e1 至 eN 的所有节点的 previous_entry_length 属性都是 1 字节长的.

这时, 如果我们将一个长度大于等于 254 字节的新节点 new 设置为压缩列表的表头节点, 那么 new 将成为 e1 的前置节点, 

<img src="http://www.milky.show/images/redis/redis_55.png" alt="http://www.milky.show/images/redis/redis_55.png" style="zoom: 50%;" />

因为 e1 的 previous_entry_length 属性仅长 1 字节, 它没办法保存新节点 new 的长度, 所以程序将对压缩列表执行空间重分配操作, 并将 e1 节点的 previous_entry_length 属性从原来的 1 字节长扩展为 5 字节长.

现在, 麻烦的事情来了 —— e1 原本的长度介于 250 字节至 253 字节之间, 在为 previous_entry_length 属性新增四个字节的空间之后, e1 的长度就变成了介于 254 字节至 257 字节之间, 而这种长度使用 1 字节长的 previous_entry_length 属性是没办法保存的.

因此, 为了让 e2 的 previous_entry_length 属性可以记录下 e1 的长度, 程序需要再次对压缩列表执行空间重分配操作, 并将 e2 节点的 previous_entry_length 属性从原来的 1 字节长扩展为 5 字节长.

正如扩展 e1 引发了对 e2 的扩展一样, 扩展 e2 也会引发对 e3 的扩展, 而扩展 e3 又会引发对 e4 的扩展……为了让每个节点的 previous_entry_length 属性都符合压缩列表对节点的要求, 程序需要不断地对压缩列表执行空间重分配操作, 直到 eN 为止.

Redis 将这种在特殊情况下产生的连续多次空间扩展操作称之为“连锁更新”(cascade update)

<img src="http://www.milky.show/images/redis/redis_56.png" alt="http://www.milky.show/images/redis/redis_56.png" style="zoom: 33%;" />

**除了添加新节点可能会引发连锁更新之外, 删除节点也可能会引发连锁更新.**

考虑图 7-14 所示的压缩列表, 如果 e1 至 eN 都是大小介于 250 字节至 253 字节的节点, big 节点的长度大于等于 254 字节(需要 5 字节的 previous_entry_length 来保存), 而 small 节点的长度小于 254 字节(只需要 1 字节的 previous_entry_length 来保存), 那么当我们将 small 节点从压缩列表中删除之后, 为了让 e1 的 previous_entry_length 属性可以记录 big 节点的长度, 程序将扩展 e1 的空间, 并由此引发之后的连锁更新.

<img src="http://www.milky.show/images/redis/redis_57.png" alt="http://www.milky.show/images/redis/redis_57.png" style="zoom: 50%;" />

因为连锁更新在最坏情况下需要对压缩列表执行 N 次空间重分配操作, 而每次空间重分配的最坏复杂度为 O(N) , 所以连锁更新的最坏复杂度为 O(N^2) .

要注意的是, 尽管连锁更新的复杂度较高, 但它真正造成性能问题的几率是很低的: 

- 首先, 压缩列表里要恰好有多个连续的, 长度介于 250 字节至 253 字节之间的节点, 连锁更新才有可能被引发, 在实际中, 这种情况并不多见; 
- 其次, 即使出现连锁更新, 但只要被更新的节点数量不多, 就不会对性能造成任何影响:  比如说, 对三五个节点进行连锁更新是绝对不会影响性能的; 

因为以上原因, ziplistPush 等命令的平均复杂度仅为 O(N) , 在实际中, 我们可以放心地使用这些函数, 而不必担心连锁更新会影响压缩列表的性能.

**重点回顾**

- 压缩列表是一种为节约内存而开发的顺序型数据结构.
- 压缩列表被用作列表键和哈希键的底层实现之一.
- 压缩列表可以包含多个节点, 每个节点可以保存一个字节数组或者整数值.
- 添加新节点到压缩列表, 或者从压缩列表中删除节点, 可能会引发连锁更新操作, 但这种操作出现的几率并不高.

#### 总结

大多数情况下, Redis使用简单字符串SDS作为字符串的表示, 相对于C语言字符串, SDS具有常数复杂度获取字符串长度, 杜绝了缓存区的溢出, 减少了修改字符串长度时所需的内存重分配次数, 以及二进制安全能存储各种类型的文件, 并且还兼容部分C函数.

通过为链表设置不同类型的特定函数, Redis链表可以保存各种不同类型的值, 除了用作列表键, 还在发布与订阅, 慢查询, 监视器等方面发挥作用(后面会介绍).

Redis的字典底层使用哈希表实现, 每个字典通常有两个哈希表, 一个平时使用, 另一个用于rehash时使用, 使用链地址法解决哈希冲突.

跳跃表通常是有序集合的底层实现之一, 表中的节点按照分值大小进行排序.

整数集合是集合键的底层实现之一, 底层由数组构成, 升级特性能尽可能的节省内存.

压缩列表是Redis为节省内存而开发的顺序型数据结构, 通常作为列表键和哈希键的底层实现之一.

以上介绍的简单字符串, 链表, 字典, 跳跃表, 整数集合, 压缩列表等数据结构就是Redis底层的一些数据结构, 用来实现上一篇博客介绍的Redis五大数据类型, 那么每种数据类型是由哪些数据结构实现的呢？下一篇博客进行介绍.

### Redis五大类型与底层结构的关系

#### 字符串对象(String)

**字符串对象的编码可以是int, raw或者embstr**
如果一个字符串的内容可以转换为long, 那么该字符串就会被转换成为long类型, 对象的ptr就会指向该long, 并且对象类型也用int类型表示.
普通的字符串有两种, embstr和raw.embstr应该是Redis 3.0新增的数据结构, 在2.8中是没有的.**如果字符串对象的长度小于39字节, 就用embstr对象.否则用传统的raw对象.**

```c
#define REDIS_ENCODING_EMBSTR_SIZE_LIMIT 44  
robj *createStringObject(char *ptr,  size_t len) {  
    if (len <= REDIS_ENCODING_EMBSTR_SIZE_LIMIT)  
        return createEmbeddedStringObject(ptr, len);  
    else  
        return createRawStringObject(ptr, len);  
}  
```

embstr的好处有如下几点: 

1. embstr的创建只需分配一次内存, 而raw为两次(一次为[`sds`](https://github.com/antirez/redis/blob/unstable/src/sds.h)分配对象, 另一次为objet分配对象, embstr省去了第一次).
2. 相对地, 释放内存的次数也由两次变为一次.
3. embstr的objet和sds放在一起, 更好地利用缓存带来的优势.
4. 但redis不集成对embstr的操作, 因此执行命令时, 会自动将embstr转换为row编码

raw 和 embstr 的区别可以用下面两幅图所示: 

**raw 编码的字符串对象:**

<img src="http://www.milky.show/images/redis/redis_11.png" alt="http://www.milky.show/images/redis/redis_11.png" style="zoom:33%;" />

**embstr 编码的字符串对象:**

<img src="http://www.milky.show/images/redis/redis_12.png" alt="http://www.milky.show/images/redis/redis_12.png" style="zoom:33%;" />



**当字符串对象是由整数构成时, 采用整数值作为底层结构; 当对象有字符串构成, 且值小于32字节, 此时用embstr编码的SDS, 否则采用row编码的SDS.**



#### 列表对象(List)

**列表对象的编码可以是ziplist或者linkedlist**

ziplist是一种压缩链表, 它的好处是更能节省内存空间, 因为它所存储的内容都是在连续的内存区域当中的.当列表对象元素不大, 每个元素也不大的时候, 就采用ziplist存储但当数据量过大时就ziplist就不是那么好用了.因为为了保证他存储内容在内存中的连续性, 插入的复杂度是O(N), 即每次插入都会重新进行realloc.如下图所示, 对象结构中ptr所指向的就是一个ziplist整个ziplist只需要malloc一次, 它们在内存中是一块连续的区域.

<img src="http://www.milky.show/images/redis/redis_13.png" alt="http://www.milky.show/images/redis/redis_13.png" style="zoom:33%;" />

linkedlist是一种双向链表.它的结构比较简单, 节点中存放pre和next两个指针, 还有节点相关的信息.当每增加一个node的时候, 就需要重新malloc一块内存.

<img src="http://www.milky.show/images/redis/redis_14.png" alt="http://www.milky.show/images/redis/redis_14.png" style="zoom:33%;" />



**当列表对象所有值小于64字节, 且长度小于512个, 采用压缩列表作为底层结构.否则自动采用双端链表的结构**

#### 哈希(Map)

**哈希对象的底层实现可以是ziplist或者hashtable.**
ziplist中的哈希对象是按照key1, value1, key2, value2这样的顺序存放来存储的.当对象数目不多且内容不大时, 这种方式效率是很高的.

hashtable的是由dict这个结构来实现的, dict是一个字典, 其中的指针dicht ht[2] 指向了两个哈希表

```c
typedef struct dict {  
    dictType *type;  
    void *privdata;  
    dictht ht[2];  
    long rehashidx; /* rehashing not in progress if rehashidx == -1 */  
    int iterators; /* number of iterators currently running */  
} dict;  
typedef struct dictht {  
    dictEntry **table;  
    unsigned long size;  
    unsigned long sizemask;  
    unsigned long used;  
} dictht;  
```

dicht[0] 是用于真正存放数据, dicht[1]一般在哈希表元素过多进行rehash的时候用于中转数据.
dictht中的table用语真正存放元素了, 每个key/value对用一个dictEntry表示, 放在dictEntry数组中.

<img src="http://www.milky.show/images/redis/redis_15.png" alt="http://www.milky.show/images/redis/redis_15.png" style="zoom:33%;" />

**当哈希对象每个值小于64字节, 且大小小于512个时, 采用压缩列表作为底层结构.否则自动采用字典的结构**

#### 集合对象(Set)

**集合对象的编码可以是intset或者hashtable**
intset是一个整数集合, 里面存的为某种同一类型的整数, 支持如下三种长度的整数: 

```c
#define INTSET_ENC_INT16 (sizeof(int16_t))  
#define INTSET_ENC_INT32 (sizeof(int32_t))  
#define INTSET_ENC_INT64 (sizeof(int64_t))
```

intset是一个有序集合, 查找元素的复杂度为O(logN), 但插入时不一定为O(logN), 因为有可能涉及到升级操作.比如当集合里全是int16_t型的整数, 这时要插入一个int32_t, 那么为了维持集合中数据类型的一致, 那么所有的数据都会被转换成int32_t类型, 涉及到内存的重新分配, 这时插入的复杂度就为O(N)了.
intset不支持降级操作.

**当集合对象每个值是整数, 且集合大小小于512个时, 采用整数作为底层结构.否则自动采用字典的结构**

#### 有序集合对象(ZSet)

**有序集合的编码可能两种, 一种是ziplist, 另一种是skiplist与dict的结合.**
ziplist作为集合和作为哈希对象是一样的, member和score顺序存放.按照score从小到大顺序排列
skiplist是一种跳跃表, 它实现了有序集合中的快速查找, 在大多数情况下它的速度都可以和平衡树差不多.但它的实现比较简单, 可以作为平衡树的替代品.它的结构比较特殊.下面分别是跳跃表skiplist和它内部的节点skiplistNode的结构体: 

```c
/* 
 * 跳跃表 
 */  
typedef struct zskiplist {  
    // 头节点,  尾节点  
    struct zskiplistNode *header,  *tail;  
    // 节点数量  
    unsigned long length;  
    // 目前表内节点的最大层数  
    int level;  
} zskiplist;  
/* ZSETs use a specialized version of Skiplists */  
/* 
 * 跳跃表节点 
 */  
typedef struct zskiplistNode {  
    // member 对象  
    robj *obj;  
    // 分值  
    double score;  
    // 后退指针  
    struct zskiplistNode *backward;  
    // 层  
    struct zskiplistLevel {  
        // 前进指针  
        struct zskiplistNode *forward;  
        // 这个层跨越的节点数量  
        unsigned int span;  
    } level[];  
} zskiplistNode;  
```

head和tail分别指向头节点和尾节点, 然后每个skiplistNode里面的结构又是分层的(即level数组)
用图表示, 大概是下面这个样子: 

<img src="http://www.milky.show/images/redis/redis_16.png" alt="http://www.milky.show/images/redis/redis_16.png" style="zoom: 33%;" />

**当集合的长度小于64字节, 且集合大小小于128时, 采用压缩列表作为底层结构.否则自动采用跳跃表和字典的结构**

**有序集合是比较特殊的结构, 采用跳跃表和字典双重结构: **

**当单独采用跳跃表时, 虽然保留跳跃表的优点, 但是获取集合的值时, 无法像字典那样效率达到O(1) **

**当单独采用字典结构时, 虽然获取值时效率较高, 但由于字典时无序的, 进行有序遍历或者排序时, 效率较差.**



## 面试

### 什么是 Redis

基于内存, KV 存储结构

KV: redis 通常是用来做缓存的, 只缓存一部分数据, 数据是不完整的, 所以不适合关系型

单线程: worker 单线程, iothreads 多线程

连接很多: 并发高

<img src="http://www.milky.show/images/redis/redis_80.png" alt="http://www.milky.show/images/redis/redis_80.png" style="zoom: 33%;" />

### 本地方法: 计算向数据移动, IO 优化

在 memcached 中, 只能将列表全部取出然后在应用内获取对应下标的值, 增加了网络 io 的开销, 而使用 redis, 可以在 redis 中计算出想要的数据, 极大地减少了网络 io 的开销

<img src="http://www.milky.show/images/redis/redis_77.png" alt="http://www.milky.show/images/redis/redis_77.png" style="zoom: 33%;" />

### 串行化/原子, 并行 VS 串行

Redis 是单线程的, 串行化, 执行命令需要 3 个步骤, 1: epoll 通知有 event 的到来, 2: 读取事件内容, 3: 本地计算结果

<img src="http://www.milky.show/images/redis/redis_76.png" alt="http://www.milky.show/images/redis/redis_76.png" style="zoom: 33%;" />

如果在多核 CPU 情况下, 此处有个小弊端, 因为 Redis 是单线程的, 所以 CPU 的利用率并不高, redis 的计算和 io 实际上是独立的, c1 的 io 要等到 c2 结束后才进行, 实际上是一种资源浪费, c1 的 io 与 c2 的 io 和计算完全可以并行进行, 所以在 Redis6.x 以后进行了 iothreads 多线程优化, 需要配置开启, 不是默认行为

<img src="http://www.milky.show/images/redis/redis_79.png" alt="http://www.milky.show/images/redis/redis_79.png" style="zoom: 33%;" />

在高并发交易场景下, 并发可能是 100, 但并行度是 2, 最终落到 db 时要保证是串行化, 如果使用传统 db 加锁性能低下, 如果使用 redis, 天然的单线程内存模型效率会大大提高

<img src="http://www.milky.show/images/redis/redis_78.png" alt="http://www.milky.show/images/redis/redis_78.png" style="zoom: 33%;" />

