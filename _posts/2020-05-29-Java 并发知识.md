---
layout: post
title: Java 并发知识
categories: [Java]
description: 
keywords: 
---

* content
{:toc}




## Lock 简介, 地位, 作用

锁是一种工具, 用于控制对共享资源的访问

Lock 和 Synchronized, 这两个是最常见的锁, 它们都可以达到线程安全的目的, 但是在使用上和功能上又有较大的不同

Lock 并不是用来代替 Synchronized 的, 而是当使用 Synchronized 不合适或不足以满足要求的时候, 来提供高级功能的

Lock 接口最常见的实现类是 ReentrantLock

### 为什么需要 Lock

#### 为什么 synchronized 不够用

效率低: 锁的释放情况少, 试图获得锁时不能设定超时, 不能中断一个正在试图获得锁的线程

不够灵活(读写锁更灵活): 加锁和释放的时机单一, 每个锁仅有单一的条件(某个对象), 可能是不够的

#### Lock 主要方法介绍

lock(): 最普通的获取锁, 如果锁已经被其他线程获取了, 则进行等待

tryLock(), tryLock(long time, TimeUnit unit) 和 lockInterruptibly()

Lock 不会像 Synchronized 一样在异常时自动释放锁, 因此最佳实践是, 在 finally 中释放锁, 以保证发生异常时锁一定释放



### 可见性保证

happens-before 原则



## 锁的分类

![http://www.milky.show/images/java/lock/lock_1.png](http://www.milky.show/images/java/lock/lock_1.png)

### 乐观锁和悲观锁

互斥同步锁(悲观锁)的劣势

*   阻塞和唤醒带来的性能劣势
*   永久阻塞: 如果持有锁的线程被永久阻塞, 比如遇到了无限循环, 死锁等活跃性问题, 那么等待该线程释放锁的那几个悲催的线程, 将永远也得不到执行
*   优先级反转

非互斥同步锁(乐观锁)

#### 悲观锁

如果我不锁住这个资源, 别人就会来争抢, 就会造成数据结果错误, 所以每次悲观锁为了确保结果的正确性, 会在每次获取并修改数据时, 把数据锁住, 让别人无法访问该数据, 这样就可以确保数据内容万无一失

Java 中的悲观锁的实现就是 synchronized 和 Lock 相关类

#### 乐观锁

认为自己在处理操作的时候不会有其他线程来干扰, 所以并不会锁住被操作对象

在更新的时候, 去对比在我修改的期间数据有没有被其他人改变过: 如果没被改变过, 就说明真的是只有我自己在操作, 那我就正常去修改数据

如果数据和我一开始拿到的不一样了, 说明其他人在这段时间内改过数据, 那我就不能继续刚才的更新数据过程了, 我会选择放弃, 报错, 重试等策略

乐观锁的实现一般都是利用 CAS 算法来实现的

#### 开销对比

悲观锁的原始开销要高于乐观锁, 但是特点是一劳永逸, 临界区持锁时间就算越来越差, 也不会对互斥锁的开销造成影响

乐观锁一开始的开销比悲观锁小, 但是如果自旋时间很长或者不停重试, 那么消耗的资源也会越来越多

#### 两种锁各自的使用场景

悲观锁适合并发写入多的情况, 适用于临界区斥锁时间比较长的情况, 悲观锁可以避免大量的无用自旋等消耗, 典型情况:

*   临界区有 IO 操作
*   临界区代码复杂或者循环量大
*   临界区竞争非常激烈

乐观锁适合并发写入少, 大部分是读取的场景, 不加锁的能让读取性能大福提高



### 可重入锁(ReentrantLock)和非可重入锁

#### 可重入锁

可以反复获得同一把锁, 内部维护了计数器, 避免死锁, 提升封装性

#### 非可重入锁

不可以重复获取同一把锁



### 公平锁和非公平锁

公平指的是按照线程请求的顺序来分配锁; 非公平指的是**不完全按照请求的顺序**, 在一定情况下可以插队

非公平也同样不提倡"插队"行为, 这里的非公平, 指的是"在合适的时机"插队, 而不是盲目插队

**非公平锁避免唤醒带来的空档期**

#### 公平锁

如果在创建 ReentrantLock 对象时, 参数填写为 true, 那么这就是个公平锁

#### 非公平锁

默认情况下都是非公平锁

### 共享锁(读锁)和排它锁(写锁)

共享锁, 又称为读锁, 获得共享锁之后, 可以查看但无法修改和删除数据, 其他线程此时也可以获取到共享锁, 也可以查看但无法修改和删除数据

排它锁又称为独占锁, 独享锁, synchronized 就是典型的排它锁, **其他线程无法读写**

**共享锁和排它锁的典型是读写锁 ReentrantReadWriteLock, 其中读锁是共享锁, 写锁是排它锁**

在没有读写锁之前, 我们假设使用 ReentrantLock, 那么虽然我们保证了线程安全, 但是也浪费了一定的资源: 多个读操作同时进行, 并没有线程安全问题

在读的地方使用读锁, 在写的地方使用写锁, 灵活控制, 如果没有写锁的情况下, 读是物阻塞的, 提高了程序的执行效率

#### 读写锁的规则

1.  多个线程只申请读锁, 都可以申请到
2.  如果有一个线程已经占用了读锁, 则此时其他线程如果要申请写锁, 则申请写锁的线程会一直等待释放读锁
3.  如果有一个线程已经占用了写锁, 则此时其他线程如果要申请写锁或者读锁, 则申请的线程会一直等待释放写锁

#### 读写锁的插队策略

公平锁: 不允许插队, 会完全按照顺序执行

非公平锁:

*   写锁可以随时插队, 保证在大量读的情况下可以写入
*   读锁仅在等待队列头结点不是想获取写锁的线程的时候可以插队

#### 读写锁的升降级

**ReentrantReadWriteLock 支持锁的降级(写锁变读锁), 不支持升级(容易造成死锁)**



### 自旋锁和阻塞锁

阻塞或唤醒一个 Java 线程需要操作系统切换 CPU 状态来完成, 这种状态转换需要耗费处理器时间, 如果同步代码块中的内容过于简单, 状态转换消耗的时间有可能比用户代码执行的时间还要常, 在许多场景中, 同步资源的锁定时间很短, 为了这一小段时间去切换线程, 线程挂起和恢复现场的花费可能会让系统得不偿失如果物理机有多个处理器, 能够让两个或以上的线程同时并行执行, 我们就可以让后面那个请求锁的线程不放弃 CPU 的执行时间, 看看持有锁的线程是否很快就会释放锁, 而为了让当前线程"稍等一下", 我们需要让当前线程进行自旋, 如果在自旋完成后前面锁定同步资源的线程已经释放了锁, 那么当前线程就可以不必阻塞而是直接获取同步资源, 从而避免切换线程的开销, 这就是自旋锁. 阻塞锁和自旋锁相反, 阻塞锁如果遇到没拿到锁的情况, 会直接把线程阻塞, 知道被唤醒.

如果被锁占用的时间很长, 那么自选的线程只会白白浪费处理器资源, 在自旋的过程中, 一直消耗 CPU, 所以虽然自旋锁的其实开销低于悲观锁, 但是随着自旋时间的增长, 开销也是线性增长的.

在 java1.5 版本及以上的并发框架 java.util.concurrent 的 atomic 包下的类基本都是自旋锁的实现.

AtomicInteger 的实现, 自旋锁的实现原理是 CAS, Atomicinteger 中调用 unsafe 进行自增操作的源码中的 do-while 循环就是一个自旋操作, 如果修改过程中遇到其他线程竞争导致没修改成功, 就在 while 里死循环, 直至修改成功.



### 可中断锁

在 Java 中, synchronized 就是不可中断锁, 而 Lock 是可中断锁, 因为 tryLock(time) 和 lockInterruptibly 都能响应中断

如果某一线程 A 正在执行锁中的代码, 另一线程 B 正在等待获取该锁, 可能由于等待时间过长, 线程 B 不想等待了, 想先处理其他事情, 我们可以中断它, 这就是可中断锁了.



### 锁优化

#### Java 虚拟机对锁的优化

自旋锁和自适应

锁消除

锁粗化

#### 我们写代码时如何优化

缩小同步代码块

尽量不要锁住方法

减少请求锁的次数

避免人为制造"热点"

锁中尽量不要再包含锁

选择合适的锁类型或合适的工具类





## 原子类

不可分割

一个操作是**不可中断**的, 几遍是多线程的情况下也可以保证

java.util.concurrent.atomic

元子类的作用和锁类似, 是为了保证并发情况下**线程安全**, 不过元子类相比于锁, 有一定的**优势**.

粒度更细: 原子变量可以把竞争范围缩小到边浪级别, 这是我们可以获得的最细粒度的情况了, 通常锁的粒度都要大于原子变量的粒度.

效率更高: 通常, 使用原子类的效率会比使用锁的效率更高, 除了**高度竞争**的情况.

### 6 类原子类总览

| 分类                               | 类                                                           |
| ---------------------------------- | ------------------------------------------------------------ |
| Atomic*基本类型原子类              | AtomicInteger<br />AtomicLong<br />AtomicBoolean             |
| Atomic*Array 数组类型原子类        | AtomicIntegerArray<br />AtomicLongArray<br />AtomicReferenceArray |
| Atomic*Reference 引用类型原子类    | AtomicReference<br />AtomicStampedReference<br />AtomicMarkableReference |
| Atomic*FieldUpdater 升级类型原子类 | AtomicIntegerFieldUpdater<br />AtomicLongFieldUpdater<br />AtomicReferenceFieldUpdater |
| Adder 累加器                       | LongAdder<br />DoubleAdder                                   |
| Accumulator 累加器                 | LongAccumulator<br />DoubleAccumulator                       |

### Atomic* 基本类型原子类常用方法

public final int get() // 获取当前的值

public final int getAndSet(int newValue) // 获取当前的值, 并且设置新的值

public final int getAndIncrement() // 获取当前的值, 并自增, 避免 a++ 问题

public final int getAndDecrement() // 获取当前的值, 并自减

public final int getAndAdd(int delta) // 获取当前的值, 并加上预期的值

boolean compareAndSet(int expect, int update) // 如果输入的数值等于预期值, 则以原子方式将该值设置为输入值(update)



### Adder 累加器

是 Java8 引入的, 相对是比较新的一个类

高并发下 LongAdder 比 AtomicLong 效率高, 不过本质是空间换时间

竞争激烈的时候, LongAdder 把不同线程对应到不同的 Cell 上进行修改, 降低了冲突的概率, 是多段锁的理念, 提高了并发性





## Java 中是如何利用 CAS 实现原子操作的

AtomicInteger 加载 Unsafe 工具, 从来**直接操作内存**数据.

用 Unsafe 来实现底层操作.

用 volatile 修饰 value 字段, 保证可见性.



## final 关键字和不变性

### 不变性(Immutable)

如果对象在创建后, 状态就不能被修改, 那么它就是不可变的.

例如: person 对象, age 和 name 都不能再变.

具有不变性的对象**一定是线程安全**的, 我们不需要对其采取任何额外的安全措施, 也能保证线程安全.

### final 的作用

**类防止被继承, 方法防止被重写, 变量防止被修改.**

天生是**线程安全**的, 而不需要额外的同步开销.

#### final 修饰变量

final instance variable(类中的 final 属性)

*   第一种是在声明变量的等号右边直接赋值
*   第二种就是构造函数中赋值
*   第三种就是在类的初始代码块中赋值(不常用)
*   如果不采用第一种赋值方法, 那么就必须在第 2,3 种挑一个来赋值, 而不能不赋值, 这是 final 语法所规定的

final static variable(类中的 static final 属性)

*   声明变量的等号右边直接赋值
*   static 初始代码块赋值, 但是不能用普通的初始代码块赋值

final local variable(方法中的 final 变量)

*   不规定赋值时机, 只要求在使用前必须赋值, 这和方法中的非 final 变量的要求也是一样的

#### final 修饰方法

构造方法不允许 final 修饰

普通方法不可被重写, 也就是不能被 override

static 方法不能被重写

#### final 修饰类

类不可被继承

典型的 String 类就是 final 的, 我们从没见过哪个类是继承 String 类的

### 注意点

被 final 修饰的变量, 意味着**值不能被修改**. 如果变量是对象, 那么对象的**引用不能变**, 但是对象自身的**内容依然可以变化.**

final 使用原则: 良好的编程习惯

### 不变性和 final 的关系

不变性并不意味着, 简单地用 final 修饰就是不可变

*   对于基本数据类型, 确实被 final 修饰后就具有不变性
*   但是对于对象类型, 需要改对象保证自身被创建后, 状态永远不会变才可以

如何利用 final 实现对象不可变

*   把所有属性都声明为 final?
*   一个属性是对象类型的不可变对象的正确例子

### 栈封闭技术

在方法里新建的局部变量, 实际上是存储在每个线程四有的栈空间, 而每个栈的栈空间是不能被其他线程所访问到的, 所以不会有线程安全问题. 这就是著名的"栈封闭"技术, 是"线程封闭"技术的一种情况







## 实现多线程的官方正确方法

### 方法一: 实现 Runnable 接口

实现 Runnable 接口更好, 解耦更好, 还可以继承类, 最终调用 target.run()

### 方法二: 继承 Thread 类

整个 run() 方法被重写



### 同时使用两种方法会怎么样?

从面向对象的思想去考虑, run 方法就被覆盖了, 经典的三行代码就会被覆盖, 所以不会调用 Runnable 的 run() 方法了









## 并发容器精讲

**ConcurrentHashMap**: 线程安全的 HashMap

**CopyOnWriteArrayList**: 线程安全的 List

**BlockingQueue**: 这是一个接口, 表示阻塞队列, 非常适合用于作为数据共享的通道

ConcurrentLinkedQueue: 高效的非阻塞并发队列, 使用链表实现. 可以看做一个线程安全的 LinkedList

ConcurrentSkipListMap: 是一个 Map, 使用跳表的数据结构进行快速查找



### 集合类的历史

Vector 和 Hashtable: 早期 JDK 线程安全的 AarrayList 和 HashMap, 性能不好, 因为方法都是用 synchronized 修饰的

HashMap 和 ArrayList: 这两个类不是线程安全的, 但是可以用 Collections.synchronizedList(new ArrayList\<E>()) 和 Collections.synchronizedMap(new HashMap\<E\>())使之变成线程安全的, 本质还是使用 synchronized

ConcurrentHashMap 和 CopyOnWriteArrayList: 取代同步的 HashMap 和同步的 ArrayList(时代巨轮滚滚向前)

### ConcurrentHashMap

#### Map 简介

HashMap: 根据 hashcode 定位, 允许 key 为 null, 线程不安全

Hashtable: 和 HashMap 功能一样, 但是性能低下, 已淘汰

LinkedHashMap: 是 HashMap 的子类

TreeMap: 实现了 SortedMap 接口, 可以排序

#### 为什么 HashMap 是线程不安全的

同时 put 碰撞导致数据丢失

同时 put 扩容导致数据丢失

HashMap 死循环造成的 CPU100%(JDK1.7 下存在), 因为在多线程情况下 HashMap 扩容造成循环链表

#### 为什么需要 ConcurrentHashMap

#### HashMap 分析

#### JDK1.7 的 ConcurrentHashMap 实现和分析

JDK1.7 中的 ConcurrentHashMap 最外层是多个 Segment, 每个 Segment 的底层数据结构与 HashMap 类似, 仍然是数组和链表组成的拉链法

每个 Segment 独立上 ReentrantLock 锁, 每个 Segnemnt 之间互不影响, 提高了并发效率

ConcurrentHashMap 默认有 16 个 Segments, 所以最多可以同时支持 16 个线程并发写(操作分别分布在不同的 Segment 上). 这个默认值可以在初始化的时候设置为其他值, 但是一旦初始化以后, 是不可以扩容的

#### JDK1.8 的 ConcurrentHashMap 实现和分析

putValue 流程

*   判断 key value 不为空
*   计算 hash 值
*   根据对应位置节点的类型来赋值, 或者 helpTransfer, 或者增长链表, 或者给红黑树增加节点
*   检查满足阈值就"红黑树化"
*   返回 oldValue

getValue 流程

*   计算 hash 值
*   找到对应的位置, 根据情况直接取值, 红黑树里取值, 遍历链表取值
*   返回找到的结果

#### 为什么要将 1.7 改为 1.8 的结构

数据结构

*   1.7 采用 Segment + 链表
*   1.8 采用 Node + 链表 + 红黑树

Hash 碰撞

*   1.7 会一直使用链表
*   1.8 首先使用链表, 当链表长度为 8 时转化为红黑树

保证并发安全

*   1.7 采用分段锁 Segment
*   1.8 采用 CAS + Synchronized

查询复杂度

*   1.7 是遍历链表O(n)
*   1.8 是遍历链表 O(n) + 遍历红黑树 O(logN)



红黑树的占用空间比链表大, 所以一开始使用链表, 当链表长度达到 8 时会转为红黑树, 但是达到 8 的概率是千万分之一, 如果达到 8 代表链表出了问题是一种极端情况, 要转为红黑树



#### ConcurrentHashMap 也不是线程安全的?

ConcurrentHashMap 本身肯定是线程安全的, 但是在组合操作下并不保证线程安全, 作者考虑到这种情况提供了 replace() 方法



### CopyOnWriteArrayList

#### 诞生的历史和原因

代替 Vector 和 SynchronizedList, 就和 ConcurrentHashMap 代替 SynchronizedMap 的原因一样

Vector 和 SynchronizedList 的锁的粒度太大, 并发效率相对比较低, 并且迭代时无法编辑

Copy-On-Write 并发容器还包括 CopyOnWriteArraySet, 用来代替同步 Set

#### 适用场景

读操作可以尽可能快, 而写即使慢一些也没有太大关系

读多写少: 黑名单, 监听器

#### 读写规则

回顾读写锁: 读读共享, 其他都互斥(写写互斥, 读写互斥, 写读互斥)

读写锁规则的升级: 读取是完全不用加锁的, 并且更厉害的是, 写入也不会阻塞读取操作. 只有写入和写入之间需要进行同步等待

#### 实现原理

CopyOnWrite 就是在写的时候复制一份新的出来, 这样写的过程中就是在一个全新的内存中, 读就不会受影响了

**创建新副本, 读写分离**

#### 缺点

数据一致性问题: CopyOnWrite 容器只能保证数据的最终一致性, 不能保证数据的实时一致性. 所以如果你希望写入的数据马上能读到, 请不要使用 CopyOnWrite 容器

内存占用问题: 因为 CopyOnWrite 的写是复制机制, 所以在进行写操作的时候, 内存里会同时驻扎两个对象的内存



### BlockingQueue

#### 为什么要使用队列

用队列可以在线程间传递数据: 生产者消费者模式, 银行转账.

考虑锁等线程安全问题的重任从"你"转移到了"队列"上.

#### 什么是阻塞队列

阻塞队列是具有阻塞功能的队列, 所以它首先是一个队列, 其次是具有阻塞功能.

通常阻塞队列的一端是给生产者放数据用, 另一端给消费者拿数据用. 阻塞队列是线程安全的, 所以生产者和消费者都可以是多线程的.

阻塞功能: 最有特色的两个带有阻塞功能的方法

take()方法: 获取并移除队列的头结点, 一旦如果执行 take 的时候, 队列里无数据, 则阻塞, 直到队列里有数据.

put()方法: 插入元素, 但是如果队列已满, 那么久无法继续插入, 则阻塞, 直到队列里有了空闲空间

是否有界(容量有多大): 这是一个非常重要的属性, 无界队列意味着里面可以容纳非常多(Integer.MAX_VALUE, 约为 2 的 31 次方, 是非常大的一个数, 可以近似认为是无限容量)

阻塞队列和线程池的关系: 阻塞队列是线程池的重要组成部分

#### 主要方法介绍

put, take

add(满了会抛出异常), remove(空了会抛出异常), element(返回队列头元素, 如果空了会抛出异常)

offer(增加, 会返回一个 boolean 值), poll(取出并删除, 如果为空会返回 null), peek(取出)

#### ArrayBlockingQueue

有界

指定容量

公平: 还可以指定是否需要保证公平, 如果想保证公平的话, 那么等待了最长时间的线程会被优先处理, 不过这会同时带来一定的性能 消耗

#### LinkedBlockingQueue

无界

容量 Integer.MAX_VALUE

内部结构: Node, 两把锁

#### PriorityBlockingQueue

支持优先级

自然顺序(而不是先进先出)

无界队列

PriorityQueue 的线程安全版本

#### SynchronousQueue

它的容量为 0

需要注意的是, SynchronousQueue 的容量不是 1 而是 0, 因为 SynchronousQueue 不需要去持有元素, 它所做的就是直接传递(direct handoff)

效率很高

SynchronousQueue 没有 peek 等函数, 因为 peek 的含义是取出头结点, 但是 SynchronousQueue 的容量是 0, 所以连头结点都没有, 也就没有 peek 方法. 同理, 没有 iterate 相关方法

是一个几号的用来直接传递的并发数据结构

SynchronousQueue 是线程池 Executors.newCachedThreadPool() 使用的阻塞队列



## 控制并发流程

### 什么是控制并发流程

控制并发流程的工具类, 作用就是帮助我们程序员更容易得让线程之间合作

让线程之间互相配合, 来满足业务逻辑

比如让线程 A 等待线程 B 执行完成后在执行等合作策略

| 类             | 作用                                                         | 说明                                                         |
| -------------- | ------------------------------------------------------------ | ------------------------------------------------------------ |
| Semaphore      | 信号量, 可以通过控制"许可证"数量, 来保证线程之间的配合       | 线程只有在拿到"许可证"后才能继续运行. 相比于其他的同步器, 更灵活. |
| CyclicBarrier  | 线程会等待, 直到足够多线程达到了事先规定的数目. 一旦达到触发条件, 就可以进行下一步的动作. | 适用于线程之间相互等待处理结果就绪的场景                     |
| Phaser         | 和 CyclicBarrier 类似, 但是计数可变                          | Java7 加入的                                                 |
| CountDownLatch | 和 CyclicBarrier 类似, 数量地见到 0 时, 触发动作             | 不可重复使用                                                 |
| Exchanger      | 让两个线程在合适时交换对象                                   | 适用场景: 当两个线程工作在同一个类的不同实例上时, 用于交换数据 |
| Condition      | 可以控制线程的"等待"和"唤醒"                                 | 是 Object.wait() 的升级版                                    |



### CountDownLatch 倒计时门闩

#### CountDownLatch 类的作用

并发流程控制的工具

*   倒数门闩
*   例子: 购物拼团; 大巴(游乐园坐过山车排队), 人满发车;
*   流程: 倒数结束之前, 一直处于等待状态, 直到倒计时结束了, 此线程才继续工作

#### 类的主要方法介绍

CountDownLatch(int count): 仅有一个构造函数, 参数 count 为需要倒数的数值

await(): 调用 await() 方法的线程会被挂起, 它会等待直到 count 值为 0 才继续执行

countDown(): 将 count 值减 1, 直到为 0 时, 等待的线程会被唤醒

#### 两个典型用法

用法一: 一个线程等待多个线程都执行完毕, 再继续自己的工作

用法二: 多个线程等待某一个线程的信号, 同时开始执行

### Semaphore 信号量

Semaphore 可以用来限制或管理数量有限的资源的使用情况

污染不能太多, 污染许可证只能发 3 张

信号量的作用是维护一个"许可证"的计数, 线程可以"获取"许可证, 那信号量剩余的许可证就减一, 线程也可以"释放"一个许可证, 那信号量剩余的许可证就加一, 当信号量所拥有的许可证数量为 0, 那么下一个还想要获取许可证的线程, 就需要等待, 直到有另外的线程释放了许可证

#### 信号量使用流程

初始化 Semaphore 并指定许可证的数量

在需要被现在的代码前加 acquire() 或者 acquireUninterruptibly() 方法

在任务执行结束后, 调用 release() 来释放许可证

#### 信号量的主要方法

new Semaphore(int permits, boolean fair): 这里可以设置是否要使用公平策略, 如果传入 true, 那么 Semaphore 会把之前等待的线程放到 FIFO 的队列里, 以便于当有了新的许可证, 可以分发给之前等待了最长时间的线程.

tryAcquire(): 看看现在有没有空闲的许可证, 如果有的话就获取, 如果没有的话也没关系, 我不必陷入阻塞, 我可以去做别的事, 过一会再来查看许可证的空闲情况.

tryAcquire(timeout): 和 tryAcquire()一样, 但是多了一个超时时间, 比如"在 3 秒内获取不到去可证, 我就去做别的事"

release(): 释放许可证

#### 注意点

获取和释放的许可证数量必须一致, 否则比如每次都获取 2 个但是只释放 1 个甚至不释放, 随着时间的推移, 到最后许可证数量不够用, 会导致程序卡死(虽然信号量类并不对是否和获取的数量做规定, 但是这是我们的编程规范, 否则容易出错)

注意在初始化 Semaphore 的时候设置公平性, 一般设置为 true 会更合理

并不是必须由获取许可证的线程释放那个许可证, 事实上, 获取和释放许可证对线程并无要求, 也是是 A 获取了, 然后由 B 释放, 只要逻辑合理即可

信号量的作用, 除了控制临界区最多同时有 N 个线程访问外, 另一个作用是可以实现"条件等待", 例如线程 1 需要在线程 2 完成准备工作后才能开始工作, 那么就线程 1 acquire(), 而线程 2 完成任务后 release(), 这样的话, 相当于是轻量级的 CountDownLatch

### Condition 接口(又称条件对象)

#### Condition 作用

当线程 1 需要等待某个条件的时候, 它就去执行 condition.await()方法, 一旦执行了 await()方法, 线程就会进入阻塞状态

然后通常会有另外一个线程, 假设是线程 2, 去执行对应的条件, 直到这个条件达成的时候, 线程 2 就会去执行 condition.signal()方法, 这时 JVM 就会从阻塞的线程里找, 找到那些等待该 condition 的线程, 当线程 1 就会收到可执行信号的时候, 它的线程状态就会变成 Runnable 可执行状

signalAll()会唤起所有的正在等待的线程

signal()是公平的, 只会唤起等待时间最长的线程

#### Condition 注意点

实际上, 如果说 Lock 用来代替 synchronized, 那么 Condition 就是用来代替相对应的 Object.wait/notify 的, 所以在用法和性质上, 几乎都一样

await 方法会自动释放持有的 Lock 锁, 和 Object.wait 一样, 不需要自己手动先释放锁

调用 await 的时候, 必须持有锁, 否则会抛出异常, 和 Object.wait 一样

### CyclicBarrier 循环栅栏

CyclicBarrier 循环栅栏和 CountDownLatch 很类似, 都能阻塞一组线程

当有大量线程相互配合, 分别计算不同人物, 并且需要最后统一汇总的时候, 我们可以使用 CyclicBarrier. CyclicBarrier 可以构造一个集结点, 当某一个线程执行完毕, 它就会到集结点等待, 知道所有线程都到了集结点, 那么该栅栏就被撤销, 所有线程再统一触发, 继续执行剩下的任务

#### CyclicBarrier 和 CountDownLatch 的区别

作用不同: CyclicBarrier 要等固定数量的线程都到达了栅栏位置才能继续执行, 而 CountDownLatch 只需等待数字到 0, 也就是说, CountDownLatch 用于事件, 但是 CyclicBarrier 是用于线程的

可重用性不同: CountDownLatch 在倒数到 0 并触发门闩打开后, 就不能再次使用了, 除非新建新的示例; 而 CyclicBarrier 可以重复使用



## AQS(AbstractQueuedSynchronizer, 并发灵魂人物, 进阶必备)

### 学习 AQS 的思路

学习 AQS 的目的主要是想理解原理, 提高技术, 以及应对面试

先从应用层面理解为什么需要他如何使用它, 然后再看一看我们 Java 代码的设计者是如何使用它的了解它的应用场景

这样之后我们再去分析它的结构, 这样的话我们就学习得更加轻松了

### 为什么需要 AQS

锁和协作类有共同点: 闸门

*   我们已经学过了 ReentrantLock 和 Semaphore, 有没有发现有共同点? 很相似?
*   事实上, 不仅是 ReentrantLock 和 Semaphore, 包括 CountDownLatch, ReentrantReadWriteLock 都有这样类似的"协作"(或者叫"同步")功能, 其实它们底层都用了一个共同的基类, 这就是 AQS

因为上面的那些协作类, 它们有很多工作都是类似的, 所以如果能提取出一个工具类, 那么就可以直接使用, 对于 ReentrantLock 和 Semaphore 而言就可以屏蔽很多细节, 只关注它们自己的"业务逻辑"就可以了

### Semaphore 和 AQS 的关系

Semaphore 内部有一个 Sync 类, Sync 类继承了 AQS

CountDownLatch 与 ReentrantLock 也一样

### AQS 的作用

AQS 是一个用于构建锁, 同步器, 协作工具类的工具类(框架). 有了 AQS 以后, 更多的协作工具类都可以很方便得被写出来

一句话总结: 有了 AQS, 构建线程协作类就容易多了

### AQS 的重要性, 地位

AbstractQueuedSynchronizer 是 DougLea 写的, 从 JDK1.5 加入的一个基于 FIFO 等待队列实现的一个用于实现同步器的基础框架, 我们用 IDE 看 AQS 的实现类, 可以发现实现类有以下这些

### AQS 内部原理解析

AQS 最核心的就是三大部分

*   state
    *   这里的 state 的具体含义, 会根据具体实现类的不同而不同, 比如在 Semaphore 里, 它表示"剩余的许可证的数量", 而在 CountDownLatch 里, 它表示"还需要倒数的数量"
    *   state 是 volatile 修饰的, 会被并发地修改, 所以所有修改 state 的方法都需要保证线程安全, 比如 getState, setState 以及 compareAndSetState 操作来读取和更新这个状态. 这些方法都依赖于 j.u.c.atomic 包的支持
*   控制线程抢锁和配合的 FIFO 队列
    *   这个队列用来存放"等待的线程", AQS 就是"排队管理器", 当多个线程争用同一把锁时, 必须有排队机制将那些没能拿到锁的线程串在一起. 当锁释放时, 锁管理器就会挑选一个合适的线程来占有这个刚刚释放的锁
    *   AQS 会维护一个等待的线程队列, 把线程都放到这个队列里
*   期望协作工具类去实现的获取/释放等重要方法
    *   这里的获取和释放方法, 是利用 AQS 的协作工具类里最重要的方法, 是由协作类自己去实现的, 并且含义各不相同
    *   获取操作会依赖 state 变量, 经常会阻塞
    *   释放操作不会阻塞

### 应用实例, 源码解析

### 利用 AQS 实现一个自己的 Latch 门闩



## Future 和 Callable

### Runnable 的缺陷

不能返回一个返回值

不能抛出 checked Exception 异常

### Callable 接口

类似于 Runnable, 被其它线程执行的任务

实现 call 方法

有返回值

### Future 类

#### Future 的主要方法

get() 方法: 获取结果, get 方法的行为取决于 Callable 任务的状态, 只有以下 5 种情况

1.  任务正常完成: get 方法会立刻返回结果
2.  任务尚未完成(任务还没开始或进行中): get 将阻塞并直到任务完成
3.  任务执行过程中抛出 Exception: get 方法会抛出 ExecutionException: 这里的抛出异常, 是 call() 执行时产生的那个异常, 看到这个异常类型是 java.util.concurrent.ExecutionException. 不论 call() 执行时抛出的异常类型是什么, 最后 get 方法抛出的异常类型都是 ExecutionException
4.  任务被取消: get 方法会抛出 CancellationException
5.  任务超时: get 方法有一个重载方法, 是传入一个延迟时间的, 如果事件到了还没有获得结果, get 方法就会抛出 TimeoutException

get(long timeout, TimeUnit unit): 有超时的获取

*   超时的需要很常见
*   用 get(long timeout, TimeUnit unit)方法时, 如果 acll()在规定时间内完成了任务, 那么就会正常获取到返回值,; 而如果在指定时间内没有计算出结果, 那么就会抛出 TimeoutException
*   超时不获取, 任务需取消

cancel() 方法: 取消任务的执行

1.  如果这个任务还没有开始执行, 那么这种情况最简单, 任务会被正常的取消, 未来也不会被执行, 方法返回 true
2.  如果任务已完成, 或者已取消: 那么 cancel() 方法会执行失败, 方法返回 false
3.  如果这个任务已经开始执行了, 那么这个取消方法将不会直接取消该任务, 而是会根据我们填的参数 mayInterruptIfRunning 做判断
    1.  Future.calcel(true) 适用于任务能够处理 interrupt
    2.  Future.cancel(false) 仅用于避免启动尚未启动的任务, 适用于未能处理 interrupt 的任务, 不清楚任务是否支持取消

isDone() 方法: 判断线程是否执行完毕, 不代表任务是否执行成功, 失败了也是执行完毕

isCancelled() 方法: 判断是否被取消

#### 用法 1: 线程池的 submit 方法返回 Future 对象

首先, 我们要给线程池提交我们的任务, 提交时线程池会立刻返回给我们一个空的 Future 容器. 当线程的任务一旦执行完毕, 也就是当我们可以获取结果的时候, 线程池便会把该结果填入到之前给我们的那个 Future 中取(而不是创建一个新的 Future), 我们此时便可以从该 Future 中获得任务执行的结果

#### 用法 2: 用 FutureTask 来创建 Future

用 FutureTask 来获取 Future 和任务的结果

FutureTask 是一种包装器, 可以吧 Callable 转化成 Future 和 Runnable, 它同时实现二者的接口, 所以它既可以作为 Runnable 被线程执行, 又可以作为 Future 得到 Callable 的返回值

把 Callable 实例当做参数, 生成 FutureTask 对象, 然后把这个对象当做一个 Runnable 对象, 用线程池或另起线程去执行这个 Runnable 对象, 最后通过 FutureTask 获取刚才执行的结果

#### Future 的注意点

当 for 循环批量获取 future 的结果时, 容易发生一部分线程很慢的情况, get 方法调用时应使用 timeout 限制

Future 的生命周期不能后退, 生命周期只能前进, 不能后退. 就和线程池的生命周期一样, 一旦完全完成了任务, 它就永远停在了"已完成"的状态, 不能重头再来

### Callable 和 Future 的关系

我们可以用 Future.get() 来获取 Callable 接口返回的执行结果, 还可以通过 Future.isDone() 来判断任务是否已经执行完成了, 以及取消这个任务, 限时获取任务的结果等

在 call() 未执行完毕之前, 调用 get() 的线程(假定此时是主线程)会被阻塞, 直到 call() 方法返回结果后, 此时 future.get() 才会得到该结果, 然后主线程才会切换到 runnable 状态

所以 Future 是一个存储器, 它存储了 call() 这个任务的结果, 而这个任务的执行时间是无法提前确定的, 因为这完全取决于 call() 方法执行的情况



## 请描述 synchronized 和 Reentrantlock 的底层实现及重入的底层原理

synchronized 的底层汇编还是 lock cmpxchg 命令

## 请描述锁的四种状态和升级过程

在 JDK1.2 时 synchronized 的性能非常差, 在 JDK1.6 后优化了锁的升级状态

**JDK 早期, synchronized 叫做重量级锁, 因为申请锁资源必须通过 kernel(内核), 早期 APP 可以直接系统调用底层硬件**

现代操作系统会分为两层, 内核态和用户态, 自己的 APP 就是用户态, 系统资源就是内核态, 如果用户态想访问内核态的资源需要通过 kernel 的允许, 将用户态转向内核态, 拿到结果后再从内核态返回用户态. 早期 synchronized 加锁就需要申请系统资源, 进行用户态和内核态的转换, 所以是重量级锁, 经过优化后在某些情况下不需要通过内核态就可以解决, 比如 CAS(轻量级锁), 只需要用户态就可以完成

![http://www.milky.show/images/mashibing/synchronized/syn_3.png](http://www.milky.show/images/mashibing/synchronized/syn_3.png)

### 无锁态

最后是 001

### 偏向锁

最后是 101, 用户态完成

将自己的线程号写进了 markword 上, 此时只是贴了一个自己的 id 上去, 并没有发生锁的竞争

多数 synchronized 方法, 在很多情况下, 只有一个线程在运行, 没有必要向内核态申请资源, 例如 StringBuffer 中的 sync 方法

**只要有另外的线程来竞争, 就会升级为轻量级锁**

### 轻量级锁, 自旋锁, 无锁(CAS)

最后是 00, 用户态完成

当发生了多线程争锁的情况, 哪个线程能将自己的 id 写进 markword 谁就能获得锁, 此时是在用户空间完成的 CAS 操作, 此时偏向锁的线程也会发起争锁, 但是会有一定优势

CAS 适合操作特别快或者线程数较小的情况, 因为自旋会消耗 CPU 资源

### 重量级锁

最后是 10, 需要向内核态申请

向操作系统申请锁

为什么有了自旋锁, 还需要重量级锁, 因为重量级锁不需要消耗 CPU 资源, 会将其他线程放到一个队列中(waitset),  因此不需要自旋的过程了

## 请谈一下 AQS, 为什么 AQS 的底层是 CAS + volatile

## 解释一下锁的四种状态

## 对象在内存中的布局

JOL = Java Object Layout(Java 对象内存布局)

在堆内存中 new 出来一个对象, 这个对象在堆中分为四个部分

1.  markword, 8 个字节, synchronized(o) 锁定对象的本质是修改了 markword, **使 markword 包含了锁的信息**, 我们平时所说的加锁, 就是修改对象的 markword 的内容

    *   锁信息, 无锁态, 偏向锁...
    *   GC 标记信息
    *   HashCode

    ![http://www.milky.show/images/mashibing/synchronized/syn_2.png](http://www.milky.show/images/mashibing/synchronized/syn_2.png)

2.  klass poniter, 是一个指针, 指向 T.class, 表名这个对象属于哪一个 class, 压缩是 4 字节, 不压缩是 8 字节

3.  instance state, 成员变量所占的位置, byte, short, int, long...

4.  padding, 对齐, 64 位虚拟机 padding 是需要 4 块内容可以被 8 字节整除, 如果前 3 块不能被 8 整除, 就用 padding 补齐

![http://www.milky.show/images/mashibing/synchronized/syn_1.png](http://www.milky.show/images/mashibing/synchronized/syn_1.png)

## Object o = new Object() 在内存中占了多少字节

16 字节

JOL 是 openjdk 的一个工具类

Object o = new Object();
sysout ClassLayout.parseInstance(o).toPrintable();

## 请描述一下锁的分类以及 JDK 的应用

## 自旋锁一定比重量级锁效率高吗

自旋是消耗CPU资源的，如果锁的时间长，或者自旋线程多，CPU会被大量消耗

重量级锁有等待队列，所有拿不到锁的进入等待队列，不需要消耗CPU资源

## 偏向锁一定比自旋锁效率高吗

**偏向锁是在 JVM 启动 4s 后开启的, 因为 JVM 启动时有很多内存区域需要进行加锁, 这时已经明确知道有多线程去竞争锁, 就不需要开启偏向锁了**

很多情况下我明知道会存在锁的竞争情况, 就不需要加偏向锁了, 如果加了偏向锁还存在一个偏向锁升级的过程, 反而效率会降低



不一定，在明确知道会有多线程竞争的情况下，偏向锁肯定会涉及锁撤销，这时候直接使用自旋锁

JVM启动过程，会有很多线程竞争（明确），所以默认情况启动时不打开偏向锁，过一段儿时间再打开



## synchronized vs Lock (CAS)

 在高争用 高耗时的环境下synchronized效率更高
 在低争用 低耗时的环境下CAS效率更高
 synchronized到重量级之后是等待队列（不消耗CPU）
 CAS（等待期间消耗CPU）

 一切以实测为准



## 锁消除 lock eliminate

```java
public void add(String str1,String str2){
    StringBuffer sb = new StringBuffer();
    sb.append(str1).append(str2);
}
```

我们都知道 StringBuffer 是线程安全的，因为它的关键方法都是被 synchronized 修饰过的，但我们看上面这段代码，我们会发现，sb 这个引用只会在 add 方法中使用，不可能被其它线程引用（因为是局部变量，栈私有），因此 sb 是不可能共享的资源，JVM 会自动消除 StringBuffer 对象内部的锁。



## 锁粗化 lock coarsening

```java
public String test(String str){
    int i = 0;
    StringBuffer sb = new StringBuffer():
    while(i < 100){
        sb.append(str);
        i++;
    }
    return sb.toString():
}
```

JVM 会检测到这样一连串的操作都对同一个对象加锁（while 循环内 100 次执行 append，没有锁粗化的就要进行 100  次加锁/解锁），此时 JVM 就会将加锁的范围粗化到这一连串的操作的外部（比如 while 虚幻体外），使得这一连串操作只需要加一次锁即可。



## 锁过程

偏向锁 - markword 上记录当前线程指针，下次同一个线程加锁的时候，不需要争用，只需要判断线程指针是否同一个，所以，偏向锁，偏向加锁的第一个线程 。hashCode备份在线程栈上 线程销毁，锁降级为无锁

有争用 - 锁升级为轻量级锁 - 每个线程有自己的LockRecord在自己的线程栈上，用CAS去争用markword的LR的指针，指针指向哪个线程的LR，哪个线程就拥有锁

自旋超过10次，升级为重量级锁 - 如果太多线程自旋 CPU消耗过大，不如升级为重量级锁，进入等待队列（不消耗CPU）-XX:PreBlockSpin



自旋锁在 JDK1.4.2 中引入，使用 -XX:+UseSpinning 来开启。JDK 6 中变为默认开启，并且引入了自适应的自旋锁（适应性自旋锁）。

自适应自旋锁意味着自旋的时间（次数）不再固定，而是由前一次在同一个锁上的自旋时间及锁的拥有者的状态来决定。如果在同一个锁对象上，自旋等待刚刚成功获得过锁，并且持有锁的线程正在运行中，那么虚拟机就会认为这次自旋也是很有可能再次成功，进而它将允许自旋等待持续相对更长的时间。如果对于某个锁，自旋很少成功获得过，那在以后尝试获取这个锁时将可能省略掉自旋过程，直接阻塞线程，避免浪费处理器资源。



偏向锁由于有锁撤销的过程revoke，会消耗系统资源，所以，在锁争用特别激烈的时候，用偏向锁未必效率高。还不如直接使用轻量级锁。











