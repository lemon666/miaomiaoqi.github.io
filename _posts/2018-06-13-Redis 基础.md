---
Vlayout: post
title: "Redis 基础"
categories: [NoSql]
description:
keywords:
---

* content
{:toc}
## 为什么使用Redis

**性能:** 我们在碰到需要执行耗时特别久,且结果不频繁变动的SQL,就特别适合将运行结果放入缓存.这样,后面的请求就去缓存中读取,使得请求能够迅速响应.

**并发:** 在大并发的情况下,所有的请求直接访问数据库,数据库会出现连接异常.这个时候,就需要使用redis做一个缓冲操作,让请求先访问到redis,而不是直接访问数据库.

## 单线程Redis为什么这么快?

纯内存操作

单线程操作,避免了频繁的上下文切换

基本对象使用多种底层数据结构,且灵活变化是redis高性能的另一个原因

**采用了非阻塞I/O多路复用机制**

我们现在要仔细的说一说I/O多路复用机制,因为这个说法实在是太通俗了,通俗到一般人都不懂是什么意思.博主打一个比方：小曲在S城开了一家快递店,负责同城快送服务.小曲因为资金限制,雇佣了一批快递员,然后小曲发现资金不够了,只够买一辆车送快递.

* 经营方式一

    客户每送来一份快递,小曲就让一个快递员盯着,然后快递员开车去送快递.慢慢的小曲就发现了这种经营方式存在下述问题
    
    几十个快递员基本上时间都花在了抢车上了,大部分快递员都处在闲置状态,谁抢到了车,谁就能去送快递
    
    随着快递的增多,快递员也越来越多,小曲发现快递店里越来越挤,没办法雇佣新的快递员了
    
    快递员之间的协调很花时间
    
    综合上述缺点,小曲痛定思痛,提出了下面的经营方式
    
* 经营方式二

    小曲只雇佣一个快递员.然后呢,客户送来的快递,小曲按送达地点标注好,然后依次放在一个地方.最后,那个快递员依次的去取快递,一次拿一个,然后开着车去送快递,送好了就回来拿下一个快递.

    对比上述两种经营方式对比,是不是明显觉得第二种,效率更高,更好呢.在上述比喻中:

每个快递员------------------>每个线程

每个快递-------------------->每个socket(I/O流)

快递的送达地点-------------->socket的不同状态

客户送快递请求-------------->来自客户端的请求

小曲的经营方式-------------->服务端运行的代码

一辆车---------------------->CPU的核数

1. 于是我们有如下结论:
   
    * 经营方式一就是传统的并发模型,每个I/O流(快递)都有一个新的线程(快递员)管理.

    * 经营方式二就是I/O多路复用.只有单个线程(一个快递员),通过跟踪每个I/O流的状态(每个快递的送达地点),来管理多个I/O流.

    下面类比到真实的redis线程模型,如图所示

    ![https://miaomiaoqi.github.io/images/redis/redis_1.png](https://miaomiaoqi.github.io/images/redis/redis_1.png)













## Redis 初识

### Redis 是什么

### Redis 的特性

#### 速度快

官方称 Redis 可以达到 10W OPS, 虽然实际上不会 100% 达到 10W OPS 但是几万 OPS 还是有的, 原因有如下 3 点

* 数据存储在内存中, 内存相较于寄存器来说便宜, 相较于硬盘来说速度又快许多, 足够满足日常需求

    ![https://miaomiaoqi.github.io/images/redis/redis_58.png](https://miaomiaoqi.github.io/images/redis/redis_58.png)

    | 类型   | 每秒读写次数 | 随机读写延迟 | 访问带宽   |
    | ------ | ------------ | ------------ | ---------- |
    | 内存   | 千万级       | 80ns         | 5GB        |
    | SSD 盘 | 35000        | 0.1-0.2ms    | 100~300MB  |
    | 机械盘 | 100 左右     | 10ms         | 100MB 左右 |

* 使用 C 语言编写

* 单线程模型

#### 持久化

Redis 所有的数据保持在内存中, 对数据的更新将异步地保存到磁盘上

#### 多种数据结构

Redis 支持 5 种经典数据结构

![https://miaomiaoqi.github.io/images/redis/redis_59.png](https://miaomiaoqi.github.io/images/redis/redis_59.png)

还支持其他的数据结构

* BitMaps: 位图
* HyperLogLog: 超小内存唯一值计数
* GEO: 地理信息定位

#### 支持多种编辑语言

Java, PHP, Python, Ruby, Lua, Nodejs

#### 功能丰富

发布订阅, Lua 脚本实现自定义功能, 事务, pipeline

#### 简单

最初的版本只有 23000 行代码, 源码易读, 不依赖外部, 单线程模型

#### 主从复制

#### 高可用, 分布式

从 Redis2.8 开始支持 Redis-Sentinel 高可用

从 Redis3.0 开始支持 Redis-Cluster 分布式

### Redis 典型使用场景

#### 缓存系统

![https://miaomiaoqi.github.io/images/redis/redis_60.png](https://miaomiaoqi.github.io/images/redis/redis_60.png)

#### 计数器功能

![https://miaomiaoqi.github.io/images/redis/redis_61.png](https://miaomiaoqi.github.io/images/redis/redis_61.png)

#### 消息队列系统

#### 排行榜

#### 社交网络

#### 实时系统

### Redis 单机安装

#### 安装

到官网下载, tar 解压缩, make&make install 安装

#### 可执行文件说明

redis-server: Redis 服务器

redis-cli: Redis 命令行客户端

redis-benchmark: Redis 性能测试工具

redis-check-aof: AOF 文件修复工具

redis-check-dump: RDB 文件检查工具

redis-sentinel: Sentinel 服务器(2.8 之后)

#### 三种启动方式

最简启动: redis-server 使用默认参数

动态参数启动: redis-server \-\-port 6380

配置文件启动: redis-server configPath

#### Redis 常用配置

daemonize: 是否是守护进程启动 no|yes

port: Redis 对外端口号, 默认 6379, 对应意大利女歌手的名字 Merz

logfile: Redis 系统日志

dir: Redis 工作目录

去除空格和注释输出 redis 配置并重定向到新的文件 `cat redis-6381.conf|grep -v "#"|grep -v "^$" > redis-6382.com`



## API 的理解和使用

### 通用命令

| **命令**        | **描述**                                                     | **用法**                                                     |      |
| --------------- | ------------------------------------------------------------ | ------------------------------------------------------------ | ---- |
| DEL             | (1)删除给定的一个或多个key<br/>(2)不存在的Key将被忽略        | DEL key1 [key2 ...]                                          | O(1) |
| EXISTS          | (1)检查给定key是否存在<br />(2)存在返回 1, 不存在返回 0, 线上可用 | EXISTS key                                                   | O(1) |
| EXPIRE          | (1)为给定key设置生存时间,key过期时它会被自动删除<br/>(2)对一个已经指定生存时间的Key设置执行EXPIRE,新的值会代替旧的值 | EXPIRE key seconds                                           | O(1) |
| EXPIREAT        | (1)同EXPIRE,但此命令指定的是UNIX时间戳,单位为秒              | EXPIRE key timestamp                                         | O(1) |
| KEYS            | (1)查找所有符合给定模式pattern的key,下面举一下例子<br/>(2)KEYS *匹配所有key<br/>(3)KEYS h?llo匹配hello、hallo、hxllo等<br/>(4)KEYS h*llo匹配hllo、heeeeello等<br/>(5)KEYS h[ae]llo匹配hello和hallo<br/>(6)特殊符号想当做查找内容经的使用\ <br />**(7)线上禁用该命令** | KEYS pattern                                                 | O(n) |
| DBSIZE          | 计算 key 的总数, 生产可用, 内部维护了计数器                  | DBSIZE                                                       | O(1) |
| MIGRATE         | (1)原子性地将key从当前实例传送到目标实例指定的数据库上<br/>(2)原数据库Key删除,新数据库Key增加<br/>(3)阻塞进行迁移的两个实例,直到迁移成功、迁移失败、等待超时三个之一发生 | MIGRATE host port key destination-db timeout [COPY] [REPLACE] |      |
| MOVE            | (1)将当前数据库的key移动到给定数据库的db中<br/>(2)执行成功的条件为当前数据库有key,给定数据库没有key | MOVE key db                                                  |      |
| PERSIST         | (1)移除给定key的生存时间,将key变为持久的                     | PERSIST key                                                  |      |
| RANDOMKEY       | (1)从当前数据库随机返回且不删除一个key,                      | RANDOMKEY                                                    |      |
| RENAME          | (1)将key改名为newkey<br/>(2)当key和newkey相同或key不存在,报错<br/>(3)newkey已存在,RENAME将覆盖旧值 | RENAME key newkey                                            |      |
| TTL             | (1)以秒为单位,返回给定的key剩余生存时间                      | TTL key                                                      |      |
| PTTL            | (1)以毫秒为单位,返回给定的key剩余生存时间                    | PTTL key                                                     |      |
| TYPE            | (1)返回key锁存储的值的类型, string, hash, list, set, zset, none | TYPE key                                                     | O(1) |
| OBJECT ENCODING | (1)显示数据类型的底层数据结构                                | OBJECT ENCODING key                                          |      |
| INFO MEMORY     | (1)查看内存使用情况                                          | INFO MEMORY                                                  |      |

#### 数据结构和内部编码

Redis 是基于内存的数据库, 内存相对来说还是比较贵的, 如果我们在使用数据结构时, 以时间换取空间, 可以使用一些压缩的结构比如 ziplist, 如果元素个数比较小的时候, 就可以用空间来换时间, 这就是内部编码的作用, 可以使我们的 redis 有一个更好的使用率, 我们在使用时不用关心具体内部编码的实现, 直接使用数据结构的 api 即可, 是一种面向接口编程的思想

![https://miaomiaoqi.github.io/images/redis/redis_62.png](https://miaomiaoqi.github.io/images/redis/redis_62.png)

#### redisObject 结构体

![https://miaomiaoqi.github.io/images/redis/redis_63.png](https://miaomiaoqi.github.io/images/redis/redis_63.png)

#### 单线程

**单线程为什么这么快**

* 纯内存
* 非阻塞 IO
* 避免线程切换和竞态消耗

**单线程要注意什么**

* 一次只运行一条命令

* 拒绝长(慢)命令, keys, flushall, flushdb, slow lua script, multi/exec, operate big value(collection)

* 其实不是单线程

    fysnc file descriptor

    close file descriptor





### 系统相关命令

| **命令**         | **描述**                                                     | **用法**                   |
| ---------------- | ------------------------------------------------------------ | -------------------------- |
| BGREWRITEAOF     | (1)手动触发AOF重写操作,用于减小AOF文件体积                   | BGREWRITEAOF               |
| BGSAVE           | (1)后台异步保存当前数据库的数据到磁盘                        | BGSAVE                     |
| CLIENT KILL      | (1)关闭地址为ip:port的客户端<br/>(2)由于Redis为单线程设计,因此当当前命令执行完之后才会关闭客户端 | CLIENT KILL ip:port        |
| CLIENT LIST      | (1)以可读的格式,返回所有连接到服务器的客户端信息和统计数据   | CLIENT LIST                |
| CONFIG GET       | (1)取得运行中的Redis服务器配置参数<br/>(2)支持*              | CONFIG GET parameter       |
| CONFIG RESETSTAT | (1)重置INFO命令中的某些统计数据,例如Keyspace hits、Keyspace misses等 | CONFIG RESETSTAT           |
| CONFIG REWRITE   | (1)对**启动Redis时指定的redis.conf文件进行改写**             | CONFIG REWRITE             |
| CONFIG SET       | (1)动态调整Redis服务器的配置而无需重启<br/>(2)修改后的配置**立即生效** | CONFIG SET parameter value |
| SELECT           | (1)切换到指定数据库,数据库索引index用数字指定,以0作为起始索引值<br/>(2)默认使用0号数据库 | SELECT index               |
| DBSIZE           | (1)返回当前数据库的Key的数量                                 | DBSIZE                     |
| DEBUG OBJECT     | (1)这是一个调试命令,不应当被客户端使用<br/>(2)key存在时返回有关信息,key不存在时返回错误 | DEBUG OBJECT key           |
| FLUSHALL         | (1)清空整个Redis服务器的数据<br />(2)线上禁用                | FLUSHALL                   |
| FLUSHDB          | (1)清空当前数据库中的所有数据                                | FLUSHDB                    |
| INFO             | (1)以一种易于解释且易于阅读的格式,返回Redis服务器的各种信息和统计数值(2)通过给定可选参数section,可以让命令只返回某一部分信息 | INFO [section]             |
| LASTSAVE         | (1)返回最近一次Redis成功将数据保存到磁盘上的时间,以UNIX时间戳格式表示 | LASTSAVE                   |
| MONITOR          | (1)实时打印出Redis服务器接收到的命令,调试用                  | MONITOR                    |
| SHUTDOWN         | (1)停止所有客户端<br/>(2)如果至少有一个保存点在等待,执行SAVE命令<br/>(3)如果AOF选项被打开,更新AOF文件<br/>(4)关闭Redis服务器 | SHUTDOWN [SAVE\|NOSAVE]    |





### 字符串类型

实际上type=string代表value存储的是一个普通字符串,那么对应的encoding可以是raw或者是int,如果是int则代表实际redis内部是按数值型类存储和表示这个字符串的,当然前提是这个字符串本身可以用数值表示,**比如"20"这样的字符串,当遇到incr、decr等操作时会转成数值型进行计算,此时redisObject的encoding字段为int**.如果你试图对name进行incr操作则报错.

#### 结构和命令

value 的值可是字符串, 可以是数字, 可以是 0,1 的二进制位, 上限是 512MB, 建议 100k 以内, 适用于缓存, 计数器, 分布式锁等等

| **命令** | **描述**                                                     | **用法**                                              | 时间复杂度 |
| -------- | ------------------------------------------------------------ | ----------------------------------------------------- | :--------: |
| SET      | (1)将字符串值 Value 关联到 Key<br/>(2)Key 已关联则覆盖,无视类型<br/>(3)原本 Key 带有生存时间 TTL,那么 TTL 被清除 | set key value [EX seconds] [PX milliseconds] [NX\|XX] |    O(1)    |
| SETEX    | (1)将 Value 关联到 Key<br/>(2)设置 Key 生存时间为 seconds,单位为秒<br/>(3)如果 Key 对应的 Value 已经存在,则覆盖旧值<br/>(4)SET 同时也可以设置失效时间, 是一个原子操作, 即关联值与设置生存时间同一时间完成 | setex key seconds value                               |    O(1)    |
| SETNX    | (1)将 Key 的值设置为Value,**当且仅当 Key 不存在**<br/>(2)若给定的 Key 已经存在 SEXNX 不做任何动作 | setnx key value                                       |    O(1)    |
| setxx    | (1)将 Key 的值设置为 Value, **当且仅当 Key 存在**<br/>(2)若给定的 Key 不存在 SEXXX 不做任何动作 | set key value xx                                      |    O(1)    |
| GET      | (1)返回 key 关联的字符串值<br/>(2)Key 不存在返回 nil<br/>(3)Key 存储的不是字符串,返回错误,因为 GET 只用于处理字符串 | GET key                                               |    O(1)    |
| MSET     | (1)同时设置一个或多个 Key-Value 键值对<br/>(2)某个给定 Key 已经存在,那么 MSET 新值会覆盖旧值<br/>(3)如果上面的覆盖不是希望的,那么使用 MSETNX 命令,**所有 Key 都不存在才会进行覆盖**<br/>(4)**MSET 是一个原子性操作**,所有 Key 都会在同一时间被设置,不会存在有些更新有些没更新的情况 | MSET key1 value1 [key1 value1 ...]                    |    O(n)    |
| MGET     | (1)返回一个或多个给定 Key 对应的 Value<br/>(2)某个 Key 不存在那么这个 Key 返回 nil | MGET key1 [key2 ...]                                  |    O(n)    |
| INCR     | (1)Key 中存储的数字值 +1,返回增加之后的值<br/>(2)Key 不存在,那么 Key 的值被初始化为 0 再执行 INCR<br/>(3)如果值包含错误类型或者字符串不能被表示为数字,那么返回错误<br/>(4)值限制在64位有符号数字表示之内,即-9223372036854775808~9223372036854775807 | INCR key                                              |    O(1)    |
| DECR     | (1)Key 中存储的数字值 -1<br/>(2)其余同 INCR                  | DECR key                                              |    O(1)    |
| INCRBY   | (1)将 key 所存储的值加上增量返回增加之后的值<br/>(2)其余同 INCR | INCRBY key increment                                  |    O(1)    |
| DECRBY   | (1)将 key 所存储的值减去减量 decrement<br/>(2)其余同 INCR    | DECRBY key decrement                                  |    O(1)    |
| APPEND   | (1)给指定 key 的 value 追加字符串,并返回新字符串的长度       | append key value                                      |    O(1)    |
| GETSET   | (1)设置 key 的值,并返回 key 旧的值                           | getset key newvalue                                   |    O(1)    |
| STRLEN   | (1)取指定 key 的 value 的长度(注意中文)                      | strlen key                                            |    O(1)    |

#### 快速实战

记录网站每个用户个人主页的访问量

```bash
incr userid:pageview(单线程, 无竞争)
```

缓存视频的基本信息(数据源在 MySQL 中), 伪代码

```java
public VideoInfo get(long id){
	String redisKey = redisPrefix + id;
	VideoInfo videInfo = redis.get(redisKey);
	if(videoInfo == null) {
		videoInfo = mysql.get(id);
		if(videoInfo != null) {
			// 序列化
			redis.set(redisKey, serialize(videoInfo));
		}
	}
    return videoInfo;
}
```

分布式 id 生成器, 不同的应用获取一个自增的 id, 因为 redis 单线程的, 所以不同的服务肯定获得不同的值

```bash
incr counter
```

### 哈希类型, 可以对key进行分类

#### 结构和命令

Hash是一个String类型的field和value之间的映射表,即redis的Hash数据类型的key(hash表名称)对应的value实际的内部存储结构为一个HashMap,因此Hash特别适合存储对象.相对于把一个对象的每个属性存储为String类型,将整个对象存储在Hash类型中会占用更少内存.

当前HashMap的实现有两种方式：当HashMap的成员比较少时Redis为了节省内存会采用类似一维数组的方式来紧凑存储,而不会采用真正的HashMap结构,这时对应的value的redisObject的encoding为zipmap,当成员数量增大时会自动转成真正的HashMap,此时encoding为ht.

用一个对象来存储用户信息,商品信息,订单信息等等.

![https://miaomiaoqi.github.io/images/redis/redis_2.png](https://miaomiaoqi.github.io/images/redis/redis_2.png)

| **命令** | **描述**                                                     | **用法**                                    | 时间复杂度 |
| -------- | ------------------------------------------------------------ | ------------------------------------------- | ---------- |
| HSET     | (1)将哈希表Key中的域field的值设为value<br/>(2)key不存在,一个新的Hash表被创建<br/>(3)field已经存在,旧的值被覆盖 | HSET key field value                        | O(1)       |
| HSETNX   | (1)设置key对应的HashMap中的field的value,如果 field 已经存在, 则失败 | hsetnx key field value                      | O(1)       |
| HGET     | (1)返回哈希表key中给定域field的值                            | HGET key field                              | O(1)       |
| HDEL     | (1)删除哈希表key中的一个或多个指定域<br/>(2)不存在的域将被忽略 | HDEL key filed1 [field2 ...]                | O(1)       |
| HEXISTS  | (1)查看哈希表key中,给定 field 是否存在,存在返回1,不存在返回0 | HEXISTS key field                           | O(1)       |
| HGETALL  | (1)返回哈希表key中,所有的域和值                              | HGETALL key                                 | O(n)       |
| HINCRBY  | (1)为哈希表key中的域field加上增量increment<br/>(2)其余同INCR命令 | HINCRYBY key filed increment                | O(1)       |
| HLEN     | (1)返回哈希表key中 field 的数量                              | HLEN key                                    | O(1)       |
| HMGET    | (1)返回哈希表key中,一个或多个给定域的值<br/>(2)如果给定的域不存在于哈希表,那么返回一个nil值 | HMGET key field1 [field2 ...]               | O(n)       |
| HMSET    | (1)同时将多个field-value对设置到哈希表key中<br/>(2)会覆盖哈希表中已存在的域<br/>(3)key不存在,那么一个空哈希表会被创建并执行HMSET操作 | HMSET key field1 value1 [field2 value2 ...] | O(n)       |
| HKEYS    | (1)返回哈希表key中的所有域                                   | HKEYS key                                   | O(n)       |
| HVALS    | (1)返回哈希表key中所有的值                                   | HVALS key                                   | O(n)       |

#### 快速实战

记录网站每个用户个人主页的访问量, 每次自增 1

```
hincrby user:1:info pageview 1
```

缓存视频的基本信息(数据源在 mysql 中)伪代码

```java
public VideoInfo get(long id) {
	String redisKey = redisPrefix + id;
	Map<String, String> hashMap = redis.hgetAll(redisKey);
	VideoInfo videoInfo = transferMapToVideo(hashMap);
	if(videoInfo == null) {
		videoInfo = mysql.get(id);
		if(videoInfo != null) {
			redis.hmset(redisKey, transferVideoToMap(videoInfo));
		}
	}
}
```



### 列表类型, 元素有序可重复

Redis的List类型其实就是每一个元素都是String类型的**双向链表**.我们可以从链表的头部和尾部添加或者删除元素.这样的List既可以作为栈,也可以作为队列使用.

如好友列表,粉丝列表,消息队列,最新消息排行等.另外还有一个就是,可以利用lrange命令,做**基于redis的分页功能**,性能极佳,用户体验好.

![https://miaomiaoqi.github.io/images/redis/redis_3.png](https://miaomiaoqi.github.io/images/redis/redis_3.png)

#### 结构和命令

| **命令**  | **描述**                                                     | **用法**                              | 时间复杂度 |
| --------- | ------------------------------------------------------------ | ------------------------------------- | ---------- |
| LPUSH     | (1)将一个或多个值value插入到列表key的表头<br/>(2)如果有多个value值,那么各个value值按从左到右的顺序依次插入表头<br/>(3)key不存在,一个空列表会被创建并执行LPUSH操作<br/>(4)key存在但不是列表类型,返回错误 | LPUSH key value1 [value2 ...]         | O(1~n)     |
| LPUSHX    | (1)将值value插入到列表key的表头,当且key存在且为一个列表<br/>(2)key不存在时,LPUSHX命令什么都不做 | LPUSHX key value1 [value2...]         | O(1~n)     |
| LPOP      | (1)移除并返回列表key的头元素                                 | LPOP key                              | O(1)       |
| LRANGE    | (1)返回列表key中指定区间内的元素,区间以偏移量start和end指定<br/>(2)start和end都以0位底<br/>(3)可使用负数下标,-1表示列表最后一个元素,-2表示列表倒数第二个元素,以此类推<br/>(4)start大于列表最大下标,返回空列表<br/>(5)stop大于列表最大下标,stop=列表最大下标 | LRANGE key start end(包含 end)        | O(n)       |
| LREM      | (1)根据count的值,移除列表中与value相等的元素<br/>(2)count>0表示从头到尾搜索,移除与value相等的元素,数量为count<br/>(3)count<0表示从从尾到头搜索,移除与value相等的元素,数量为count<br/>(4)count=0表示移除表中所有与value相等的元素 | LREM key count value                  | O(n)       |
| LSET      | (1)将列表key下标为index的元素值设为value<br/>(2)index参数超出范围,或对一个空列表进行LSET时,返回错误 | LSET key index value                  | O(n)       |
| LINDEX    | (1)返回列表key中,下标为index的元素                           | LINDEX key index                      | O(n)       |
| LINSERT   | (1)将值value插入列表key中,位于pivot前面或者后面插入 value 元素<br/>(2)pivot不存在于列表key时,不执行任何操作<br/>(3)key不存在,不执行任何操作 | LINSERT key BEFORE\|AFTER pivot value | O(n)       |
| LLEN      | (1)返回列表key的长度<br/>(2)key不存在,返回0                  | LLEN key                              | O(1)       |
| LTRIM     | (1)对一个列表进行修剪,让列表只返回指定区间内的元素,**不存在指定区间内的都将被移除** | LTRIM key start end                   | O(n)       |
| RPOP      | (1)移除并返回列表key的尾元素                                 | RPOP key                              | O(1)       |
| RPOPLPUSH | 在一个原子时间内,执行两个动作：<br/>(1)将列表source中最后一个元素弹出并返回给客户端<br/>(2)将source弹出的元素插入到列表desination,作为destination列表的头元素 | RPOPLPUSH source destination          |            |
| RPUSH     | (1)将一个或多个值value插入到列表key的表尾                    | RPUSH key value1 [value2 ...]         | O(1~n)     |
| RPUSHX    | (1)将value插入到列表key的表尾,当且仅当key存在并且是一个列表<br/>(2)key不存在,RPUSHX什么都不做 | RPUSHX key value                      |            |

#### 快速实战

根据时间轴展示微博内容, 当有用户更新微博时, 将用户的 id 使用 rpush 存入 list 中, 每次 lrange 获取 id, 并根据 id 找到对应的微博内容

### 集合类型, 元素是无序的, 元素不能重复. 并集, 交集, 差集

因为set堆放的是一堆不重复值的集合.所以可以做**全局去重**的功能.为什么不用JVM自带的Set进行去重？因为我们的系统一般都是集群部署,使用JVM自带的Set,比较麻烦,难道为了一个做一个全局去重,再起一个公共服务,太麻烦了.
另外,就是利用交集、并集、差集等操作,可以计算**共同喜好,全部的喜好,自己独有的喜好等功能**

Redis 集合(Set类型)是一个无序的String类型数据的集合,类似List的一个列表,与List不同的是Set不能有重复的数据.实际上,Set的内部是用HashMap实现的,Set只用了HashMap的key列来存储对象

**集合有取交集、并集、差集等操作,因此可以求共同好友、共同兴趣、分类标签等**

#### 结构和命令

| **命令**    | **描述**                                                     | **用法**                              | 时间复杂度 |
| ----------- | ------------------------------------------------------------ | ------------------------------------- | ---------- |
| SADD        | (1)将一个或多个member元素加入到key中,已存在在集合的member将被忽略<br/>(2)假如key不存在,则只创建一个只包含member元素做成员的集合<br/>(3)当key不是集合类型时,将返回一个错误 | SADD key member1 [member2 ...]        | O(1)       |
| SCARD       | (1)返回key对应的集合中的元素数量                             | SCARD key                             | O(1)       |
| SDIFF       | (1)返回一个集合的全部成员,该集合是第一个Key对应的集合和后面key对应的集合的差集 | SDIFF key [key ...]                   |            |
| SDIFFSTORE  | (1)和SDIFF类似,但结果保存到destination集合而不是简单返回结果集<br/>(2) destination如果已存在,则覆盖 | SDIFFSTORE destionation key [key ...] |            |
| SINTER      | (1)返回一个集合的全部成员,该集合是所有给定集合的交集<br/>(2)不存在的key被视为空集 | SINTER key [key ...]                  |            |
| SINTERSTORE | (1)和SINTER类似,但结果保存早destination集合而不是简单返回结果集<br/>(2)如果destination已存在,则覆盖<br/>(3)destination可以是key本身 | SINTERSTORE destination key [key ...] |            |
| SUNION      | (1)返回一个集合的全部成员,该集合是所有给定集合的并集<br/>(2)不存在的key被视为空集 | SUNION key [key ...]                  |            |
| SUNIONSTORE | (1)类似SUNION,但结果保存到destination集合而不是简单返回结果集<br/>(2)destination已存在,覆盖旧值<br/>(3)destination可以是key本身 | SUNION destination key [key ...]      |            |
| SISMEMBER   | (1)判断member元素是否key的成员,0表示不是,1表示是             | SISMEMBER key member                  |            |
| SMEMBERS    | (1)返回集合key中的所有成员<br/>(2)不存在的key被视为空集      | SMEMBERS key                          |            |
| SMOVE       | (1)原子性地将member元素从source集合移动到destination集合<br/>(2)source集合中不包含member元素,SMOVE命令不执行任何操作,仅返回0<br/>(3)destination中已包含member元素,SMOVE命令只是简单做source集合的member元素移除 | SMOVE source desination member        |            |
| SPOP        | (1)**移除**并返回集合中的一个随机元素,如果count不指定那么随机返回一个随机元素<br/>(2)count为正数且小于集合元素数量,那么返回一个count个元素的数组且数组中的**元素各不相同**<br/>(3)count为正数且大于等于集合元素数量,那么返回整个集合<br/>(4)count为负数那么命令返回一个数组,数组中的**元素可能重复多次**,数量为count的绝对值 | SPOP key [count]                      |            |
| SRANDMEMBER | (1)如果count不指定,那么返回集合中的一个随机元素<br/>(2)count同上<br />(3)不会破坏集合元素 | SRANDMEMBER key [count]               |            |
| SREM        | (1)移除集合key中的一个或多个member元素,不存在的member将被忽略 | SREM key member1 [member2 ...]        | O(1)       |

#### 快速实战

打标签(tag), 可以方便查看标签下的用户, 也可以做交集并集查看共同标签

```
sadd user:1:tags tag1 tag2 tag5
sadd user:2:tags tag2 tag3 tag5
...
sadd user:k:tags tar1 tag2 tar4

sadd tag1:users user1 user3
sadd tag2:users user1 user2 user3
...
sadd tagk:users user1 user2
```



### 有序集合类型, 有序的set, 元素不能重复但有序

SortSet顾名思义,是一个排好序的Set,它在Set的基础上增加了一个顺序属性score,这个属性在添加修改元素时可以指定,每次指定后,SortSet会自动重新按新的值排序.

sorted set的内部使用HashMap和跳跃表(SkipList)来保证数据的存储和有序,HashMap里放的是成员到score的映射,而跳跃表里存放的是所有的成员,排序依据是HashMap里存的score. 

**可以做排行榜应用,取TOP N操作.可以用来做延时任务.最后一个应用就是可以做范围查找.**

#### 结构和命令

| **命令**         | **描述**                                                     | **用法**                                                     | 时间复杂度  |
| ---------------- | ------------------------------------------------------------ | ------------------------------------------------------------ | ----------- |
| ZADD             | (1)将一个或多个member元素及其score值加入有序集key中<br/>(2)如果member已经是有序集的成员,那么更新member对应的score并重新插入member保证member在正确的位置上<br/>(3)score可以是整数值或双精度浮点数 | ZADD key score1 member1 [[score2 member2] [score3 member3] ...] | O(logN)     |
| ZCARD            | (1)返回有序集key的元素个数                                   | ZCARD key                                                    | O(1)        |
| ZCOUNT           | (1) 返回有序集key中,score值>=minScore且<=maxScore的成员的数量 | ZCOUNT key minScore maxScore                                 | O(logN + m) |
| ZSCORE           | (1) 返回元素的分数                                           | ZSCORE key member                                            | O(1)        |
| ZRANGE           | (1)返回有序集key中指定区间内的成员,成员位置按score从小到大排序<br/>(2)具有相同score值的成员按字典序排列<br/>(3)需要成员按score从大到小排列,使用ZREVRANGE命令<br/>(4)下标参数start和end都以0为底,也可以用负数,-1表示最后一个成员,-2表示倒数第二个成员<br/>(5)可通过WITHSCORES选项让成员和它的score值一并返回 | ZRANGE key start end [WITHSCORES]                            | O(logN + m) |
| ZREVRANGE        | (1)返回有序集key中,指定区间内的成员.其中成员的位置按score值递减(从大到小)来排列 | ZREVRANGE key start end                                      | O(logN + m) |
| ZRANGEBYSCORE    | (1)返回有序集key中,指定分数范围的元素列表                    | ZRANGEBYSCORE key minScore maxScore [WITHSCORES]             | O(logN + m) |
| ZRANK            | (1)返回有序集key中成员member的排名,有序集成员按score值从小到大排列<br/>(2)排名以0为底,即score最小的成员排名为0<br/>(3)ZREVRANK命令可将成员按score值从大到小排名 | ZRANK key member                                             |             |
| ZREVRANK         | (1)得成员按score值递减(从大到小)排列的排名                   |                                                              |             |
| ZREM             | (1)移除有序集key中的一个或多个成员,不存在的成员将被忽略<br/>(2)当key存在但不是有序集时,返回错误 | ZREM key member1 [member2 ...]                               |             |
| ZREMRANGEBYRANK  | (1)移除有序集key中指定排名区间内的所有成员                   | ZREMRANGEBYRANK key start end                                | O(logN + m) |
| ZREMRANGEBYSCORE | (1)移除有序集key中,所有score值>=minScore且<=maxScore之间的成员 | ZREMRANGEBYSCORE key minScore maxScore                       | O(logN + m) |
| ZINCRBY          | (1)如果key对应的zset中已经存在元素member,则对member的score属性加指定的值 | ZINCRBY key score member                                     | O(1)        |



## Jedis 客户端

Jedis 是基于 Java 语言的 Redis 客户端

### Jedis 直连

生成一个 Jedis 对象, 这个对象负责和指定 Redis 节点通信

```java
Jedis jedis = new Jedis("127.0.0.1", 6379);
```

jedis 执行 set 操作

```java
jedis.set("hello", "world");
```

jedis 执行 get 操作, value="world"

```java
String value = jedis.get("hello");
```

Jedis(String host, int port, int connectionTimeout, int soTimeout) 构造函数参数意义

host: Redis 节点的所在机器的 ip

port: Redis 节点的端口

connectionTimeout: 客户端连接超时

soTimeout: 客户端读写超时

### Jedis 连接池配置

初始化 Jedis 连接池, 通常来讲 JedisPool 是单例的

```java
GenericObjectPoolConfig poolConfig = new GenericObjectPoolConfig();
JedisPool jedisPool = new JedisPool(poolConfig, "127.0.0.1", 6379);
```

**资源数配置**

| 参数名     | 含义                          | 默认值 | 使用建议 |
| ---------- | ----------------------------- | ------ | -------- |
| maxTotal   | 资源池最大连接数              | 8      |          |
| maxIdle    | 资源池允许最大空闲连接数      | 8      |          |
| minIdle    | 资源池确保最少空闲连接数      | 0      |          |
| jmxEnabled | 是否开启 jmx 监控, 可用于监控 | true   | 建议开启 |

* maxTotal

    这是一个比较难确定的参数值, 举个例子

    1. 命令平均执行时间 0.1ms = 0.001s
    2. 业务需要 50000QPS
    3. maxTotal 理论值 = 0.001 * 50000 = 50 个, 实际要偏大一些

    **业务希望 Redis 并发量**

    **客户端执行命令时间**

    **Redis 资源: 例如 nodes(应用个数) * maxTotal 是不能超过 redis 的最大连接数(config get maxclients)**

    **资源开销, 例如虽然希望控制空闲连接, 但是不希望因为连接池的频繁释放创建连接造成不必要开销**

* 适合的 maxIdle 和 minIdle

    建议 maxIdle = maxTotal, 假如 maxTotal 是 100, maxIdle 是 50, 当有第 51 个连接时, 就会使用 new Jedis 创建新的连接, 这个过程也是耗费资源的

    建议预热 minIdle, 减少第一次启动后的新连接开销



**借还参数**

| 参数名             | 含义                                                         | 默认值           | 使用建议         |
| ------------------ | ------------------------------------------------------------ | ---------------- | ---------------- |
| blockWhenExhausted | 当资源池用尽后, 调用者是否要等待. 只有当为 true 时, 下面的 maxWaitMillis 才会生效 | true             | 建议使用默认值   |
| maxWaitMillis      | 当资源池连接用尽后, 调用者的最大等待时间(单位为毫秒)         | -1: 表示永不超时 | 不建议使用默认值 |
| testOnBorrow       | 向资源池借用连接时是否做连接有效性检测(ping), 无效连接会被移除 | false            | 建议 false       |
| testOnReturn       | 向资源池归还连接时是否做连接有效性检测(ping), 无效连接会被移除 | false            | 建议 false       |



## 瑞士军刀 Redis

### 慢查询

#### 生命周期

1. 客户端发送命令
2. 排队
3. 执行命令
4. 返回结果

慢查询一般发生在第 3 阶段

客户端超时不一定慢查询, 但慢查询是客户端超时的一个因素

#### 两个配置

**慢查询是一个先进先出的队列, 队列是固定长度的, 满了之后会出队一个元素, 保存在内存中, 不会持久化**

**slowlog-max-len:** 设置队列长度

**slowlog-log-slower-than:** 慢查询阈值(单位: 微妙), 该值等于 0 记录所有命令, 小于 0 不记录任何命令, 1毫秒等于 1000 微妙

#### 配置方法

1. **默认值**

    config get slowlog-max-len=128

    config get slowlog-log-slower-than=10000

2. 修改配置文件重启(不推荐)

3. 动态配置

    config set slowlog-max-len 1000

    config set slowlog-log-slower-than 1000

#### 三个命令

slowlog get [n]: 获取 n 条慢查询队列

slowlog len: 获取慢查询队列长度

slowlog reset: 清空慢查询队列

#### 运维经验

slowlog-max-len 不要设置过小, 通常设置 1000 左右

slowlog-log-slower-than 不要设置过大, 默认 10ms, 通常设置 1ms = 1000 微秒, 根据业务 qps 来决定

理解命令生命周期, 更容易定位慢在哪里

定期持久化慢查询

### pipeline

如果我们发送 n 条命令, 那么就是 n 次网络时间 + n 次命令时间, 如果使用流水线(pipeline), 会将 n 条命令打包发送给服务端, 服务端会将 n 条结果一次返回, 消耗是 1 次网络时间 + n 次命令时间, 这就是流水线的作用, 减少网络开销

| 命令   | N 个命令操作        | 1 次 pipeline(N 个命令) |
| ------ | ------------------- | ----------------------- |
| 时间   | n 次网络 + n 次命令 | 1 次网络 + n 次命令     |
| 数据量 | 1 条命令            | n 条命令                |

#### 使用 JedisPipeline

没有 pipeline 设置 10000 个 key, 1W hset 花费 50s

```java
Jedis jedis = new Jedis("127.0.0.1", 6379);
for(int i = 0; i < 10000; i++) {
	jedis.hset("hashKey" + i, "field" + i, "value" + i);
}
```

**使用 pipeline 操作**, 拆分 10000 条命令, 执行 100 次, 每次执行 100 条命令, 花费 0.7s

```java
Jedis jedis = new Jedis("127.0.0.1", 6379);
for(int i = 0; i < 10000; i++) {
	Pipeline pipeline = jedis.pipelined();
	for(int j = i * 100; j < (i + 1) * 100; j++) {
		pipeline.hset("hashKey" + j, "field" + j, "value" + j);
	}
	pipeline.syncAndReturnAll();
}
```

#### 使用建议

注意每次 pipeline 携带数据量

pipeline 每次只能作用在一个 Redis 节点上

注意原子性问题, 与 M 命令相比, pipeline 会将命令拆分执行, 不是原子的, 而 M 命令是原子的

### 发布订阅

### Bitmap

Redis 可以直接操作数据的位数据

### HyperLogLog

### GEO



## Redis 持久化的取舍和选择

Redis 的所有数据都保持在内存中, 对数据的更新将异步地保存到磁盘上

持久化的方式

* 快照: 某一个时间点的备份, mysqldump, redis rdb
* 写日志: 将所有的操作都记录到日志中, 当需要恢复的时候只需要将日志中的操作从走一遍即可, mysql binlog, hbase hlog, redis aof

### RDB快照

把内存中的数据来一份一模一样的放在硬盘中, **会丢失掉最后一部分未存储的数据**, 适合大规模的数据恢复, 对数据完整性和一致性要求不高, 默认是这种方式

Redis会单独创建(fork)一个子进程来进行持久化, 会先将数据写入到一个临时文件中, 待持久化过程结束后, 再用这个临时文件替换上次持久化的文件, 整个过程中, 主进程不进行任何IO操作, 这就确保了极高的性能

隐患: 若当前的进程数据量庞大, fork之后数据量*2, 会造成服务器压力过大, 所以超过服务器 50%内存就会错误

#### 触发机制

**save命令(同步):** 在 redis 客户端中执行 save 命令, 有个致命的问题是这个命令是一个阻塞操作 O(n), 不会使用 fork 子进程

**bgsave命令(异步):** 在 redis 客户端中执行 bgsave 命令, redis 会使用 fork()函数, fork 一个子进程进行备份

| 命令    | save             | bgsave                   |
| ------- | ---------------- | ------------------------ |
| IO 类型 | 同步             | 异步                     |
| 阻塞    | 是               | 是(阻塞发生在 fork 过程) |
| 复杂度  | O(n)             | O(n)                     |
| 优点    | 不会消耗额外内存 | 不阻塞客户端命令         |
| 缺点    | 阻塞客户端命令   | 需要 fork, 消耗内存      |

**自动备份:** Redis 提供了系统自动备份的功能, 需要在配置文件中进行配置, 内部使用 bgsave 方式, 缺点是不太好控制生成时机, 造成磁盘的读写有可能过多

#### 其他触发机制

全量复制: 当进行主从复制时, master 节点会进行 rdb 备份

debug reload: debug 级别的重启, 不会将内存数据清空, 也会触发 rdb

shutdown: 会执行 shutdown save, 生成 rdb 文件

#### 相关配置

| 配置                            | 说明                              | 建议                                  |
| ------------------------------- | --------------------------------- | ------------------------------------- |
| save 900 1                      | 900秒内1次操作会触发备份          | 去除该条                              |
| save 300 10                     | 300 秒内 10 次操作会触发备份      | 去除该条                              |
| save 60 10000                   | 60秒内10000次操作会触发备份       | 去除该条                              |
| save ""                         | 不备份                            | 采用这条                              |
| dbfilename dump.rdb             | 指定 rdb 文件的名字               | dbfilename dump-\${host}-\${port}.rdb |
| dir ./                          | 指定 rdb 文件, aof 文件的存储位置 | dir /bigdiskpath                      |
| stop-writes-on-bgsave-error yes | bgsave 错误时是否停止写入         | yes                                   |
| rdbcompression yes              | 是否采用压缩格式, 方便主从复制    | yes                                   |
| rdbchecksum yes                 | 是否对 rdb 文件进行校验           | yes                                   |





### AOF保存命令日志(Append Only File)

#### RDB 现存问题

耗时, 耗性能: O(n)数据非常耗时, fork()消耗内存, 磁盘 IO

不可控, 丢失数据

#### AOF 介绍

把**每一条**对redis的**写操作**命令, 保存到类似日志文件中文件采用Redis协议的格式来保存, **新命令会追加到文件末尾**, 也支持每秒同步(默认)和不同步, 在数据恢复时按照从前到后的顺序再将指令都执行一遍. 配置文件中`appendonly yes`开启aof持久化,最大限度的保证了数据的完整性

AOF方式的另一个好处,我们通过一个“场景再现”来说明.某同学在操作redis时,不小心执行了FLUSHALL,导致redis内存中的数据全部被清空了,这是很悲剧的事情.不过这也不是世界末日,只要redis配置了AOF持久化方式,且AOF文件还没有被重写（rewrite）,我们就可以用最快的速度暂停redis并编辑AOF文件,将最后一行的FLUSHALL命令删除,然后重启redis,就可以恢复redis的所有数据到FLUSHALL之前的状态了.是不是很神奇,这就是AOF持久化方式的好处之一.但是如果AOF文件已经被重写了,那就无法通过这种方法来恢复数据了

#### AOF 三种策略

**Redis 写命令会刷新到缓冲区中**, 缓冲区会根据一定策略 fsync 到磁盘的 aof 文件中

always: 每条命令都会被 fsync 到磁盘, 有可能丢失最后一次命令, 推荐使用这种

everysec: 每秒把缓冲区 fsync 到磁盘, 有可能丢失最后一秒命令

no: 由 os 来决定什么时候进行 fsync

| 命令 | always                                      | everysec                   | no     |
| ---- | ------------------------------------------- | -------------------------- | ------ |
| 优点 | 不丢失数据                                  | 每秒一次 fsync 丢 1 秒数据 | 不用管 |
| 缺点 | IO 开销比较大, 一般的 sata 磁盘只有几百 TPS | 丢 1 秒数据                | 不可控 |

#### AOF 重写

因为采用了追加方式,如果不做任何处理的话,AOF文件会变得越来越大,为此,redis提供了AOF文件重写（rewrite）机制,即当AOF文件的大小超过所设定的阈值时,redis就会启动AOF文件的内容压缩,只保留可以恢复数据的最小指令集.举个例子或许更形象,假如我们调用了100次INCR指令,在AOF文件中就要存储100条指令,但这明显是很低效的,完全可以把这100条指令合并成一条SET指令,这就是重写机制的原理.**在进行AOF重写时,仍然是采用先写临时文件,全部完成后再替换的流程,所以断电、磁盘满等问题都不会影响AOF文件的可用性**

**命令行重写:** redis 客户端使用 bgrewriteaof 命令

**配置文件重写策略的参数设置, 自动配置**

1. 当前的AOF文件大小**超过**上一次重写时的AOF文件大小的百分之多少时,会再次进行重写,如果之前没有重写过,则以启动时的AOF文件大小为依据

    ```
    auto-aof-rewrite-percentage 100
    ```

2. 限制了允许重写的最小AOF文件大小,通常在AOF文件很小的时候, 即使其中有些冗余的命令也是可以忽略的

    ```
    auto-aof-rewrite-min-size 64mb
    ```

3. 统计当前 AOF 的尺寸, 单位字节

    ```
    aof_current_size
    ```

4. 统计 AOF 上次启动和重写的尺寸, 单位字节

    ```
    aof_base_size
    ```

5. 当满足如下条件时, 会自动触发 aof 重写

    `aof_current_size > auto-aof-rewrite-min-size`

    `(aof-current-size - aof_base_size)/aof_base_size > auto-aof-rewrite-percentage`

如果运气比较差,AOF文件出现了被写坏的情况,也不必过分担忧,redis并不会贸然加载这个有问题的AOF文件,而是报错退出.这时可以通过以下步骤来修复出错的文件：

1. 备份被写坏的AOF文件
2. 运行redis-check-aof –fix进行修复
3. 用diff -u来看下两个文件的差异,确认问题点
4. 重启redis,加载修复后的AOF文件

虽然优点多多,但AOF方式也同样存在缺陷,比如在同样数据规模的情况下,AOF文件要比RDB文件的体积大.而且,AOF方式的恢复速度也要慢于RDB方式.

#### 相关配置

| 配置                        | 说明                                                         | 建议                            |
| --------------------------- | ------------------------------------------------------------ | ------------------------------- |
| appendonly                  | 是否开启 aof 持久化                                          | 去除该条                        |
| appendfilename              | aof 文件的文件名                                             | appendonly-\${host}-${port}.aof |
| appendfsync                 | 同步策略                                                     | everysec                        |
| dir ./                      | 不备份                                                       | /bigdiskpath                    |
| no-appendfsync-on-rewrite   | 当 aof 重写时, 暂停 aof 持久化, 这样会提高性能, 但是有可能会丢失数据, no 的话相反, 具体选用哪种, 根据业务权衡 | yes                             |
| auto-aof-rewrite-percentage | 当前的AOF文件大小**超过**上一次重写时的AOF文件大小的百分之多少时,会再次进行重写,如果之前没有重写过,则以启动时的AOF文件大小为依据 |                                 |
| auto-aof-rewrite-min-size   | 限制了允许重写的最小AOF文件大小,通常在AOF文件很小的时候, 即使其中有些冗余的命令也是可以忽略的 |                                 |
| aof-load-truncated          | 遇到错误是否忽略                                             | yes                             |



### 使用建议

| 命令       | RDB    | AOF          |
| ---------- | ------ | ------------ |
| 启动优先级 | 低     | 高           |
| 体积       | 小     | 大           |
| 恢复速度   | 快     | 慢           |
| 数据安全性 | 丢数据 | 根据策略决定 |
| 轻重       | 重     | 轻           |

**如果只做缓存, 可以不使用任何持久化方式**

如果两个持久化方案同时开启, 优先采用aof方式, 因为aof保存的数据要比rdb完整

建议同时开启rdb和aof, rdb适合备份数据库, 因为aof在不断变化, 不好备份, 可以快速重启, 作为以防万一的手段

RDB 文件一旦被创建, 就不会进行任何修改. 当服务器要创建一个新的 RDB 文件时, 它先将文件的内容保存在一个临时文件里面, 当临时文件写入完毕时, 程序才使用 rename(2) 原子地用临时文件替换原来的 RDB 文件.这也就是说, 无论何时, 复制 RDB 文件都是绝对安全的.创建一个定期任务（cron job）, 每小时将一个 RDB 文件备份到一个文件夹, 并且每天将一个 RDB 文件备份到另一个文件夹

保证服务器有足够的内存, 做好监控(硬盘, 内存, 负载, 网络)      





## Redis 开发运维常见问题

### fork 操作

fork 操作是一个同步操作, 与内存量息息相关, 内存越大, 耗时越长, rdb 和 aof 的异步备份都需要 fork 一份子进程, 这个 fork 的过程就有可能阻塞住 redis 的主线程, 影响 qps

info 命令中有一个 latest_fork_usec 选项可以查看 fork 耗时的微秒数

如何改善 fork

* 优先使用物理机或者高效支持 fork 操作的虚拟化技术
* 控制 Redis 实例最大可用内存: maxmemory, 减少内存可以加快 fork
* 合理配置 Linux 内存分配策略: vm.overcommit_memory=1
* 降低 fork 频率: 例如放宽 AOF 重写自动触发时机, 不必要的全量复制

### 子进程开销和优化

CPU: RDB 和 AOF 文件生成, 属于 CPU 密集型, 我们部署 Redis 时, 不做 CPU 绑定, 不和 CPU 密集型的服务部署在一起

内存: fork 内存开销, copy-on-write 时会占用两份内存, 尽量不要大量写入

硬盘: AOF 和 RDB 文件写入, 可以结合 iostat, iotop 分析, 尽量将 Redis 单独部署一台服务器, 不要混用磁盘, 开启 no-appendfsync-on-rewrite=yes, 根据写入量使用 SSD 磁盘

### AOF 追加阻塞

主线程会向 AOF 缓冲区写入, 同时 AOF 会开启一个同步线程进行 AOF 同步, 主线程继续向下执行, 对比上次 fsync 的时间, 如果大于 2 秒, 阻塞主线程, 小于 2 秒, 正常执行

![https://miaomiaoqi.github.io/images/redis/redis_64.png](https://miaomiaoqi.github.io/images/redis/redis_64.png)

如果发现 Redis 阻塞情况发生, 可以通过 Redis 日志查看是否有 AOF 阻塞: `Asynchronous AOF fsync is takine too long(disk in busy?)`, 也可以通过 top 命令查看 linux 系统的 IO 情况

这种情况一般都是磁盘 IO 太忙导致, 尽量将 Redis 单独部署一台服务器, 不要混用磁盘, 开启 no-appendfsync-on-rewrite=yes, 根据写入量使用 SSD 磁盘



## Redis 主从复制的原理和优化

### 主从复制

如果单机部署 Redis 服务, 如果机器发生了故障, 虽然我们可以启动其他的服务迁移过去, 但是机器已经发生了故障, 数据就全部丢失了

Redis 的主从复制可以配置一台机器为 master 节点, 一台机器为 slave 节点, slave 节点会将 master 节点的数据根据一定策略全部拷贝一份, 达到一个备份的效果, 如果 master 节点的机器出现了故障, 那么 slave 节点就可以发挥作用了, Redis 还支持一主多从, 一份数据可以有多份备份, 还可以实现读写分离

一个 master 可以有多个 slave, 一个 slave 只能有一个 master, 数据流向是单向的, master 到 slave

### 主从复制配置

Redis 提供了两种主从复制的方式, 一种是使用 slaveof 命令, 另一种是使用配置文件进行配置, 第一次启动时建议使用配置文件, 配置文件方便集中管理, 后续有特殊修改可以使用命令的方式

#### slaveof 命令

如果我们希望 127.0.0.1:6380 成为 127.0.0.1:6379 的从节点, 就使用客户端连接到从节点的 redis 服务器执行命令, 这个命令是一个异步命令

```bash
slaveof 127.0.0.1 6379
```

如果我们需要取消 6380 的从节点, 可以执行如下命令, 但是 6380 原来同步过来的数据不会清除, 只是 6379 不在向 6380 同步数据, 需要手动清空数据, 如果 6380 节点再次执行 slaveof 命令成为其他主节点的从节点, 就会自动清空数据

```
slaveof no one
```

#### 配置文件

| 命令                           | 说明                                | 建议     |
| ------------------------------ | ----------------------------------- | -------- |
| slaveof ip port                | 将当前节点变为 ip port 节点的从节点 |          |
| slave-read-only yes            | 当前节点是不是只读的                | yes      |
| masterauth \<master-password\> | 配置主节点密码                      | 根据情况 |

info replication: 可以查看当前节点的备份信息, 节点状态等信息

### 全量复制和增量复制

#### 主从策略

主从刚刚连接的时候，进行全量同步；全同步结束后，进行增量同步。当然，如果有需要，slave 在任何时候都可以发起全量同步。redis 策略是，无论如何，首先会尝试进行增量同步，如不成功，要求从机进行全量同步。

#### 全量同步

Redis全量复制一般发生在Slave初始化阶段，这时Slave需要将Master上的所有数据都复制一份。具体步骤如下：

1. 从服务器连接主服务器，发送SYNC(Redis2.8 之后叫做 psync)命令, psync ?(run_id第一次不知道) -1(偏移量, 第一次是-1)
2. 从服务器接收主服务器的信息, runId, offset 保存

3. 主服务器接收到SYNC命名后，主服务器开启一个子进程执行BGSAVE命令生成RDB文件, **并使用缓冲区(repl_back_buffer)记录此后执行的所有写命令**

4. 主服务器BGSAVE执行完后，向所有从服务器发送快照文件，并在发送期间继续记录被执行的写命令

5. 从服务器收到快照文件后丢弃所有旧数据，载入收到的快照

6. 主服务器快照发送完毕后开始向从服务器发送缓冲区中的写命令

7. 从服务器完成对快照的载入，开始接收命令请求，并执行来自主服务器缓冲区的写命令

**全量复制的开销**

1. 主节点 bgsave 生成 rdb 文件的时间
2. rdb 文件网络传输时间
3. 从节点清空数据时间
4. 从节点加载 rdb 的时间
5. 可能的 aof 重写时间

#### 增量同步

Redis增量复制是指Slave初始化后开始正常工作时主服务器发生的写操作同步到从服务器的过程。增量复制的过程主要是主服务器每执行一个写命令就会向从服务器发送相同的写命令，从服务器接收并执行收到的写命令。

### 开发运维常见问题

#### 读写分离

复制数据延迟, 这个不可避免

读到过期数据, redis 处理过期数据的三种方式是定时过期, 惰性过期, 定期过期, 在主从全量同步时, 有可能会把未过期的数据同步到从节点, 从节点读到过期数据时, 又不能处理过期数据, 因为从节点是只读的, redis3.2 已解决该问题

从节点故障, 需要手动将从节点的客户端迁移到其他节点, 后期使用 Redis Sentinel 解决

#### 主从配置不一致

maxmemory 不一致导致丢失数据

数据结构优化参数(例如 hash-max-ziplist-entries): 因为优化参数不一致, 导致内存大小不一致

#### 规避全量复制

第一次全量复制, 第一次不可避免, maxmemory 不要设置过大, 在低峰时刻进行

主节点重启(运行 id 变化)

复制挤压缓冲区不足

#### 规避复制风暴

一个 master 节点挂载了许多从节点, 当 master 节点重启后, 每个 slave 节点都需要传输一份数据, 要合理规划服务拓扑, Redis Sentinel 可解决



## Redis Sentinel

### 主从复制高可用

主从复制可以使程序的读写分离, 并且达到一个备份的效果, 但是出现故障后只能手动故障转移, 转个流程非常不方便操作, 另外是写能力和存储能力受限

假如 master 宕机了, 主从的增量同步会断掉, master 的客户端的写操作也会失败, 此时读操作还是正常的, 首先手动在一台 slave 节点执行 `slaveof no one` 命令, 让其成为 master 节点, 对其他 slave 节点执行 `slaveof host port` 命令找到新的 master, 所有的客户端都要改变 redis 地址, 整个过程虽然可以用脚本完成, 但是很复杂

### Redis Sentinel 架构

### 安装配置

### 客户端连接

### 实现原理

### 常见开发运维问题





## Redis Cluster









## 常用配置与命令

info replication: 查看节点状态, 备份等信息

info memory: 查看内存使用情况