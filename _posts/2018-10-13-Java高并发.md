---
layout: post
title: "Java 高并发"
categories: [Java]
description:
keywords:
---

* content
{:toc}

## 基本概念

* 并发

    同时拥有两个或者多个线程, 如果程序在单核处理器上运行, 多个线程将交替地换入或者换出内存, 这些线程是同时"存在"的, 每个线程都处于执行过程中的某个状态, 如果运行在多核处理器上, 此时, 程序中的每个线程都将分配到一个处理器核上, 因此可以同时运行

    多个线程操作相同的资源, **保证线程安全**, 合理使用资源

* 高并发

    高并发(High Concurrency)是互联网分布式系统架构设计中必须考虑的因素之一, 它通常是指, 通过设计保证系统能够**同时并行处理**很多请求

    服务能同时处理很多请求, **提高程序性能**

* CPU多级缓存

    CPU的频率太快了, 快到主存跟不上, 这样在处理器时钟周期内, CPU常常需要等待主存, 浪费资源. 所以Cache出现, 是为了缓解CPU和内存之间速度的不匹配问题(结构: cpu -> cache -> memory)

    * CPU Cache有什么意义

        1. 时间局部性: 如果某个数据被访问, 那么在不久的将来它可能再次被访问

        1. 空间局部性: 如果某个数据被访问, 那么与它相邻的数据很快也可能被访问

    * 缓存一致性(MESI)

        用于保证多个CPU Cache之间缓存共享数据的一致

        ![http://miaomiaoqi.github.io/images/concurrency/1.png](http://miaomiaoqi.github.io/images/concurrency/1.png)

* CPU乱序执行优化

    处理器为提高运算速度而做出违背代码原有顺序的优化

* Java内存模型(Java Memory Model, JMM)

    规范Java虚拟机与计算机内存是如何协调工作的, 规定了一个线程如何和何时可以看到其他线程修改过的共享变量的值, 以及在必须时如何同步地访问共享变量

    ![http://miaomiaoqi.github.io/images/concurrency/1.png](http://miaomiaoqi.github.io/images/concurrency/2.png)

    * 同步八种操作

        1. lock(锁定)

            作用于主内存的变量, 把一个变量标识位一条线程独占的状态

        1. unlock(解锁)

            作用于主内存的变量, 把一个处于锁定状态的变量释放出来, 释放后的变量才可以被其他线程锁定

        1. read(读取)

            作用于主内存的变量, 把一个变量值从主内存传输到线程的工作内存中, 以便随后的load动作使用

        1. load(载入)

            作用于工作内存的变量, 它把read操作从主内存中得到的变量值放入工作内存的变量副本中

        1. use(使用)

            作用于工作内存的变量, 把工作内存中的一个变量值传递给执行引擎

        1. assign(赋值)

            作用于工作内存的变量, 它把一个从执行引擎接收到的值赋值给工作内存的变量

        1. store(存储)

            作用于工作内存的变量, 把工作内存中的一个变量的值传送到主内存中, 以便随后的write的操作

        1. write(写入)

            作用于主内存的变量, 它把store操作从工作内存中一个变量的值传送到主内存的变量中

    * 同步规则

        1. 如果要把一个变量从主内存中复制到工作内存中, 就需要按顺序的执行read和load操作, 如果把变量从工作内存中同步回主内存中, 就要按顺序的执行store和write操作. 但java内存模型只要求上述操作必须按顺序执行, 而没有保证必须是连续执行

        1. 不允许read和load, store和write操作之一单独出现

        1. 不允许一个线程丢弃它的最近assign的操作, 即变量在工作内存中改变了之后必须同步到主内存中

        1. 不允许一个线程无原因地(没有发生过任何assign操作)把数据从工作内存同步回主内存中

        1. 一个新的变量只能在主内存中诞生, 不允许在工作内存中直接使用一个未初始化(load或assign)的变量. 即就是对一个变量实施use和store操作之前, 必须先执行过了assign和load操作

        1. 一个变量在同一时刻只允许一条线程对其进行lock操作, 但lock操作可以被同一条线程重复执行多次, 多次执行lock后, 只有执行相同次数的unlock操作, 变量才会被解锁. lock和unlock必须成对出现

        1. 如果一个变量执行lock操作, 将会清空工作内存中此变量的值, 在执行引擎使用这个变量前需重新执行load或assign操作初始化变量的值

        1. 如果一个变量事先没有被lock操作锁定, 则不允许对它执行unlock操作; 也不允许去unlock一个被其他线程锁定的变量

        1. 对一个变量执行unlock操作之前, 必须先把此变量同步到主内存中(执行store和write操作)

        ![http://miaomiaoqi.github.io/images/concurrency/1.png](http://miaomiaoqi.github.io/images/concurrency/3.png)
        
        ![http://miaomiaoqi.github.io/images/concurrency/1.png](http://miaomiaoqi.github.io/images/concurrency/4.png)

## 并发模拟

* Postman

    Http请求模拟工具

* Apache Bench(AB)

    Apache附带的工具, 测试网站性能

* JMeter

    Apache组织开发的压力测试工具

        jmeter.sh

* 代码

    Semaphore, CountDownLatch等

## 线程安全性

* 当多个线程访问某个类时, 不管运行时环境采用何种调度方式或者这些进程将如何交替执行, 并且在主调代码中不需要任何额外的同步或协同, 这个类都能表现出正确的行为, 那么就称这个类是线程安全的

    * 原子性

        提供了互斥访问, 同一时刻只能有一个线程来对它进行操作

        * Atomic包
        
            AtomicXXX: CAS, Unsafe.compareAndSwapInt
    
            AtomicLong和LongAdder
    
            AtomicReference, AtomicXxxFieldUpdater
            
            AtomicStampReference 解决CAS的ABA问题
    
            AtomicBoolean

        * 锁

            synchronized 依赖 JVM

            * 修饰代码块

                大括号括起来的对象, 作用于**调用的对象**

            * 修饰方法

                整个方法, 作用于**调用的对象**
                
            * 修饰静态方法

                整个静态方法, 作用于**所有对象**

            * 修饰类

                括号括起来的部分, 作用于**所有对象**
            
            Lock 依赖特殊的CPU指令, 代码实现, ReentrantLock

        * 对比

            * synchronized

                不可中断锁, 适合竞争不激烈, 可读性好

            * Lock

                可中断锁, 多样化同步, 竞争激烈时能维持常态

            * Atomic

                竞争激烈时能维持常态, 比Lock性能好, 但只能同步一个值

    * 可见性

        一个线程对主内存的修改可以及时的被其他线程观察到

        导致共享变量在线程间不可见的原因

        * 线程交叉执行

        * 重排序结合线程交叉执行

        * 共享变量更新后的值没有在工作内存与主内存间及时更新

        JMM关于synchronized的两条规定

        * 线程解锁前, 必须把共享变量的最新值刷新到主内存中

        * 线程加锁前, 将清空工作内存中共享变量的值, 从而使用共享变量时需要从主内存中重新读取最新的值**(加锁与解锁是同一把锁)**

        volatile关键字, 通过加入内存屏障和禁止重排序优化来实现

        * 对volatile变量写操作时, 会在写操作后加入一条store屏障指令, 将本地内存中的共享变量值刷新到主存中

            ![http://miaomiaoqi.github.io/images/concurrency/5.png](http://miaomiaoqi.github.io/images/concurrency/5.png)

        * 对volatile变量读操作时, 会在读操作前加入一条load屏障指令, 从主内存中读取共享变量

            ![http://miaomiaoqi.github.io/images/concurrency/6.png](http://miaomiaoqi.github.io/images/concurrency/6.png)

    * 有序性

        一个线程观察其他线程中的指令执行顺序, 由于指令重排序的存在, 该观察结果一般杂乱无序

        在Java内存模型中, 允许编译器和处理器对指令进行重排序, 但是重排序过程不会影响到单线程程序的执行, 却会影响到多线程并发执行的正确性

        * happens-before原则

            * 程序次序规则

                一个线程内, 按照代码顺序, 书写在前面的操作先行发生于书写在后面的操作, 只是保证单线程操作的正确性

            * 锁定规则

                一个unlock操作先行发生于后面对同一个锁的lock操作

            * volatile变量规则

                对一个变量的写操作先行发生于后面对这个变量的读操作

            * 传递规则

                如果操作A先行发生于操作B, 而操作B又先行发生于操作C, 则可以得出操作A先行发生于操作C

            * 线程启动原则

                Thread对象的start()方法先行发生于此线程的每一个动作

            * 线程中断规则

                对线程interrupt()方法的调用先行发生于被中断线程的代码检测到中断事件的发生

            * 线程终结规则

                线程中所有操作都先行发生于线程的终止检测, 我们可以通过Thread.join()方法结束. Thread.isAlive()的返回值手段检测到线程已经终止执行

            * 对象终结规则

                一个对象的初始化完成先行发生于他的finalize()方法的开始


## 安全发布对象

* 发布对象

    使一个对象能够被当前范围之外的代码所使用
    
* 对象逸出

    一种错误的发布, 当一个对象还没有构造完成时, 就使它被其他线程所见

参考单例模式

### 安全发布对象的四中方法

* 在静态初始化函数中

* 将对象的引用保存到volatile类型域或者AtomicReference对象中

* 将对象的引用保存到某个正确构造对象的final类型域中

* 将对象的引用保存到一个由锁保护的域中


## 不可变对象

* 不可变对象需要满足的条件

    * 对象创建以后其状态就不能修改

    * 对象所有域都是final类型

    * 对象时正确创建的(在对象创建期间, this引用没有逸出)

* final关键字: 类, 方法, 变量

    * 修饰类

        不能被继承, 所有成员方法会被隐式声明为final方法

    * 修饰方法

        1. 锁定方法不被继承类修饰

        1. 效率

    * 修饰变量

        1. 基本数据类型变量, 值不能被修改

        1. 引用类型变量, 引用地址不能被修改

* Collections.unmodifiableXXX: Collection, List, Set, Map...

* Guava: ImmutableXXX: Collection, List, Set, Map...

  ​      
## 线程封闭

* Ad-hoc线程封闭: 程序控制实现, 最糟糕, 忽略

* 堆栈封闭: 局部变量, 无并发问题

* ThreadLocal线程封闭: 特别好的封闭方法

## 线程不安全类与写法

* StringBuilder -> StringBuffer

* SimpleDateFormat -> JodaTime

* ArrayList, HashSet, HashMap等Collections

## 线程安全

### 同步容器

* ArrayList -> Vector, Stack

* HashMap -> HashTable(key, value不能为null)

* Collections.synchronizedXXX(List, Set, Map)

### 并发容器JUC

* ArrayList -> CopyOnWriteArrayList

    不能实时读, 会占用内存(读写分离, 最终一致性)

* HashSet, TreeSet -> CopyOnWriteArraySet, ConcurrentSkipListSet

* HashMap, TreeMap -> ConcurrentHashMap, ConcurrentSkipListMap(跳表)

### AQS - AbstractQueuedSynchronizer

* 底层是双向链表

    * 子类通过继承并通过实现它的方法管理其状态(acquire和release)的方法操作状态

    * 可以实现排它锁和共享锁模式(独占, 共享)

* AQS同步组件

    * CountDownLatch

        ![http://miaomiaoqi.github.io/images/concurrency/7.png](http://miaomiaoqi.github.io/images/concurrency/7.png)

        内部维护了一个计数器, 只有当计数器为0时程序才能向下执行

    * Semaphore

        信号量, 可以控制线程的个数

    * CyclicBarrier
    
    * ReentrantLock(可重入锁)

        * 与synchronized对比
    
            ||ReentrantLock|synchronized|
            |-----|-----|-----|
            |可重入性|可以|可以|
            |锁的实现|编码实现|依赖JVM|
            |性能|一样|一样|
            |功能|细粒度, 不便捷|粗粒度, 便捷|
            |公平锁|可以|不可以|
        
        * 独有功能

            1. 可以指定是公平锁(先等待先获得)还是非公平锁

            1. 提供了一个Condition类, 可以分组唤醒需要唤醒的线程

            1. 提供能够中断等待锁的线程的机制, lock.lockInterruptibly()

    * Condition

    * FutureTask

        Callable接口可以有返回值, Runnable接口不能有返回值

        Future接口, 可以获得结果

        FutureTask

    * Fork/Join框架

        Java7提供的用于并行执行任务的框架

        将大任务分割为多个小任务, 最终将小任务的结果汇合, 采用工作窃取算法

    * BlockingQueue

        |-|Throws Exception|Special Value|Blocks|Times Out|
        |-----|-----|-----|-----|-----|
        |Insert|add(o)|offer(o)|put(o)|offer(o, timeout, timeunit)|
        |Remove|remove(o)|poll()|take()|poll(timeout, timeunit)|
        |Examine|element()|peek()|||

        * ArrayBlockingQueue

            容量有限, 先进先出

        * DelayQueue

            可以排序

        * LinkedBlockingQueue

            内部是链表, 先进先出
            
        * PriorityBlockingQueue

            可以插入null, 可以排序

        * SynchronousQueue

            内部只允许容纳一个元素

## 线程池

* new Thread的弊端

    * 每次new Thread新建对象, 性能差

    * 线程缺乏统一管理, 可能无限制的新建线程, 相互竞争, 有可能占用过多系统资源导致死机或者OOM

    * 缺少更多功能, 如更多执行, 定期执行, 线程中断

* 线程池的好处

    * 重用存在的线程, 减少对象的创建, 消亡的开销, 性能佳

    * 可有效控制最大并发线程数, 提高系统资源利用率, 同时可以避免过多资源竞争, 避免阻塞

    * 提供定时执行, 定期执行, 单线程, 并发数控制等功能

* ThreadPoolExecutor

    * 核心参数

        * corePoolSize: 核心线程数量
    
            如果线程池的数量**小于**corePoolSize, 即使有空余线程, 也会直接创建新线程
    
        * maximumPoolSize: 线程最大线程数
    
            如果线程池的数量**大于等于**corePoolSize**且小于**maximumPoolSize, 则只有当workQueue满的时候才会创建新线程
    
        * workQueue: 阻塞队列, 存储等待执行的任务, 很重要, 对线程池运行过程产生重大影响
    
        * keepAliveTime: 线程没有任务执行时最多保持多久时间终止
    
        * unit: keepAliveTime的时间单位
    
        * threadFactory: 线程工厂, 用来创建线程
    
        * rejectHandler: 当拒绝处理任务时的策略

    ![http://miaomiaoqi.github.io/images/concurrency/8.png](http://miaomiaoqi.github.io/images/concurrency/8.png)

    * 核心方法

        * execute(): 提交任务, 交给线程池执行

        * submit(): 提交任务, 能够返回执行结果, execute + Future

        * shutdown(): 关闭线程池, 等待任务都执行完

        * shutdownNow(): 关闭线程池, 不等待任务执行完成

        * getTaskCount(): 线程池已执行和未执行的任务总数

        * getCompletedTaskCount(): 已完成的任务数量

        * getPoolSize(): 线程池当前的线程数量

        * getActiveCount(): 当前线程池中正在执行任务的线程数量

    ![http://miaomiaoqi.github.io/images/concurrency/9.png](http://miaomiaoqi.github.io/images/concurrency/9.png)

* Executors

    * Executors.newCachedThreadPool

        创建可缓存的线程池, 如果线程池的数量超过了需要处理的任务, 可以回收线程

    * Executors.newFixedThreadPool

        创建一个定长的线程池, 可以控制线程的最大并发数, 超出的线程会在队列中等待

    * Executors.newScheduledThreadPool

        创建一个定长的线程池, 支持定时以及周期性的任务执行

    * Executors.newSingleThreadExecutor

        创建一个单线程的线程池, 只能创建一个工作线程, 保证任务按照指定顺序执行

* 线程池合理配置

    * CPU密集型任务, 就需要尽量压榨CPU, 参考值可以设置为NCPU + 1

    * IO密集型任务, 参考值可以设置为2 * NCPU

    首先设置为参考值, 再观察CPU利用率进行适当调整


## 死锁

* 两个线程互相等待对方释放资源

* 死锁的条件

    * 互斥条件

    * 请求和保持条件

    * 不剥夺条件

    * 环路等待条件

## 多线程并发最佳实践

* 使用本地变量

* 使用不可变量

* 最小化锁的作用域范围

* 使用线程池的Executor, 而不是直接new Thread执行

* 宁可使用同步, 也不要使用wait和notify方法

* 使用BlockingQueue实现生产-消费模式

* 使用并发集合而不是加了锁的同步集合

* 使用Semaphore创建有界的访问

* 宁可使用同步代码块, 也不使用同步的方法

* 避免使用静态变量

## Spring与线程安全

* Spring Bean: singleton, prototype

* 无状态对象

## 高并发处理思路与手段

### 高并发扩容

* 垂直扩容(纵向扩展)

    提高系统部件能力, 通俗来说就是增加单节点的内存大小

* 水平扩容(横向扩展)

    增加更多系统成员来实现, 通俗来说是单节点变为集群

* 数据库扩容

    * 读操作扩容

        memcache, redis, cdn等缓存

    * 写操作扩展

        Cassandra, Hbase等

### 高并发缓存

![http://miaomiaoqi.github.io/images/concurrency/10.png](http://miaomiaoqi.github.io/images/concurrency/10.png)

* 缓存特征

    * 命中率

        命中数 / (命中数 + 没有命中数)

        命中率越高, 我们的收益越好

    * 最大元素(空间)

        可以容纳的最大数据的数量, 如果达到了阈值, 就会触发缓存清空策略

    * 清空策略

        选择合适的清空策略, 可以提高我们的命中率

        FIFO, LFU, LRU, 过期时间, 随机等

* 影响缓存命中率的因素

    1. 业务场景和业务需求

        适合对读取要求高, 实时性要求低的业务场景

    1. 缓存的设计(粒度和策略)

    1. 缓存容量与基础设施

* 缓存分类和应用场景

    * 本地缓存

        编程实现(成员变量, 局部变量, 静态变量)Guava Cache

    * 分布式缓存

        MemCache, Redis

### 高并发消息队列

![http://miaomiaoqi.github.io/images/concurrency/11.png](http://miaomiaoqi.github.io/images/concurrency/11.png)

* 消息队列特性

    * 业务无关: 只做消息分发

    * FIFO: 先进先出

    * 容灾: 节点的动态增删和消息的持久化

    * 性能: 吞吐量

* 为什么需要消息队列

    * [生产]和[消费]的速度或稳定性等因素不一致

* 消息队列的好处

    * 业务解耦

    * 最终一致性

    * 广播

    * 错峰与流控

### 高并发应用拆分

![http://miaomiaoqi.github.io/images/concurrency/12.png](http://miaomiaoqi.github.io/images/concurrency/12.png)

* 应用拆分原则

    * 业务优先

    * 循序渐进

    * 兼顾技术: 重构, 拆分

    * 可靠测试

* 应用拆分-思考

    * 应用间通信: RPC(dubbo等), 消息队列

    * 应用之间数据库: 每个应用都有独立的数据库

    * 避免事物操作跨应用

### 高并发应用限流

![http://miaomiaoqi.github.io/images/concurrency/13.png](http://miaomiaoqi.github.io/images/concurrency/13.png)

### 高并发服务降级与熔断

* 服务降级

    * 自动降级: 超时, 失败次数, 故障, 限流

    * 人工降级: 秒杀, 双11大促

* 服务熔断
        

### 高并发分库分表

* 数据库瓶颈

    * 单个库数据量太大(1T~2T): 拆分多个库

    * 单个数据库服务器压力过大, 读写瓶颈: 拆分多个库

    * 单个表数据量过大: 分表

* 切库

    * 切库的基础及实际运用: 读写分离

    * 自定义注解完成数据库切库

    * 支持读数据源

### 高可用的一些手段

* 任务调度系统分布式: elastic-job + zookeeper

* 主备切换: apache curator + zookeeper分布式锁实现

* 监控报警机制
        
        
        
        
        
        
        
        
        
        
        




​    
​    